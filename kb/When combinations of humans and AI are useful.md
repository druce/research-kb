# Research Notes: When combinations of humans and AI are useful

**Source:** `When combinations of humans and AI are useful`  
**Processed:** research-kb

---

```markdown
**Key Finding: Human-AI Combinations Often Underperform**
On average, human-AI systems perform worse than either humans alone or AI alone, suggesting a lack of synergy in many current implementations. — Vaccaro, Almaatouq, & Malone (2024)

---

**Supporting Fact: Negative Synergy Effect Size**
A meta-analysis of 106 experiments revealed a negative pooled effect (Hedges’ g = -0.23) when comparing human-AI systems to the best of human or AI alone. — Vaccaro, Almaatouq, & Malone (2024)

---

**Key Finding: Human Augmentation Exists, But Not Synergy**
While human-AI combinations often underperform the *best* of either alone, they *do* generally outperform humans working alone. — Vaccaro, Almaatouq, & Malone (2024)

---

**Supporting Fact: Positive Augmentation Effect Size**
The pooled effect size for human augmentation (human-AI vs. human alone) was positive (g = 0.64), indicating that AI helps humans perform better on average. — Vaccaro, Almaatouq, & Malone (2024)

---

**Key Finding: Task Type Moderates Synergy**
Decision-making tasks show performance losses in human-AI combinations, while creative tasks show potential for synergy. — Vaccaro, Almaatouq, & Malone (2024)

---

**Supporting Fact: Task Type Effect Sizes**
Decision tasks had a significantly negative pooled effect size (g = -0.27), while creation tasks had a positive effect size (g = 0.19), though not significantly different from 0. — Vaccaro, Almaatouq, & Malone (2024)

---

**Key Finding: Relative Performance Matters**
Human-AI synergy is more likely when humans outperform AI alone; performance losses occur when AI outperforms humans alone. — Vaccaro, Almaatouq, & Malone (2024)

---

**Supporting Fact: Relative Performance Effect Sizes**
When humans outperformed AI, the human-AI system showed synergy (g = 0.46); when AI outperformed humans, the human-AI system showed performance losses (g = -0.54). — Vaccaro, Almaatouq, & Malone (2024)

---

**Surprisingly Insignificant Moderators: Explanation and Confidence**
Factors like AI explanations and confidence levels, often emphasized in research, did not significantly impact the effectiveness of human-AI collaboration in this meta-analysis. — Vaccaro, Almaatouq, & Malone (2024)

---

**Critical Capability: Innovative Process Design**
Effective AI use requires designing innovative processes for combining humans and AI, not just developing innovative technologies. — Vaccaro, Almaatouq, & Malone (2024)

---

**AI Roadmap: Focus on Generative AI for Creation Tasks**
Future research should prioritize human-AI synergy in creation tasks, particularly with generative AI, as these areas show more promise. — Vaccaro, Almaatouq, & Malone (2024)

---

**Measuring Success: Robust Evaluation Metrics**
Develop and employ more robust metrics that consider task completion time, financial cost, and the practical implications of different types of errors, beyond just overall accuracy. — Vaccaro, Almaatouq, & Malone (2024)

---

**Critical Capability: Commensurability Criteria**
Develop a set of commensurability criteria to facilitate systematic comparisons across human-AI collaboration studies and track progress. — Vaccaro, Almaatouq, & Malone (2024)

---

**Best Practice: Commensurability Criteria Dimensions**
Commensurability criteria should include standardized guidelines for task designs, quality constraints, incentive schemes, process types, and evaluation metrics. — Vaccaro, Almaatouq, & Malone (2024)

---

**Best Practice: Open Reporting Repository**
Establish a standardized and open reporting repository for human-AI collaboration experiments to facilitate replication, extension, and synthesis of research. — Vaccaro, Almaatouq, & Malone (2024)
```