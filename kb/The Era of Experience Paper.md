# Research Notes: The Era of Experience Paper

**Source:** `The Era of Experience Paper`  
**Processed:** research-kb

---

**Key Finding: Shift from Human Data to Experiential Learning**
AI is transitioning from relying on human-generated data to learning from its own experiences, which will enable superhuman capabilities. This shift is driven by the limitations of human data in achieving further progress in domains like mathematics, coding, and science.

---
**Key Finding: Limitations of Human-Centric AI**
While imitating humans allows AI to reproduce human capabilities to a competent level, it is unlikely to achieve superhuman intelligence across many important topics and tasks. Valuable new insights lie beyond the boundaries of human understanding and cannot be captured by existing human data.

---
**Key Finding: Experiential Learning Enables Continuous Improvement**
Agents learning from their own experience can continually improve as they become stronger, surpassing the limitations of static, synthetically generated data. This approach allows AI to explore possibilities beyond pre-existing human knowledge.

---
**Key Finding: Characteristics of the Era of Experience**
Agents will inhabit long streams of experience, interact with the environment in a grounded manner, receive rewards based on their experience, and plan/reason about experience, rather than solely in human terms.

---
**Critical Capability: Long-Term Interaction Streams**
Buy-side firms need to develop AI systems that can operate within long-term interaction streams, carrying information across episodes and adapting over time to achieve long-term goals, rather than focusing on short, isolated interactions.

---
**Critical Capability: Grounded Actions and Observations**
Firms should prioritize AI agents that can act autonomously in the real world through motor control and sensors, rather than relying solely on human-privileged communication channels like text input/output.

---
**Critical Capability: Grounded Rewards**
Buy-side firms should explore using rewards grounded in real-world signals and environmental feedback, rather than relying solely on human prejudgment, to enable AI to discover strategies that humans may not appreciate.

---
**Critical Capability: Non-Human Reasoning**
Firms should encourage AI systems to develop non-human reasoning methods, such as symbolic or distributed computations, that may be more efficient than imitating human thought processes.

---
**Critical Capability: World Modeling**
Firms should invest in AI agents that can build world models to predict the consequences of their actions, including predicting rewards, allowing them to plan effectively and adapt to changing environments.

---
**AI Roadmap: Phase 1 - Implement Long-Term Interaction Streams**
Begin by developing AI systems that can operate within long-term interaction streams, carrying information across episodes and adapting over time to achieve long-term goals.

---
**AI Roadmap: Phase 2 - Integrate Grounded Actions and Observations**
Integrate AI agents that can act autonomously in the real world through motor control and sensors, rather than relying solely on human-privileged communication channels like text input/output.

---
**AI Roadmap: Phase 3 - Utilize Grounded Rewards**
Utilize rewards grounded in real-world signals and environmental feedback, rather than relying solely on human prejudgment, to enable AI to discover strategies that humans may not appreciate.

---
**AI Roadmap: Phase 4 - Develop Non-Human Reasoning**
Develop AI systems to develop non-human reasoning methods, such as symbolic or distributed computations, that may be more efficient than imitating human thought processes.

---
**AI Roadmap: Phase 5 - Build World Modeling Capabilities**
Build AI agents that can build world models to predict the consequences of their actions, including predicting rewards, allowing them to plan effectively and adapt to changing environments.

---
**Measuring Success: Long-Term Goal Achievement**
Evaluate AI systems based on their ability to achieve long-term goals within a stream of experience, such as improving a user's health or learning a new language.

---
**Measuring Success: Discovery of Novel Strategies**
Assess AI systems based on their ability to discover novel strategies and insights that go beyond existing human knowledge.

---
**Measuring Success: Adaptation to Changing Environments**
Evaluate AI systems based on their ability to adapt to changing environments and unexpected events, demonstrating robustness and resilience.

---
**Best Practice: Flexible Reward Adaptation**
Implement reward functions that can be flexibly adapted based on grounded signals and user feedback, allowing for continuous improvement and alignment with user goals.

---
**Best Practice: Combining Human and Environmental Feedback**
Design AI systems that can integrate both human feedback and environmental signals to optimize their behavior and achieve desired outcomes.

---
**Decision: Algorithm Selection**
Choose algorithms that are well-suited for long-term learning, exploration, and planning in complex environments, such as reinforcement learning methods with temporal abstraction and world modeling capabilities.

---
**Decision: Data Strategy**
Develop a data strategy that focuses on collecting and utilizing real-world data and environmental signals, rather than relying solely on human-generated data.

---
**Decision: Infrastructure Investment**
Invest in the infrastructure and resources needed to support autonomous agents that can interact with the real world through sensors, actuators, and digital interfaces.

---
**Key Quote: DeepSeek AI on Reinforcement Learning**
"Rather than explicitly teaching the model on how to solve a problem, we simply provide it with the right incentives, and it autonomously develops advanced problem-solving strategies." — DeepSeek AI

---
**Key Quote: On the potential of experiential learning**
"Incredible new capabilities will arise once the full potential of experiential learning is harnessed."

---
**Key Quote: On the limitations of human-centric AI**
"Relying on human prejudgement in this manner usually leads to an impenetrable ceiling on the agent’s performance: the agent cannot discover better strategies that are underappreciated by the human rater."