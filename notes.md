**Source:** `2023 survey & evolutionary tree`

**LLMs vs. Fine-tuned Models: Definitions**
LLMs are huge language models pre-trained on large amounts of datasets without tuning on data for specific tasks; fine-tuned models are typically smaller language models pre-trained and then further tuned on a smaller, task-specific dataset.


---

**Source:** `2023 survey & evolutionary tree`

**Key Capability: Reasoning Ability**
Understand and harness the reasoning capabilities of LLMs to improve decision-making and problem-solving in various contexts.


---

**Source:** `2023 survey & evolutionary tree`

**LLMs Generalize Better with OOD Data**
LLMs generalize better than fine-tuned models in downstream tasks facing out-of-distribution data, such as adversarial examples and domain shifts.


---

**Source:** `2023 survey & evolutionary tree`

**Data Availability and Model Choice**
LLMs are preferable to fine-tuned models when working with limited annotated data, and both can be reasonable choices when abundant annotated data is available, depending on specific task requirements.


---

**Source:** `2023 survey & evolutionary tree`

**Importance of Pre-training Data Similarity**
It’s advisable to choose models pre-trained on fields of data that are similar to downstream tasks.


---

**Source:** `2023 survey & evolutionary tree`

**Zero Annotated Data: Use LLMs**
In scenarios where annotated data is unavailable, utilizing LLMs in a zero-shot setting proves to be the most suitable approach.


---

**Source:** `2023 survey & evolutionary tree`

**Few Annotated Data: Use LLMs with In-Context Learning**
With few annotated data, incorporate the few-shot examples directly in the input prompt of LLMs, which is named as in-context learning, and these examples can effectively guide LLMs to generalize to the task.


---

**Source:** `2023 survey & evolutionary tree`

**Abundant Annotated Data: Consider Both LLMs and Fine-tuned Models**
With a substantial amount of annotated data for a particular task available, both fine-tuned models and LLMs can be considered, depending on desired performance, computational resources, and deployment constraints.


---

**Source:** `2023 survey & evolutionary tree`

**Traditional NLU Tasks: Fine-tuned Models Often Better**
Fine-tuned models generally are a better choice than LLMs in traditional NLU tasks, but LLMs can provide help while requiring strong generalization ability.


---

**Source:** `2023 survey & evolutionary tree`

**Traditional NLU Tasks: LLMs Struggle with Toxicity Detection**
All LLMs cannot perform well on toxicity detection, and on CivilComments even the best one is only better than random guessing.


---

**Source:** `2023 survey & evolutionary tree`

**Traditional NLU Tasks: LLMs Not Widely Exploited in IR**
In information retrieval (IR) tasks, LLMs are not widely exploited yet, one major reason is that IR tasks are fundamentally different from others.


---

**Source:** `2023 survey & evolutionary tree`

**Key Finding: Decoder-Only Models Dominating LLM Development**
Decoder-only models have gradually dominated the development of LLMs, especially after the introduction of GPT-3 in 2021, while encoder-only models have begun to fade after BERT's initial growth. — Source: 2023 survey & evolutionary tree


---

**Source:** `2023 survey & evolutionary tree`

**Use Case for LLMs: Miscellaneous Text Classification**
One of the representative tasks is miscellaneous text classification, which deals with a diverse range of topics and categories that may not have a clear or strong relationship with one another.


---

**Source:** `2023 survey & evolutionary tree`

**Use Case for LLMs: Adversarial NLI**
LLMs have shown superior performance on Adversarial NLI (ANLI), especially on the R3 and R2.


---

**Source:** `2023 survey & evolutionary tree`

**Generation Tasks: LLMs Show Superiority**
Due to their strong generation ability and creativity, LLMs show superiority at most generation tasks.


---

**Source:** `2023 survey & evolutionary tree`

**Summarization Tasks: Humans Prefer LLM Results**
Although LLMs do not have an obvious advantage over fine-tuned models under traditional automatic evaluation metrics, human evaluation results indicate that humans tend to prefer the results generated by LLMs.


---

**Source:** `2023 survey & evolutionary tree`

**Machine Translation: LLMs Good at Low-Resource Languages**
LLMs are particularly good at translating some low-resource language texts to English texts, such as in the Romanian-English translation of WMT’16.


---

**Source:** `2023 survey & evolutionary tree`

**Code Synthesis: LLMs are Remarkably Adept**
LLMs are remarkably adept at code synthesis as well. Either for text-code generation, such as HumanEval and MBPP, or for code repairing, such as DeepFix, LLMs can perform pretty well.


---

**Source:** `2023 survey & evolutionary tree`

**Knowledge-Intensive Tasks: LLMs Excel**
LLMs excel at knowledge-intensive tasks due to their massive real-world knowledge.


---

**Source:** `2023 survey & evolutionary tree`

**Closed-Book Question Answering: LLMs Perform Better**
Closed-book question-answering tasks require the model to answer a given question about factual knowledge without any external information, and LLMs perform better on nearly all datasets.


---

**Source:** `2023 survey & evolutionary tree`

**Scaling and Reasoning: LLMs Benefit Greatly**
With the exponential increase of model scales, LLMs become especially capable of reasoning like arithmetic reasoning and commonsense reasoning.


---

**Source:** `2023 survey & evolutionary tree`

**Emergent Abilities: Serendipity for LLM Uses**
Emergent abilities become serendipity for uses that arise as LLMs scale up, such as ability in word manipulation and logical ability.


---

**Source:** `2023 survey & evolutionary tree`

**OpenAI Leading LLM Development**
OpenAI consistently maintains its leadership position in LLM, both currently and potentially in the future. Other companies and institutions are struggling to catch up with OpenAI in developing models comparable to GPT-3 and the current GPT-4.


---

**Source:** `2023 survey & evolutionary tree`

**No-Use Cases: Performance Doesn't Always Improve with Scaling**
In many cases, performance does not steadily improve with scaling due to the limited understanding of how large language models’ abilities change as they scale up.


---

**Source:** `2023 survey & evolutionary tree`

**Regression Tasks: LLMs Generally Struggle**
LLMs generally struggle with some tasks due to differences in objectives and training data, for example, ChatGPT’s performance on the GLUE STS-B dataset, which is a regression task evaluating sentence similarity, is inferior to a fine-tuned RoBERTa performance.


---

**Source:** `2023 survey & evolutionary tree`

**LLMs: Excellent at Mimicking Humans**
LLMs are excellent at mimicking human, data annotation and generation. They can also be used for quality evaluation in NLP tasks and have bonuses like interpretability.


---

**Source:** `2023 survey & evolutionary tree`

**LLMs: Good Annotators and Data Generators**
LLMs can both act as a good annotator and data generator for data augmentation. Some LLMs have been found as good as human annotators in some tasks.


---

**Source:** `2023 survey & evolutionary tree`

**LLMs: Quality Assessment on NLG Tasks**
LLMs can also be used for quality assessment on some NLG tasks, such as summarization and translation.


---

**Source:** `2023 survey & evolutionary tree`

**Real-World Scenarios: LLMs are Better Suited**
LLMs are better suited to handle real-world scenarios compared to fine-tuned models. However, evaluating the effectiveness of models in the real world is still an open problem.


---

**Source:** `2023 survey & evolutionary tree`

**Cost Considerations: Light, Local Models May Be Better**
Light, local, fine-tuned models should be considered rather than LLMs, especially for those who are sensitive to the cost or have strict latency requirements.


---

**Source:** `2023 survey & evolutionary tree`

**Parameter-Efficient Tuning: Viable Option**
Parameter-Efficient tuning can be a viable option for model deployment and delivery.


---

**Source:** `2023 survey & evolutionary tree`

**Trustworthiness: Robustness and Calibration**
The zero-shot approach of LLMs prohibits the learning of shortcuts from task-specific datasets, which is prevalent in fine-tuned models. Nevertheless, LLMs still demonstrate a degree of shortcut learning issues.


---

**Source:** `2023 survey & evolutionary tree`

**Trustworthiness: Safety Concerns**
Safety concerns associated with LLMs should be given utmost importance as the potentially harmful or biased outputs, and hallucinations from LLMs can result in severe consequences.


---

**Source:** `2023 survey & evolutionary tree`

**Meta's Contribution to Open-Source LLMs**
Meta contributes significantly to open-source LLMs and promotes research of LLMs. Meta stands out as one of the most generous commercial companies, as all the LLMs developed by Meta are open-sourced. — Source: 2023 survey & evolutionary tree


---

**Source:** `2023 survey & evolutionary tree`

**Safety: Hallucinations**
The potential for LLMs to "hallucinate," or generate nonsensical or untruthful content, can have significant negative impacts on the quality and reliability of information in various applications.


---

**Source:** `2023 survey & evolutionary tree`

**Safety: Harmful Content**
Due to the high coherence, quality, and plausibility of texts generated by LLMs, harmful contents from LLMs can cause significant harm, including hate speech, discrimination, incitement to violence, false narratives, and even social engineering attack.


---

**Source:** `2023 survey & evolutionary tree`

**Safety: Privacy**
LLMs can face serious security issues, an example is the issue of user privacy.


---

**Source:** `2023 survey & evolutionary tree`

**LLMs Exhibiting a Tendency Towards Closed-Sourcing**
In the early stages of LLM development (before 2020), the majority of models were open-sourced. However, with the introduction of GPT-3, companies have increasingly opted to close-source their models. — Source: 2023 survey & evolutionary tree


---

**Source:** `2023 survey & evolutionary tree`

**Encoder-Decoder Models Remain Promising**
Encoder-decoder models remain promising, as this type of architecture is still being actively explored, and most of them are open-sourced. Google has made substantial contributions to open-source encoder-decoder architectures. — Source: 2023 survey & evolutionary tree


---

**Source:** `2023 survey & evolutionary tree`

**Key Capability: Generalization with Limited Data**
Employ the exceptional generalization ability of LLMs when facing out-of-distribution data or with very few training data.


---

**Source:** `2023 survey & evolutionary tree`

**Key Capability: High-Quality Text Generation**
Utilize LLMs’ capabilities to create coherent, contextually relevant, and high-quality text for various applications.


---

**Source:** `2023 survey & evolutionary tree`

**Key Capability: Leveraging Extensive Knowledge**
Leverage the extensive knowledge stored in LLMs for tasks requiring domain-specific expertise or general world knowledge.


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Startup Surge in Generative AI**
Y Combinator startups focused on AI have dramatically increased, indicating a strong interest and investment in the field. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Platform Shifts Reset the Tech Industry**
Historically, new platforms like PCs, the web, smartphones, and the cloud have emerged every 10-15 years, reshaping the tech landscape. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**S-Curve Adoption of New Technologies**
New technologies typically progress from initial skepticism to excitement and eventually to widespread adoption and perceived "boringness." — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Machine Learning's Maturation**
After a decade of development, machine learning is transitioning towards a mature and widely adopted technology. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Generative ML: Pattern Creation or Reasoning?**
The core functionality of generative ML is still being debated, with possibilities including pattern creation, synthesis, summary, or even reasoning. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**"Artificial intelligence is whatever hasn’t been done yet"**
Larry Tesler's quote highlights the evolving definition of AI as technology advances. — Larry Tesler, early 1970s


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Generative ML: Infinite Interns**
Generative AI can be viewed as providing "infinite interns," capable of assisting with various tasks. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Early Use Cases for Generative AI**
Early wins for generative AI include code assistants, brainstorming tools, autosuggest features, and synthesis capabilities. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**LLMs in Text Boxes**
The integration of Large Language Models (LLMs) into text boxes across the internet is expected to become commonplace. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Amazon's Generative AI Exploration**
Every team at Amazon is exploring generative AI applications. — Amazon CEO


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Platform Shift Value Capture**
In a platform shift, incumbents may integrate the new technology as a feature, while startups may leverage it to unbundle existing services. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Venture Capital Flows into AI Software**
Despite a slowdown in overall tech venture investments, AI software continues to attract significant funding. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**"There are two ways to make money. You can bundle, or you can unbundle"**
Jim Barksdale's quote emphasizes the fundamental strategies for value creation in technology. — Jim Barksdale


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**New Tools Change the Nature of Work**
New technologies initially fit existing workflows, but eventually, they transform the nature of the work itself. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Platform Shifts Change Everything**
Platform shifts have the potential to change everything, creating new kinds of building blocks that go further than expected. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**New Gatekeepers in AI**
New channels and platforms created by AI can lead to new points of control and leverage. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Generative AI and Search**
Generative AI may impact search, potentially leading to the end of traditional links. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Beware of Extrapolation with Generative AI**
Generative AI is currently presented as chatbots, but this may not be the only or best model for its application. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Generative ML Results Can Be Misleading**
Generative ML results are very likely to look correct, and that can be persuasive if you’re not careful. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Generative AI is Not a Database**
Generative AI is probabilistic, trained on vast amounts of data, and good at tasks computers are traditionally bad at; it's not a database, Napster, or predictable. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Machine Learning: Automated Learning**
Instead of explicitly programming computers, machine learning involves giving them data and allowing them to learn patterns. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**The Blank Canvas Problem**
A challenge with general-purpose AI is the "blank canvas problem" - knowing what to ask or what to do with its capabilities. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**"In my lifetime, I’ve seen two demonstrations of technology that struck me as revolutionary… the GUI and ChatGPT"**
Bill Gates highlights the transformative potential of ChatGPT alongside the graphical user interface (GUI). — Bill Gates, March 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Bundling vs. Unbundling with LLMs**
It's unclear whether LLMs will lead to the consolidation of apps or an explosion of new, specialized applications. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Product Paradox with General-Purpose AI**
It's uncertain whether general-purpose AI will result in general-purpose tools or require single-purpose products with specific tooling and UX. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**AGI as a Thought Experiment**
"Artificial General Intelligence" is as much a thought experiment as it is a technology goal. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Understanding in LLMs: Three Views**
Opinions vary on whether LLMs can achieve true "structural understanding," with some believing it will emerge with scale, others that scale will make it irrelevant, and others that unknown breakthroughs are needed. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Measuring AI: What Are We Benchmarking?**
It's important to consider whether AI should be benchmarked against tasks people are good at or tasks people are bad at. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Uncertainty Around AGI**
We lack a clear understanding of what AGI is, how far away it is, or how to achieve it. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Regulatory Questions and Externalities**
AI adds complexity to existing regulatory questions related to privacy, competition, harmful content, and intellectual property. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Software's Impact on Non-Software Questions**
As software continues to "eat the world," many of the important questions are no longer purely software-related but span various industries. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**The Great Model Boom of 2023**
Following OpenAI's breakthrough, numerous projects are competing to develop and improve AI models, leading to a proliferation of options. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**GPU Compute Capacity Demand**
Nvidia's revenue from its data center segment, driven by GPU sales, is rapidly increasing, reflecting the high demand for compute power for AI. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Hyperscaler Infrastructure Investment**
The "big three" cloud platforms (Microsoft, AWS, Alphabet) are projected to spend a combined $100 billion on infrastructure, partly driven by AI demands. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**Corporate Interest in Generative AI**
A McKinsey survey indicates significant interest in generative AI among corporate management across various industries. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**OpenAI's Rapid Growth**
OpenAI has achieved 100 million weekly active ChatGPT users and $1.3 billion in revenue. — Benedict Evans, December 2023


---

**Source:** `2024+AI+and+Everything+Else+1.1`

**AI as a Platform Shift**
Generative AI is considered by many in the tech industry to be a new platform shift, potentially changing the nature of software. — Benedict Evans, December 2023


---

**Source:** `2302.06590`

**Supporting Fact: Completion Time Reduction**
The treatment group (with Copilot) had an average task completion time of 71.17 minutes, compared to 160.89 minutes for the control group. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Key Finding: Potential for Skill Initiatives**
The productivity benefits for novice programmers and older programmers suggest opportunities for skill initiatives that support job transitions into software development. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Measuring Success: Task Success Rate**
Task success rate, measured as the percentage of participants who adequately completed the task, was a secondary metric, though the difference between groups was not statistically significant. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Supporting Fact: Experiment Demographics**
The majority of participants were in the 25-34 age group, from India and Pakistan, with relatively lower income but high education levels. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Critical Capability: Understanding Heterogeneous Effects**
Buy-side firms should consider how AI tools may impact different employee segments (e.g., experience levels, age groups) differently and tailor training and support accordingly.


---

**Source:** `2302.06590`

**AI Roadmap: Further Research Needed**
Further research is needed to understand how the productivity benefits of AI tools generalize to other tasks, programming languages, and the impact on code quality. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Key Finding: Heterogeneous Benefits of Copilot**
Less experienced programmers, developers with heavy coding loads, and developers aged 25-44 benefited more from using GitHub Copilot. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Critical Capability: Experiment Design**
The study used a controlled experiment with random assignment to treatment and control groups, a standardized task (HTTP server implementation in JavaScript), and precise measurement of task completion time via GitHub Classroom.


---

**Source:** `2302.06590`

**Measuring Success: Task Completion Time**
Task completion time, measured from the start to the successful completion of all test suite checks, served as a primary KPI for evaluating productivity. — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**AI Roadmap: Experimentation and Measurement**
The study highlights the importance of controlled experiments for accurately measuring the productivity impact of AI tools in software development.


---

**Source:** `2302.06590`

**Key Quote: Productivity Impact**
"Our results suggest that Copilot has statistically and practically significant impact on productivity: the treated group that has access to GitHub Copilot was able to complete the task 55.8% faster than the control group." — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Supporting Fact: Willingness to Pay**
The treated group (with Copilot experience) showed a statistically significant higher willingness to pay for GitHub Copilot ($27.25/month) compared to the control group ($16.91/month). — Peng, Kalliamvakou, Cihon, Demirer (2023)


---

**Source:** `2302.06590`

**Decisions about what technology and workflows to implement**
The study used GitHub Classroom to administer the task, track progress, and automatically run test suites, providing a structured environment for measuring developer performance.


---

**Source:** `2302.06590`

**Best Practices: Controlled Experimentation**
The study emphasizes the value of using controlled experiments with standardized tasks to obtain precise measurements of productivity when evaluating AI tools.


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Conventional Software vs. LLMs**
Unlike conventional software created with explicit instructions, LLMs are built on neural networks trained with billions of words, making their inner workings less transparent. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Attention Mechanism: Matchmaking for Words**
The attention mechanism in transformers allows words to "look around" for other words with relevant context and share information. Each word creates query and key vectors to find the best matches. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Attention Heads Focus on Different Tasks**
Each attention layer has multiple "attention heads" that focus on different tasks, such as matching pronouns with nouns, resolving homonyms, or linking two-word phrases. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Feed-Forward Step Predicts the Next Word**
After the attention heads transfer information, a feed-forward network "thinks about" each word vector and tries to predict the next word, analyzing each word in isolation. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Feed-Forward Layers Use Pattern Matching**
Feed-forward layers work by pattern matching, with each neuron in the hidden layer matching a specific pattern in the input text. Patterns become more abstract in later layers. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Feed-Forward Layers Reason with Vector Math**
Feed-forward layers can use vector arithmetic to reason by analogy and predict the next word (e.g., Berlin - Germany + France = Paris). — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Attention Heads vs. Feed-Forward Layers**
Attention heads retrieve information from earlier words in a prompt, while feed-forward layers enable language models to "remember" information that's not in the prompt. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Feed-Forward Layers as a Database**
Feed-forward layers can be thought of as a database of information the model has learned from its training data. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**LLMs Learn from Unlabeled Data**
LLMs learn by trying to predict the next word in ordinary passages of text, eliminating the need for explicitly labeled data. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Training Adjusts Weight Parameters**
During training, the model's weight parameters are gradually adjusted to make better predictions. The training algorithm increases or decreases the language model’s weight parameters to control how information flows through the neural network. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Scale Drives Performance**
The surprising performance of LLMs is partly due to scale, with models like GPT-3 trained on a corpus of approximately 500 billion words. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Incomplete Understanding of LLMs**
No one fully understands the inner workings of LLMs, and gaining a better understanding is a slow process that could take years or decades. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Performance Scales with Model Size**
OpenAI reported that the accuracy of its language models scaled "as a power-law with model size, dataset size, and the amount of compute used for training." — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Emergent Reasoning Capabilities**
Language models appear to spontaneously develop high-level reasoning capabilities, such as theory of mind, as they increase in size. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Debate on Understanding**
There is a debate about whether LLMs truly understand the meanings of the words in their training set or are simply "stochastic parrots" that repeat increasingly complex word sequences. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Focus on Empirical Performance**
It is important to focus on the empirical performance of LLMs, regardless of whether they understand language in the same way that people do. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Prediction and Biological Intelligence**
Prediction may be foundational to biological intelligence, with the human brain acting as a "prediction machine." — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Word Vectors Represent Words as Numbers**
LLMs represent words using word vectors, which are long lists of numbers. Similar words are placed closer together in an imaginary "word space." — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Word Vectors Enable Reasoning**
Representing words as vectors allows for mathematical operations that reveal relationships between words, such as analogies (e.g., "biggest" - "big" + "small" = "smallest"). — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Word Vectors Reflect Human Biases**
Word vectors are built from human language and can reflect biases present in that language (e.g., "doctor minus man plus woman" yields "nurse"). Mitigating these biases is an active area of research. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**LLMs Handle Multiple Word Meanings**
LLMs can represent the same word with different vectors depending on the context, allowing them to differentiate between homonyms (unrelated meanings) and polysemy (closely related meanings). — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**LLMs Resolve Ambiguities Based on Context**
LLMs use word vectors to represent each word's precise meaning in the context of a particular passage, resolving ambiguities based on understanding facts about the world. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Transformers Clarify Word Meaning**
Each layer of an LLM is a transformer that takes a sequence of vectors as input and adds information to clarify the meaning of each word and predict the next word. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Transformer Layers Focus on Different Tasks**
Early transformer layers focus on understanding syntax and resolving ambiguities, while later layers develop a high-level understanding of the passage as a whole. — [Timothy B. Lee and Sean Trott, Ars Technica]


---

**Source:** `AI and indsutrial org`

**Key Finding: Upskilling Trend with AI Adoption**
AI investments are associated with a general upskilling trend, with firms increasing their shares of workers with bachelor's, master's, and doctoral degrees.


---

**Source:** `AI and indsutrial org`

**Critical Capability: Measuring Firm-Level AI Investments**
Accurately measuring firm-level AI investments is crucial for understanding the impact of AI on workforce composition. The study uses a novel measure based on firms' AI-skilled human capital.


---

**Source:** `AI and indsutrial org`

**Critical Capability: Granular Data on Labor Composition**
Access to granular data on firms' labor composition and organization, including educational backgrounds and hierarchical positions, is essential for in-depth empirical analysis.


---

**Source:** `AI and indsutrial org`

**Decisions: Excluding Tech Sector Firms**
The study excludes firms in the tech sectors (2-digit NAICS 51 or 54) to focus on the impact of AI on AI-using firms rather than AI-producing firms.


---

**Source:** `AI and indsutrial org`

**AI Roadmap: Gradual Accumulation of AI Investments**
AI investments accumulate gradually over time and generate effects that are not immediate, making a long-differences strategy well-suited for analysis.


---

**Source:** `AI and indsutrial org`

**Best Practice: Long-Differences Regression**
Using long-differences regressions (changes from 2010 to 2018) helps ensure that time-invariant firm characteristics do not drive the results.


---

**Source:** `AI and indsutrial org`

**Measuring Success: Metrics for AI Programs**
Success can be measured by the changes in workforce composition, such as the increase in STEM workers or the flattening of the hierarchy, associated with AI investments.


---

**Source:** `AI and indsutrial org`

**Key Quote: AI as Prediction Technology**
"AI is a prediction technology, and predictions are at the heart of decision-making under uncertainty...making AI applicable to solve a variety of business problems with different potential effects on labor." — [Babina, Fedyk, He, and Hodson]


---

**Source:** `AI and indsutrial org`

**Key Quote: AI and Upskilling**
"While Babina et al. (2021) show that AI investments increase total firm employment, our evidence further shows that this increase is concentrated in highly-educated workers and high-skill workers with STEM backgrounds and IT skills." — [Babina, Fedyk, He, and Hodson]


---

**Source:** `AI and indsutrial org`

**Key Quote: AI and Organizational Structure**
"We find that firms investing in AI technologies become less top-heavy, which is similar to the previously-documented effect of IT but opposite to the effect of communication technologies." — [Babina, Fedyk, He, and Hodson]


---

**Source:** `AI and indsutrial org`

**Key Finding: Demand for Technical Skills Increases with AI**
AI investments are associated with a significant increase in the share of employees with STEM degrees and a corresponding decline in social science degrees.


---

**Source:** `AI and indsutrial org`

**Key Finding: AI Investments Flatten Hierarchies**
AI investments are associated with firms becoming flatter, with higher shares of employees in entry-level roles and fewer in middle-management or senior roles.


---

**Source:** `AI and indsutrial org`

**Supporting Fact: Magnitude of Hierarchy Flattening**
A one-standard-deviation change in the share of AI workers is associated with a 1.6% increase in the share of junior employees, a 0.8% decline in middle management, and a 0.7% decline in senior management.


---

**Source:** `AI and indsutrial org`

**Supporting Fact: Education Increase with AI**
A one-standard-deviation increase in the firm's share of AI workers translates into a 3.7% increase in workers with associate's or bachelor's degrees, a 2.9% increase in master's degrees, and a 0.6% increase in doctoral degrees.


---

**Source:** `AI and indsutrial org`

**Supporting Fact: Decline in Non-College Educated Workers**
The increases in educated workers correspond to a 7.2% decline in the share of workers without a college education.


---

**Source:** `AI and indsutrial org`

**Supporting Fact: AI Investments Increase Required Education**
A one-standard-deviation increase in the share of AI workers is associated with a 0.5 additional year of required education in the firm's new job openings.


---

**Source:** `AI and indsutrial org`

**Supporting Fact: Industry Coverage of Cognism Data**
The Cognism resume data captures 42% of all U.S. employment in 2010, increasing to 63% in 2018, with an average coverage of 53% across these years.


---

**Source:** `AI and indsutrial org`

**Supporting Fact: Public Firms in Cognism Data**
The sample of 120 million person-firm-years matched to U.S. public firms corresponds to 19 million distinct individual employees.


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Agentic Workflows Enhance Automation**
Agentic workflows, where AI agents can plan, reason, use tools, and revise their plans, offer a more sophisticated approach to automation compared to traditional scripted or LLM-only workflows. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Risk Mitigation: Human in the Loop**
Incorporating human oversight in AI workflows ensures ethical decision-making, improves accountability, enhances accuracy, facilitates adaptation to context, and manages unforeseen risks. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Risk Mitigation: Responsible AI Frameworks**
Implementing Responsible AI (RAI) frameworks is crucial for mitigating risks associated with AI systems. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Assessing AI Risks: Key Questions**
When assessing AI risks, consider the system's purpose, potential misuse, all stakeholders, data profiles, and clear accountability responsibilities. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Microsoft Responsible AI Transparency Report Metrics**
The Microsoft Responsible AI Transparency Report includes metrics for measuring groundedness, relevance, similarity, content risks, and jailbreak success rate. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Elements of AI Governance**
Key elements of AI governance include a Generative AI Governance Framework, data privacy and security measures, and regulatory compliance protocols. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Overcoming Resistance to Gen AI: Expectation Management**
Overcoming resistance to GenAI requires realistic communication about its capabilities and limitations, balancing innovation with risk tolerance, and cross-disciplinary conversations. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Overcoming Resistance to Gen AI: Education & Training**
Training teams on the effective use of LLMs, understanding their outputs, and maintaining human oversight are crucial for successful adoption. Training should be persistent and ongoing. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Overcoming Resistance to Gen AI: Cultural Adaptation**
Fostering a culture that balances the value of AI with human review, involving employees early, and leveraging champions are key to cultural adaptation. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Best Practice: AI Center of Excellence**
Establish an AI Center of Excellence (CoE) with a robust framework supported by essential pillars to ensure a comprehensive, innovative, and ethical approach to AI. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Best Practice: Strategic Alignment**
Align AI initiatives with overall business objectives, ensuring AI solutions address specific problems or improve processes, and focus on value generation and measurable business impact. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**GenAI Use Cases: Client Engagement**
Generative AI can personalize client communications, generate tailored content, and provide deep, holistic insights for client engagement. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Best Practice: AI Roadmap**
Develop a strategic AI roadmap to identify areas where AI can be applied most effectively, define value-add opportunities, and prioritize initiatives. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Best Practice: Data Governance and Quality**
Ensure access to quality, structured, and unstructured data, create transparent data pipelines, and establish clear governance rules for securing and protecting data. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Best Practice: Regulatory Standards**
Stay up-to-date with evolving AI regulations, ensure compliance with legal requirements like algorithmic transparency, and address ethical concerns, including anti-discrimination laws. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Takeaway: Data Curation Matters**
Data curation is extremely important for successful AI implementation. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Takeaway: GenAI is Not a Silver Bullet**
GenAI is not a universal solution; choose the right tool for the specific task. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Takeaway: Encourage Experimentation**
Foster a culture of experimentation to explore the potential of AI. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Takeaway: Engage Teams Early**
Involve teams early in the AI implementation process. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Takeaway: Follow a Responsible AI Framework**
Adhere to a Responsible AI framework to mitigate risks and ensure ethical AI practices. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Key Takeaway: Build an AI Center of Excellence**
Establish an AI Center of Excellence to drive AI innovation and adoption. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Next Steps: Pilot Projects**
Launch pilot projects to test generative AI safely. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**GenAI Use Cases: Documentation & Reporting**
Generative AI can streamline legal and compliance documentation, internal reports, and investment memo creation, as well as synthesize financial information. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Next Steps: Governance Structures**
Establish governance structures around the use of LLMs. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Next Steps: Stakeholder Engagement**
Engage stakeholders and internal teams in education and expectation management for generative AI. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**GenAI Use Cases: Research & Market Analysis**
Generative AI can analyze market trends, generate insights from unstructured data, and summarize research data for improved market analysis. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Common LLM Concerns: Data Security**
Key concerns surrounding LLMs include vendor selection, model location, the use of proprietary data for training, and the protection of sensitive data. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Generative AI-Specific Risks: Model Risk**
Model risk includes a lack of explainability in model outputs, data quality and integrity issues, and challenges related to generalization and model drift. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Generative AI-Specific Risks: Operational Risk**
Operational risks include system failures, downtime, model maintenance and updates, and dependencies on vendors or third parties. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Generative AI-Specific Risks: Reputational Risk**
Reputational risks include content accuracy, misinformation, intellectual property infringement, and the potential for deepfakes and manipulated data. — AITEC_Workshop_GenAI20241017


---

**Source:** `AITEC_Workshop_GenAI20241017`

**Generative AI-Specific Risks: Bias & Hallucinations**
Bias and hallucination risks involve the amplification of data and social biases, hallucinations in conversational AI, and inaccuracies in decision support systems. — AITEC_Workshop_GenAI20241017


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Only 12% are AI Achievers**
Only 12% of surveyed organizations are considered "AI Achievers," demonstrating superior growth and business transformation through advanced AI maturity. — Accenture Research


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Focusing Beyond Financial Metrics**
Achievers develop strong relationships with customers—by building trust, reducing churn and boosting the quality and safety of offerings.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Sustainability Commitment**
Achievers double down on their commitment to sustainability by, for instance, rigorously measuring and reducing their greenhouse gas emissions, consuming water and other natural resources more economically and using AI responsibly.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Five Success Factors for AI Achievers**
The five key success factors for AI Achievers are: championing AI as a strategic priority, investing heavily in talent, industrializing AI tools and teams, designing AI responsibly, and prioritizing long- and short-term AI investments.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**CEO Sponsorship Critical**
83% of Achievers have formal senior sponsorship for their AI strategies, while only 67% of Builders and just 56% of Experimenters have it.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Culture of Innovation**
48% of Achievers embed innovation in their organizational strategies, while just 33% of Experimenters do.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Mandatory AI Training**
78% of Achievers have mandatory AI trainings for most employees, from product development engineers to C-suite executives.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Building an AI Core**
Another priority for Achievers involves building an AI core: an operational data and AI platform that taps into companies’ talent, technology and data ecosystems, allowing firms to balance experimentation and execution.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Responsible AI by Design**
Achievers are 53% more likely, on average, than Builders and Innovators to be responsible by design: designing, developing and deploying AI with good intention to empower employees and businesses, and to fairly impact customers and society—allowing companies to engender trust and scale AI with confidence.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Prioritizing AI Investment**
In 2018, Achievers devoted 14% of their total technology budgets to AI, while in 2021 they devoted 28%. In 2024, they plan to devote 34%.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**AI Achievers to Double by 2024**
The share of AI Achievers will increase rapidly and significantly, more than doubling from the current 12% to 27% by 2024.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**AI Achievers Outperform**
Pre-pandemic (2019), AI Achievers already enjoyed 50% greater revenue growth on average, compared with their peers. — Accenture Research


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**AI Maturity Assessment Questions**
C-suite leaders should ask questions about accountability for data and AI strategy, value identification, resource allocation, cloud platform support, data platform effectiveness, data science team utilization, AI literacy strategy, talent model, innovation culture, responsible AI framework, and tracking AI-related laws and regulations.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**AI Transformation Faster Than Digital**
AI transformation is projected to occur on average 16 months faster than digital transformation.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**AI-Influenced Revenue Tripling**
The share of companies' revenue that is "AI-influenced" more than doubled between 2018 and 2021 and is expected to roughly triple between 2018 and 2024. — Accenture Research


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Increased AI Investment**
In 2021, 19% of companies dedicated >30% of their tech budgets to AI development. By 2024, 49% of companies intend to.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Key Capability Combinations**
AI maturity comes down to mastering a set of key capabilities in the right combinations—not only in data and AI, but also in organizational strategy, talent and culture—to give companies a strong competitive advantage.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Foundational vs. Differentiation AI Capabilities**
AI maturity requires both foundational capabilities (cloud platforms, data governance) and differentiation capabilities (AI strategy, C-suite sponsorship, innovation culture).


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**AI Achievers' Multitasking Mastery**
AI Achievers demonstrate high performance across a combination of capabilities, excelling in strategy, processes, and people, rather than just one area.


---

**Source:** `Accenture-Art-of-AI-Maturity-Report-Global-Revised`

**Turning Pilots into Production**
Achievers are 25% more likely to scale AI pilots across the enterprise compared with Experimenters.


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Key Finding: Automated Prompt Engineering (APE) Automates Prompt Optimization**
APE automates the process of generating and refining prompts for LLMs to improve performance on specific tasks, similar to automated hyperparameter optimization in traditional ML. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Critical Capability: Meta-Prompt Engineering**
Crafting an effective meta-prompt is crucial for guiding the optimizer LLM in APE, combining the optimization goal, task examples, and the history of previous prompts and their performance. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Decisions about what technology and workflows to implement: Model Selection**
The author recommends using a fast and cost-effective model like Gemini 1.5 Flash as the target LLM, a more powerful model like Gemini 1.5 Pro as the optimizer LLM, and Gemini 1.5 Flash again as the evaluation LLM. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Best Practice: Test Optimized Prompts on Unseen Data**
It's crucial to test the best-performing prompt on unseen test data to ensure its effectiveness generalizes beyond the training data. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Key Capability: Exemplar Selection**
Exemplar selection, which aims to find the best few-shot examples for a given task, can further enhance the effectiveness of an optimized prompt. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

```


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Key Finding: APE Can Unlock Significant Performance Gains**
APE allows for the exploration of a wider range of prompt designs, often leading to unexpected approaches and significant performance improvements compared to manual methods. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Key Finding: LLMs Can Be Used to Evaluate LLM Responses**
LLMs can be effectively used to evaluate other LLMs' responses, especially when the evaluation task is independent and within the evaluator LLM's capabilities. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Critical Capability: APE Workflow Requires Labeled Data, Initial Prompt, and Evaluation Metric**
To implement APE, you need a labeled dataset representative of the task, an initial prompt, and an evaluation metric to optimize against. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**AI Roadmap: APE Workflow Steps**
The APE workflow involves starting with an initial prompt and dataset, generating responses from the target LLM, evaluating those responses against ground truth, optimizing the prompt using an optimizer LLM, and repeating the process iteratively until satisfactory performance is achieved. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Decisions about what technology and workflows to implement: OPRO Strategy**
OPRO (Optimisation by PROmpting) leverages results from previous iterations to actively hill climb against the evaluation metric, using a meta-prompt to guide the optimizer LLM based on the optimization trajectory. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Best Practice: Use Asynchronous Programming to Speed Up APE**
Leveraging asynchronous programming allows for sending multiple requests to the Gemini API simultaneously, speeding up the evaluation process. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Supporting Fact & Figure: APE Achieved Significant Accuracy Improvement**
Implementing APE with the OPRO algorithm boosted accuracy on the geometric_shapes task from a baseline of 49% to 85% on an unseen test dataset. — [Heiko Hotz]


---

**Source:** `Automated Prompt Engineering_ The Definitive Hands-On Guide _ by Heiko Hotz _ Sep, 2024 _ Towards Data Science`

**Key Quote: APE as a Game-Changer**
"That’s why, in my opinion, APE is starting to emerge as a game-changer, enabling us to harness the power of automation to optimise prompts and unlock the full potential of LLMs." — [Heiko Hotz]


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Key Finding: Deceleration of Labor Demand Growth**
The US has experienced a slowdown in labor demand growth over the last three decades, with near-stagnation in the last two, due to weaker productivity growth and shifts in the task content of production against labor. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**US Labor Demand Since WWII: 1947-1987**
From 1947 to 1987, rapid wage bill growth was largely driven by productivity gains, with small substitution and composition effects. Displacement and reinstatement effects were substantial but balanced each other out. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**US Labor Demand Since WWII: 1987-2017**
From 1987 to 2017, labor demand growth slowed significantly due to weaker productivity growth and a negative shift in the task content of production against labor, driven by accelerated automation and decelerating reinstatement. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Evidence for Automation and New Task Measures**
Industry-level measures of automation technologies (e.g., robot penetration, share of routine jobs) are negatively correlated with changes in the task content of production in favor of labor, while measures of new tasks (e.g., share of new job titles) are positively correlated. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Policy Implications: Addressing Imbalances**
If the balance between automation and new tasks has shifted inefficiently, policy interventions may be needed to remove incentives for excessive automation and rebalance the direction of technological change. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Future of Work Depends on Task Creation**
The future of work depends on the creation of new tasks and other technologies that raise the labor intensity of production and the labor share, ensuring continued wage growth commensurate with productivity growth. — Acemoglu and Restrepo
```


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Reinstatement Effect Counterbalances Automation**
Historically, the displacement effect of automation has been counterbalanced by technologies that create new tasks in which labor has a comparative advantage, leading to a "reinstatement effect" that increases labor demand. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Task Content of Production**
The "task content of production" refers to the allocation of tasks to capital or labor. Shifts in this allocation can significantly impact labor demand and productivity. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Automation's Impact on Labor Share**
Automation always reduces the labor share in industry value added, regardless of the elasticity of substitution between capital and labor. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**New Tasks Increase Labor Share**
The introduction of new tasks in which labor has a comparative advantage always increases the labor share. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Productivity Effect of Automation Depends on Wages**
The productivity effect of automation is stronger when wages are high and labor is scarce, as the cost savings from substituting capital for labor are greater. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Factor-Augmenting Technologies vs. Automation/New Tasks**
Factor-augmenting technologies (making labor or capital more productive in existing tasks) primarily affect labor demand through the productivity effect, while automation and new tasks also have significant displacement and reinstatement effects. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Composition Effect in Multi-Sector Economy**
In a multi-sector economy, automation in one sector can reallocate economic activity to other sectors, creating a "composition effect" that impacts aggregate labor demand depending on the labor intensity of the expanding and contracting sectors. — Acemoglu and Restrepo


---

**Source:** `Automation and New Tasks - How Technology Displace`

**Decomposition of Wage Bill Changes**
Changes in the aggregate wage bill can be decomposed into productivity, composition, substitution, and task content effects, allowing for analysis of the drivers of labor demand. — Acemoglu and Restrepo


---

**Source:** `Best Practices for RAG pipelines`

**Query Classification Determines Retrieval Need**
Query classification checks if the user's question requires document retrieval, as LLMs have built-in knowledge that may suffice. Retrieval is needed when the answer is outside the model's knowledge.


---

**Source:** `Best Practices for RAG pipelines`

**Query Classification Improves RAG Effectiveness and Efficiency**
Implementing a query classification module increases RAG effectiveness and efficiency, improving the average score from 0.428 to 0.443 and reducing latency from 16.41 seconds to 11.58 seconds.


---

**Source:** `Best Practices for RAG pipelines`

**Hybrid Retrieval Balances Performance and Latency**
While "Hybrid with HyDE" achieves the highest RAG score (0.58), it has a high computational cost; using "Hybrid" or "Original" methods is recommended to balance performance and latency.


---

**Source:** `Best Practices for RAG pipelines`

**Re-Ranking is Crucial for Relevance**
The absence of a re-ranking module leads to a significant performance drop, highlighting its importance for relevance. MonoT5 achieved the highest average score in re-ranking.


---

**Source:** `Best Practices for RAG pipelines`

**Re-Packing with Reverse Configuration Improves Results**
The reverse configuration in the re-packing module, which places more relevant context closer to the query, achieved a RAG score of 0.560.


---

**Source:** `Best Practices for RAG pipelines`

**Recomp is the Preferred Summarization Method**
Recomp demonstrated superior performance in summarization. Removing the summary module can yield comparable results with lower latency, but Recomp remains preferred for handling the generator's maximum length limitation.


---

**Source:** `Best Practices for RAG pipelines`

**Document Chunking Improves Retrieval Accuracy**
Document chunking improves retrieval accuracy and helps handle length limitations in LLMs. Sentence-level chunking is often favored for its balance of meaning preservation and simplicity.


---

**Source:** `Best Practices for RAG pipelines`

**Embedding Model Selection Balances Performance and Resources**
Choosing the right embedding model is key for balancing performance and resource use; LLM-Embedder offers a good balance of effectiveness and efficiency. Enhancing chunk blocks with metadata like titles and keywords can further improve retrieval.


---

**Source:** `Best Practices for RAG pipelines`

**Milvus Excels as a Vector Database**
Among vector databases like Weaviate, Faiss, Chroma, and Qdrant, Milvus stands out for its superior performance and comprehensive feature set.


---

**Source:** `Best Practices for RAG pipelines`

**HyDE + Hybrid Search for Optimal Retrieval**
Using HyDE (Pseudo-Document Generation) combined with hybrid search (integrating BM25 and LLM embeddings) is recommended as the default retrieval method for balanced performance and low latency.


---

**Source:** `Best Practices for RAG pipelines`

**Re-Ranking Improves Document Relevance**
Re-ranking refines document relevance after initial retrieval, and its absence leads to a significant performance drop. MonoT5 is recommended for a balance of performance and efficiency in re-ranking.


---

**Source:** `Best Practices for RAG pipelines`

**Re-Packing Optimizes Document Order for LLM Response**
The re-packing module optimizes document order after re-ranking to ensure effective LLM response generation. A reverse configuration, placing more relevant context closer to the query, yields better results.


---

**Source:** `Best Practices for RAG pipelines`

**Summarization Reduces Redundancy and Prevents Long Prompts**
Summarization reduces redundancy and prevents long prompts from slowing down inference in LLMs. Recomp is the preferred summarization method, with LongLLMLingua as an alternative.


---

**Source:** `Best Practices for RAG pipelines`

**Fine-Tuning with Mixed Contexts Improves Generator Performance**
Fine-tuning the generator with a mix of relevant and random documents (Mgr) shows the best performance with gold or mixed context.


---

**Source:** `Brynjolfsson-2023`

**Supporting Fact: AI Impact Greatest on Novice Workers**
The productivity gains from AI assistance were most significant for novice and low-skilled workers, with minimal impact on experienced and highly skilled agents. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Doesn't Impact Customer Satisfaction**
AI assistance doesn't lead to any economically significant change in customer satisfaction, as measured by net promoter scores. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Adherence Matters**
Returns to AI model deployment tend to be higher among agents who follow a greater share of recommendations. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Changes Communication Patterns**
AI assistance leads lower-skill agents to communicate more like high-skill agents. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Measuring Success: Resolutions Per Hour (RPH)**
Resolutions per hour (RPH), the number of chats that a worker is able to successfully resolve per hour, is the most effective summary of a worker’s productivity at the firm.


---

**Source:** `Brynjolfsson-2023`

**Measuring Success: Average Handle Time (AHT)**
Average handle time (AHT), the average length of time an agent takes to finish a chat, is a key metric for measuring efficiency.


---

**Source:** `Brynjolfsson-2023`

**Measuring Success: Resolution Rate (RR)**
Resolution rate (RR), the share of conversations that the agent can successfully resolve, is a key metric for measuring effectiveness.


---

**Source:** `Brynjolfsson-2023`

**Measuring Success: Net Promoter Score (NPS)**
Net promoter score (NPS), customer satisfaction, is calculated by randomly surveying customers after a chat and calculating the percentage of customers who would recommend an agent minus the percentage who would not.


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Disseminates Tacit Knowledge**
The AI model appears to disseminate the tacit knowledge of more able workers, helping newer workers move down the experience curve faster. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Supporting Fact: AI Improves Customer Sentiment**
AI assistance improved customer sentiment in chat interactions, as measured by sentiment analysis of customer messages. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Supporting Fact: AI Reduces Managerial Intervention**
The use of AI assistance reduced the number of requests for managerial intervention from customers. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Supporting Fact: AI Improves Employee Retention**
AI assistance was associated with improved employee retention, particularly for newer workers. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Critical Capability: Augment, Don't Replace**
The AI system studied is designed to augment human agents, not replace them. Agents retain full discretion over whether to incorporate AI suggestions. This is key to the success of the implementation.


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Reduces Average Handle Time**
AI assistance leads to a 3.8 minute decrease in the average duration of customer chats, a 9% decline from the baseline mean. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Increases Chats Per Hour**
AI assistance leads to a 0.37 unit increase in the number of chats that an agent can handle per hour, a roughly 14% increase. — Brynjolfsson et al. 2023


---

**Source:** `Brynjolfsson-2023`

**Key Finding: AI Increases Resolution Rate**
AI assistance leads to a small 1.3 percentage point increase in chat resolution rates. — Brynjolfsson et al. 2023


---

**Source:** `Building effective agents _ Anthropic`

**Agent Definition**
Agents are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Prompt Chaining**
Prompt chaining is ideal for tasks that can be easily decomposed into fixed subtasks, trading latency for higher accuracy. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Workflow: Routing**
Routing classifies an input and directs it to a specialized follow-up task, enabling separation of concerns and specialized prompts. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Routing**
Routing works well for complex tasks with distinct categories that are better handled separately, provided classification can be handled accurately. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Workflow: Parallelization**
Parallelization involves LLMs working simultaneously on a task, with outputs aggregated programmatically, either through sectioning (independent subtasks) or voting (multiple attempts). — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Parallelization**
Parallelization is effective when subtasks can be parallelized for speed or when multiple perspectives are needed for higher confidence results. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Workflow: Orchestrator-Workers**
In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Orchestrator-Workers**
This workflow is well-suited for complex tasks where you can’t predict the subtasks needed, and subtasks aren't pre-defined, but determined by the orchestrator based on the specific input. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Workflow: Evaluator-Optimizer**
In the evaluator-optimizer workflow, one LLM call generates a response while another provides evaluation and feedback in a loop. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Evaluator-Optimizer**
This workflow is particularly effective when there are clear evaluation criteria, and when iterative refinement provides measurable value. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Agent Characteristics**
Agents understand complex inputs, engage in reasoning and planning, use tools reliably, and recover from errors. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Workflow Definition**
Workflows are systems where LLMs and tools are orchestrated through predefined code paths. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Agent Execution**
During execution, agents gain "ground truth" from the environment at each step to assess progress, pausing for human feedback at checkpoints or when encountering blockers. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Tool Design for Agents**
It is crucial to design toolsets and their documentation clearly and thoughtfully for agents. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Agents**
Agents can be used for open-ended problems where it’s difficult or impossible to predict the required number of steps, and where you can’t hardcode a fixed path. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Agent Considerations**
The autonomous nature of agents means higher costs and the potential for compounding errors, necessitating extensive testing in sandboxed environments and appropriate guardrails. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Key to Success with LLM Features**
The key to success is measuring performance and iterating on implementations, adding complexity only when it demonstrably improves outcomes. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Core Principles for Implementing Agents**
Maintain simplicity in agent design, prioritize transparency by showing planning steps, and carefully craft the agent-computer interface (ACI) through thorough tool documentation and testing. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Customer Support Application**
Customer support combines chatbot interfaces with enhanced capabilities through tool integration, making it a natural fit for open-ended agents. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Coding Agents Application**
The software development space has shown remarkable potential for LLM features, with capabilities evolving from code completion to autonomous problem-solving. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Prompt Engineering for Tools**
Tool definitions and specifications should be given just as much prompt engineering attention as overall prompts. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Tool Format Suggestions**
Give the model enough tokens to "think", keep the format close to what the model has seen naturally occurring in text, and ensure there's no formatting "overhead". — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Agentic Systems**
Agentic systems often trade latency and cost for better task performance, making them suitable when flexibility and model-driven decision-making are needed at scale. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Agent-Computer Interface (ACI)**
Invest as much effort in creating a good ACI as you would in human-computer interfaces (HCI). — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Tool Testing and Optimization**
Test how the model uses your tools, run many example inputs to see what mistakes the model makes, and iterate. Poka-yoke your tools by changing the arguments so that it is harder to make mistakes. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**When to Use Workflows**
Workflows offer predictability and consistency for well-defined tasks. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Framework Considerations**
Frameworks can simplify initial implementation but may obscure underlying prompts and responses, making debugging harder and tempting unnecessary complexity. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Best Practice: Start Simple**
Developers should start by using LLM APIs directly, as many patterns can be implemented in a few lines of code. If using a framework, ensure a thorough understanding of the underlying code. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Building Block: Augmented LLM**
The basic building block of agentic systems is an LLM enhanced with augmentations such as retrieval, tools, and memory. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Key Implementation Aspects: Augmented LLM**
Focus on tailoring LLM capabilities to the specific use case and ensuring an easy, well-documented interface. — Anthropic


---

**Source:** `Building effective agents _ Anthropic`

**Workflow: Prompt Chaining**
Prompt chaining decomposes a task into a sequence of steps, where each LLM call processes the output of the previous one. — Anthropic


---

**Source:** `Cognitive architectures for llm agents`

**Key Finding: Language Agents as a Synthesis**
Language agents synthesize advances in LLMs with traditional agent design, mitigating LLMs' limitations in knowledge and reasoning by connecting them to memory and environments, while leveraging LLMs' commonsense priors to adapt to novel tasks.


---

**Source:** `Cognitive architectures for llm agents`

**Critical Capability: Reasoning Actions**
Reasoning actions should allow language agents to process the contents of working memory to generate new information, supporting learning and decision-making.


---

**Source:** `Cognitive architectures for llm agents`

**Critical Capability: Learning Actions**
Learning actions should write information to long-term memory, including updating episodic memory with experience, semantic memory with knowledge, LLM parameters, and agent code.


---

**Source:** `Cognitive architectures for llm agents`

**Critical Capability: Planning Stage**
During the planning stage of decision-making, reasoning and retrieval can be flexibly applied to propose, evaluate, and select actions, and these sub-stages could interleave or iterate to build up multi-step simulations before taking an external action.


---

**Source:** `Cognitive architectures for llm agents`

**Best Practice: Modular Agent Design**
Agents should be structured and modular, with standardized terms and open-source implementations to facilitate plug-and-play and re-use, reducing technical debt and standardizing the customer experience.


---

**Source:** `Cognitive architectures for llm agents`

**Best Practice: Balancing Code and LLMs**
Use code sparingly to implement generic algorithms that complement LLM limitations, such as implementing tree search to mitigate myopia induced by autoregressive generation.


---

**Source:** `Cognitive architectures for llm agents`

**Best Practice: Structured Reasoning**
Implement a more structured reasoning procedure to update working memory variables, using prompting frameworks and structural output parsing solutions.


---

**Source:** `Cognitive architectures for llm agents`

**AI Roadmap: Beyond Retrieval Augmentation**
Move beyond traditional retrieval-augmented language models by enabling memory-augmented language agents to both read and write self-generated content autonomously, opening up possibilities for efficient lifelong learning.


---

**Source:** `Cognitive architectures for llm agents`

**AI Roadmap: Meta-Learning**
Explore meta-learning by modifying agent code to allow agents to learn more effectively, such as learning better retrieval procedures.


---

**Source:** `Cognitive architectures for llm agents`

**AI Roadmap: Action Space Safety**
Specify and ablate the agent’s action space for worst-case scenario prediction and prevention, especially for "learning" and "grounding" actions that could cause internal or external harm.


---

**Source:** `Cognitive architectures for llm agents`

**AI Roadmap: Deliberative Decision-Making**
Investigate more complex decision-making employing iterative proposal and evaluation to consider multiple actions, modeled after classical planning algorithms.


---

**Source:** `Cognitive architectures for llm agents`

**Key Finding: CoALA as a Theoretical Framework**
CoALA combines theoretical framework with empirical work, grounding theory in existing practices and identifying short-term and long-term directions for future work in language agent design.


---

**Source:** `Cognitive architectures for llm agents`

**AI Roadmap: Metareasoning**
Develop mechanisms to estimate the utility of planning and modify the decision procedure accordingly, either via amortization, routing among decision sub-procedures, or updates to the decision-making procedure.


---

**Source:** `Cognitive architectures for llm agents`

**Measuring Success: Performance and Generalization**
Trade-off between performance and generalization when defining the decision-making procedure; more complex procedures can better fit a particular problem, while simpler ones are more domain-agnostic and generalizable.


---

**Source:** `Cognitive architectures for llm agents`

**Measuring Success: Safety and Alignment**
Address issues such as over-confidence, miscalibration, misalignment with human values, hallucinations in self-evaluation, and lack of human-in-the-loop mechanisms to improve LLMs' utilities as agent backbones.


---

**Source:** `Cognitive architectures for llm agents`

**Key Capability: Memory Modules**
Language agents should explicitly organize information into multiple memory modules, including short-term working memory and long-term episodic, semantic, and procedural memories, to enable multi-step interaction with the world.


---

**Source:** `Cognitive architectures for llm agents`

**Key Capability: Action Space Structure**
Agents' action spaces should be structured into internal (retrieval, reasoning, learning) and external (grounding) actions, allowing for both interaction with internal memory and external environments.


---

**Source:** `Cognitive architectures for llm agents`

**Key Capability: Decision-Making Procedure**
Language agents need a well-defined decision-making procedure, structured as an interactive loop with planning and execution, to choose actions based on reasoning and retrieval, affecting the outside world or the agent's long-term memory.


---

**Source:** `Cognitive architectures for llm agents`

**Key Quote: Reasoning Actions**
"Yet the incorporation of an LLM leads to the addition of 'reasoning' actions, which can flexibly produce new knowledge and heuristics for various purposes – replacing hand-written rules in traditional cognitive architectures."


---

**Source:** `Cognitive architectures for llm agents`

**Key Quote: Text as Internal Representation**
"It also makes text the de facto internal representation, streamlining agents’ memory modules. Finally, recent advances in vision-language models (VLMs; Alayrac et al., 2022) can simplify grounding by providing a straightforward translation of perceptual data into text (Zeng et al., 2022)."


---

**Source:** `Cognitive architectures for llm agents`

**Critical Capability: Grounding Actions**
Grounding procedures should execute external actions and process environmental feedback into working memory as text, simplifying the agent's interaction with the outside world.


---

**Source:** `Cognitive architectures for llm agents`

**Critical Capability: Retrieval Actions**
Retrieval procedures should read information from long-term memories into working memory, implemented in various ways (rule-based, sparse, or dense retrieval), to support adaptive and context-specific recall.


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Anthropic's Focus on AI Risks**
Anthropic prioritizes AI risk research to maximize leverage, avoid propaganda perceptions, prevent grandiosity, and steer clear of "sci-fi" baggage. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Intelligence Routing Around Bottlenecks**
Intelligence will initially be heavily bottlenecked by other factors of production, but over time, it will increasingly route around them, though some constraints are absolute. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Biology as a Prime Area for AI Impact**
Biology has the greatest potential to directly and unambiguously improve the quality of human life. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Challenges in Applying AI to Biology**
The main challenges are data limitations, the speed of the physical world (experiment times), and intrinsic complexity of biological systems. Human constraints (clinical trial bureaucracy) also play a role. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI as a Virtual Biologist**
The right way to think of AI is not as a method of data analysis, but as a virtual biologist who performs all the tasks biologists do, including designing and running experiments. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Key Discoveries Drive Biological Progress**
A small number of discoveries related to broad measurement tools or techniques drive a large fraction of progress in biology. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Examples of Key Biological Discoveries**
Examples include CRISPR, advanced microscopy, genome sequencing/synthesis, optogenetics, mRNA vaccines, and cell therapies like CAR-T. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Increasing the Rate of Biological Discovery**
The rate of key biological discoveries could be increased by 10x or more with more talented, creative researchers, suggesting high returns to intelligence. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI Could Accelerate Biological Progress**
Powerful AI could potentially 10x the rate of key biological discoveries, compressing 50-100 years of progress into 5-10 years. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Clinical Trial Speed and AI**
AI-enabled biology could reduce the need for iteration in clinical trials by developing better animal and cell experimental models, particularly for aging-related drugs. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Biomedical Innovations and Successful Deployment**
Biomedical innovations have a strong track record of successful deployment, in contrast to some other technologies hampered by societal factors. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Need for an Inspiring Vision of AI's Future**
It's critical to have a genuinely inspiring vision of a positive-sum future with AI, not just a plan to fight fires. Fear alone is insufficient; hope is also needed. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**"Compressed 21st Century" in Biology**
AI-enabled biology and medicine could compress the progress humans would have achieved in the next 50-100 years into 5-10 years, referred to as the "compressed 21st century." — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Potential Outcomes of AI-Accelerated Biology**
This includes reliable prevention/treatment of infectious diseases, elimination of most cancers, cures for genetic diseases, prevention of Alzheimer's, improved treatment of other ailments, biological freedom, and doubling of human lifespan. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Impact on Social Security and Medicare**
AI-driven advances in health could radically improve the solvency of programs like Social Security and Medicare by changing the ratio of working-age to retired population. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Neuroscience and Mental Health**
Mental health affects human well-being even more directly than physical health, and AI can accelerate progress in neuroscience similarly to biology. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI's Contribution to Neuroscience**
AI can accelerate neuroscientific progress through traditional molecular biology, fine-grained neural measurement/intervention, advanced computational neuroscience, and behavioral interventions. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Potential Outcomes in Neuroscience**
This includes curing most mental illnesses, effective genetic prevention of mental illness, solving everyday psychological problems, and improving human baseline experience. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Economic Development and Poverty**
AI should help the developing world catch up to the developed world, and failure to do so would be a moral failure. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Challenges in Applying AI to Economic Development**
The economy involves human constraints and intrinsic complexity, making it harder to apply AI compared to technology development. Corruption also complicates matters. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Optimism for AI in Economic Development**
Diseases have been eradicated and countries have gone from poor to rich, suggesting high returns to intelligence in these tasks, making AI potentially beneficial. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI for Distributing Health Interventions**
AI can optimize the distribution of health interventions globally, potentially eradicating diseases through top-down campaigns and logistical optimization. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Five Key Areas for AI to Improve Human Life**
The author focuses on biology/physical health, neuroscience/mental health, economic development/poverty, peace/governance, and work/meaning as areas where AI can significantly improve life quality. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Economic Growth in the Developing World**
AI finance ministers and central bankers could replicate or exceed the 10% annual GDP growth rates achieved by East Asian economies. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI and Food Security**
AI can drive a second Green Revolution through advances in crop technology and efficient agricultural supply chains. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI and Climate Change Mitigation**
AI can lead to improvements in technologies that slow or prevent climate change, benefiting the developing world. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Inequality Within Countries**
There are concerns that advanced health interventions and cognitive enhancement drugs will only be accessible to the rich, but markets and political institutions in developed countries may mitigate this. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**The "Opt-Out" Problem**
People opting out of AI-enabled benefits could lead to a dystopian underclass, but increasing scientific understanding and AI itself may help address this. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Peace and Governance**
AI can help both "good guys" and "bad guys" in human conflict, and may enable better propaganda and surveillance, so democracies must actively shape its development. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**"Entente Strategy" for Democracies**
Democracies should form a coalition to gain an advantage in AI by securing its supply chain, scaling quickly, and blocking adversaries' access to key resources, while offering benefits in exchange for supporting democracy. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI and Information Warfare**
Democratic governments can use AI to counter propaganda and create a globally free information environment, undermining authoritarianism. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI for Improving Legal and Judicial Systems**
AI could improve legal and judicial systems by making decisions and processes more impartial, working alongside humans as an aid to decision-making. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**AI for Government Services**
AI can help provision government services more effectively and transparently, increasing state capacity and strengthening respect for democratic governance. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Definition of Powerful AI**
Powerful AI is defined as an AI model smarter than a Nobel laureate across most fields, with interfaces for virtual work, capable of autonomous task completion, and able to control physical tools remotely. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Work and Meaning in an AI-Driven World**
Even if AI does everything, meaning comes mostly from human relationships and connection, not economic labor. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Economic Challenges in the Long Run**
In the long run, AI may become so effective and cheap that humans can no longer contribute meaningfully to the economy, requiring a broader societal conversation about economic organization. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Potential Economic Solutions**
Solutions could include universal basic income, a capitalist economy of AI systems distributing resources, or humans remaining economically valuable in unforeseen ways. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Powerful AI Speed and Scale**
The resources used to train a powerful AI model can be repurposed to run millions of instances, absorbing information and generating actions at 10x-100x human speed. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**"Country of Geniuses in a Datacenter"**
The author summarizes the concept of powerful AI as a "country of geniuses in a datacenter," capable of solving difficult problems quickly. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Limits to AI's Transformative Power**
While powerful, AI's impact is limited by physical constraints, data availability, intrinsic complexity, human constraints, and physical laws. Instantaneous transformation is unlikely. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Marginal Returns to Intelligence**
In the AI age, we should focus on the "marginal returns to intelligence" and identify complementary factors that become limiting when intelligence is very high. — Dario Amodei


---

**Source:** `Dario Amodei — Machines of Loving Grace`

**Factors Limiting or Complementary to Intelligence**
These include the speed of the outside world, need for data, intrinsic complexity, constraints from humans, and physical laws. — Dario Amodei


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Key Finding: Augmentation Potential of Generative AI**
Occupations with a mix of automatable and non-automatable tasks are likely to experience the highest productivity gains from generative AI, leading to increased labor demand.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Increase in New Skills in Augmentation-Prone Roles**
Generative AI increases the emergence of new required skills in augmentation-prone occupations.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Critical Capability: Identifying Automation and Augmentation Potential**
Buy-side firms need to accurately assess the automation and augmentation potential of various tasks within different roles to understand the impact of generative AI on their workforce. This can be done by using tools like OpenAI's GPT-4o model to assess whether each task can be effectively performed by generative AI.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Critical Capability: Skills Development for Human-AI Collaboration**
Firms must invest in upskilling and reskilling initiatives to equip employees with the skills needed to effectively collaborate with AI systems, particularly in augmentation-prone roles.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Decision: Prioritizing Augmentation Strategies**
Buy-side firms should prioritize strategies that leverage generative AI to augment human capabilities, focusing on roles where AI can complement human judgment, creativity, and problem-solving.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Decision: Addressing Job Displacement**
Firms must proactively address potential job displacement in automation-prone roles through retraining programs, internal mobility opportunities, or other support mechanisms.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Measuring Success: Tracking Changes in Labor Demand**
KPIs should include changes in job postings for different occupational groups, reflecting the impact of generative AI on labor demand.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Measuring Success: Monitoring Skill Evolution**
Track the evolution of skill requirements in different roles, including the number of AI-exposed skills, total skills, and new skills, to assess the impact of generative AI on skill development.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**AI Roadmap: Task Analysis and Scoring**
The first step in an AI roadmap should involve a detailed analysis of tasks within each occupation, assigning automation and augmentation scores based on AI's capabilities.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**AI Roadmap: Pilot Programs in Augmentation-Prone Areas**
Firms should start with pilot programs in augmentation-prone areas to test and refine AI-driven workflows, focusing on productivity gains and skill development.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Limitation: Short-Term Effects**
The study only unveils the short-term effects on the labor market, and so the long-term impacts remain uncertain as adoption scales.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Job Postings Decrease in Automation-Prone Roles**
Job postings decrease by 17% per quarter per firm for occupations in the top quartile of automation potential after generative AI introduction.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Data and Measurement: O*NET and Lightcast Datasets**
The study uses O*NET for task descriptions and Lightcast for U.S. job postings to assess AI exposure and its impact on labor demand and skills.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Methodology: Synthetic Difference-in-Differences**
The study employs a synthetic difference-in-differences approach to analyze the impact of generative AI on labor demand and skill requirements, using the introduction of ChatGPT as an exogenous shock.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Conceptual Framework: Generative AI as Task-Augmenting and Task-Automating Technology**
Generative AI automates cognitive tasks while complementing human capabilities, creating heterogeneous effects across occupations, contingent on their task composition.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Job Postings Increase in Augmentation-Prone Roles**
Job postings for augmentation-prone occupations increase by 22% per quarter per firm after generative AI introduction.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Key Finding: Generative AI and Skill Requirements**
Generative AI reduces the need for certain skills in highly automatable jobs, while simultaneously creating demand for new skills in jobs that can be effectively augmented by the technology.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Decrease in AI-Exposed Skills in Automation-Prone Roles**
There is a significant 24% decrease in generative AI-exposed skills per firm per quarter among jobs in the top quartile of automation exposure.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Increase in AI-Exposed Skills in Augmentation-Prone Roles**
There is a 15% increase in generative AI-exposed skills per firm per quarter for jobs most susceptible to augmentation.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Decrease in Total Skills in Automation-Prone Roles**
Generative AI decreases the total number of required skills in automation-prone occupations.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Increase in Total Skills in Augmentation-Prone Roles**
Generative AI increases the total number of required skills in augmentation-prone occupations.


---

**Source:** `Displacement or complementarity-labor market impact of gen ai`

**Supporting Fact: Decrease in New Skills in Automation-Prone Roles**
Generative AI reduces the emergence of new required skills in automation-prone occupations.


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Reference Architecture for LLM Apps**
A reference architecture is emerging for LLM applications, encompassing systems, tools, and design patterns used by AI startups and sophisticated tech companies. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Embeddings: OpenAI API is Popular**
Most developers use the OpenAI API (text-embedding-ada-002 model) for embeddings due to its ease of use, reasonable results, and decreasing cost. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Embeddings: Alternatives to OpenAI**
Alternatives to OpenAI for embeddings include Cohere, which focuses on embeddings and performs better in certain scenarios, and the open-source Sentence Transformers library from Hugging Face. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Vector Databases: Pinecone is a Common Choice**
Pinecone is a popular vector database choice due to its cloud-hosted nature, ease of use, and enterprise-level features like performance at scale, SSO, and uptime SLAs. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Vector Databases: Open Source Options**
Open-source vector databases like Weaviate, Vespa, and Qdrant offer excellent single-node performance and customization options for experienced AI teams. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Vector Databases: Local Libraries and OLTP Extensions**
Local vector management libraries like Chroma and Faiss provide great developer experience for small apps, while OLTP extensions like pgvector offer vector support within existing database systems. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Future of Vector Databases**
The future of vector databases may involve cloud offerings from open-source systems, but achieving strong performance in the cloud across various use cases is challenging. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Embedding Pipeline May Become More Important**
Despite larger context windows, the embedding pipeline may become more important, with different embedding models trained for model relevancy and vector databases designed to take advantage of this. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Prompting Strategies: From Simple to Advanced**
Prompting strategies range from simple zero-shot or few-shot prompting to more advanced techniques designed to ground model responses in a source of truth. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Orchestration Frameworks: LangChain and LlamaIndex**
Orchestration frameworks like LangChain and LlamaIndex abstract away prompt chaining, API interfacing, contextual data retrieval, and memory management across LLM calls. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**LangChain: Popular but Evolving**
LangChain is widely used among hobbyists and startups, but some developers switch to raw Python in production to avoid dependencies. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**In-Context Learning is a Common Starting Point**
The reference architecture is based on in-context learning, a design pattern where LLMs are used off-the-shelf and controlled through prompting and contextual data. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**ChatGPT as an Orchestration Tool**
ChatGPT can be considered a substitute for orchestration frameworks, abstracting away bespoke prompts, maintaining state, and retrieving contextual data via plugins or APIs. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**LLM APIs: OpenAI is the Leader**
OpenAI is the leading LLM API provider, with developers starting new apps using gpt-4 or gpt-4-32k for best-case performance and ease of use. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**LLM APIs: Production Considerations**
As projects scale, options like switching to gpt-3.5-turbo (cheaper and faster), experimenting with Anthropic's Claude models, and triaging requests to open-source models come into play. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Open Source LLMs: Closing the Gap**
Open-source models are closing the gap with proprietary offerings, with models like LLaMa setting a new bar for accuracy and driving the development of alternative base models. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Fine-Tuning Open Source Models**
Fine-tuning open-source base models is becoming more common, with platforms like Databricks, Anyscale, Mosaic, Modal, and RunPod supporting engineering teams. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Inference Options for Open Source Models**
Inference options for open-source models include simple API interfaces from Hugging Face and Replicate, raw compute resources from cloud providers, and opinionated cloud offerings. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Future of Open Source LLMs**
When open-source LLMs reach accuracy levels comparable to GPT-3.5, a "Stable Diffusion-like moment" is expected, with massive experimentation and productionizing of fine-tuned models. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Operational Tooling: Caching and Logging**
Caching (usually based on Redis) is common for improving application response times and cost, while tools like Weights & Biases, MLflow, PromptLayer, and Helicone are used for logging, tracking, and evaluating LLM outputs. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Validation and Security Tools**
Tools like Guardrails are being developed to validate LLM outputs, and tools like Rebuff are being developed to detect prompt injection attacks. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Hosting LLM Apps: Standard and Emerging Options**
LLM apps are hosted using standard options like Vercel or major cloud providers, but startups like Steamship and companies like Anyscale and Modal are emerging with end-to-end hosting or model/code hosting solutions. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**In-Context Learning Solves Scalability Issues**
In-context learning addresses the limitations of directly feeding large datasets into LLMs by sending only the most relevant documents with each prompt. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**AI Agents: Potential but Immature**
AI agent frameworks have the potential to solve complex problems, act on the outside world, and learn from experience, but most are still in the proof-of-concept phase and lack reliability. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**LLMs: A Major Architectural Change**
Pre-trained AI models represent a significant architectural shift in software, enabling individual developers to build powerful AI apps quickly. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**The LLM App Stack is Evolving**
The tools and patterns described are a starting point for integrating LLMs, and the architecture will likely evolve as major changes take place, such as a shift toward model training. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**In-Context Learning Workflow: Data Preprocessing/Embedding**
The first stage of in-context learning involves storing private data by breaking it into chunks, passing it through an embedding model, and storing it in a vector database. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**In-Context Learning Workflow: Prompt Construction/Retrieval**
The second stage involves constructing prompts that combine a template, few-shot examples, external API information, and relevant documents from the vector database. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**In-Context Learning Workflow: Prompt Execution/Inference**
The final stage involves submitting the compiled prompts to a pre-trained LLM for inference, with optional operational systems like logging, caching, and validation. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**In-Context Learning vs. Fine-Tuning**
In-context learning can be easier than training or fine-tuning LLMs, requiring less specialized expertise and infrastructure, and can outperform fine-tuning for small datasets. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Context Window Limitations and Costs**
While increasing the context window is possible, it comes with tradeoffs, as cost and time of inference can scale quadratically with prompt length, making it cost-prohibitive for many applications. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Data Pipelines: ETL Tools and Document Loaders**
Data loading and transformation for LLM apps often use traditional ETL tools like Databricks or Airflow, as well as document loaders built into orchestration frameworks like LangChain and LlamaIndex. — [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**ChatGPT Reduces Inequality Among Workers**
ChatGPT compresses the productivity distribution by benefiting lower-ability workers more than higher-ability workers. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Measuring Success: Output Quality**
Output quality can be measured by evaluator grades, including overall grade, writing quality, content quality, and originality. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Critical Capability: Experimentation and Learning**
Buy-side firms should encourage experimentation with generative AI tools like ChatGPT to understand their potential impact on different roles and tasks.


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Decisions about Implementation: Task Selection**
Start by applying AI to well-defined, repeatable writing tasks that don't require extensive context-specific knowledge.


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**ChatGPT Primarily Substitutes for Effort**
The study suggests ChatGPT primarily substitutes for worker effort rather than complementing worker skills. Most participants submitted ChatGPT's initial output without editing. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Task Structure Shifts with ChatGPT**
ChatGPT restructures writing tasks, shifting focus from rough-drafting to idea generation and editing. The share of time spent writing a rough draft falls by more than half and the share of time spent editing more than doubles. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**ChatGPT Increases Job Satisfaction**
Exposure to ChatGPT increases job satisfaction and self-efficacy among users. Job satisfaction increased by about 0.40 standard deviations. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**ChatGPT Heightens Awareness of Automation**
Using ChatGPT increases both concern and excitement about automation technologies. Worry about automation increases by 0.26 standard deviations, excitement by 0.39. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Real-World Usage Confirms Experimental Findings**
A two-week follow-up survey showed that 33% of former treatment group participants used ChatGPT in their jobs, compared to 18% of the control group. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Limitation: Context-Specific Knowledge**
The study acknowledges that the tasks were relatively short and lacked context-specific knowledge, which may inflate estimates of ChatGPT's usefulness. — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Key Quote: Impact on Workers**
"The experimental evidence suggests that ChatGPT largely substitutes for worker effort rather than complementing workers’ skills, potentially causing a decrease in demand for workers, with adverse distributional effects as capital owners gain at the expense of workers." — Noy & Zhang, 2023


---

**Source:** `Experimental Evidence onthe Productivity EffectsofGenerativeArtificialIntelligence`

**Measuring Success: Productivity Gains**
Productivity gains can be measured by earnings per minute, comparing pre- and post-treatment performance with and without ChatGPT. — Noy & Zhang, 2023


---

**Source:** `Field experiments on AI in software dev`

**Supporting Fact: Experiment Sample Size**
The analysis included data from 4,867 software developers across Microsoft, Accenture, and an anonymous Fortune 100 electronics manufacturing company.


---

**Source:** `Field experiments on AI in software dev`

**Heterogeneity: Code Acceptance Rates**
Higher-tenure developers are approximately 4.3% less likely to accept code suggested by Copilot.


---

**Source:** `Field experiments on AI in software dev`

**Heterogeneity: Productivity Gains by Tenure and Level**
The productivity-enhancing effects of Copilot are stronger for lower tenure and more junior developers.


---

**Source:** `Field experiments on AI in software dev`

**Key Finding: Impact on Less Experienced Developers**
Less experienced and more junior developers showed higher adoption rates and greater productivity gains from using GitHub Copilot.


---

**Source:** `Field experiments on AI in software dev`

**Supporting Fact: Increased Code Updates and Compilations**
Usage of the coding assistant caused a 13.55% increase in code updates (commits) and a 38.38% increase in code compilations.


---

**Source:** `Field experiments on AI in software dev`

**Key Quote: Real-World vs. Lab Settings**
"While lab experiments offer a valuable opportunity to examine the short-term implications of generative AI, challenges and complex interactions arise when these tools are deployed in real-world environments."


---

**Source:** `Field experiments on AI in software dev`

**Critical Consideration: Adoption Rates Below 100%**
Despite the ease of adopting Copilot, adoption rates remained significantly below 100% in all three experiments, suggesting individual preferences and perceived utility play a role.


---

**Source:** `Field experiments on AI in software dev`

**Empirical Strategy: Addressing Imperfect Compliance**
The study uses experimental assignment as an instrument for adoption of GitHub Copilot to account for imperfect compliance.


---

**Source:** `Field experiments on AI in software dev`

**Empirical Strategy: Weighting for Instrument Relevance**
To address the issue of control groups gaining access to Copilot, the 2SLS estimates are weighted by the period-by-period difference in adoption across treatment and control groups.


---

**Source:** `Field experiments on AI in software dev`

**Heterogeneity: Adoption by Tenure and Level**
Short-tenure developers were 9.5 percentage points more likely to adopt Copilot, and junior developers were 5.3 percentage points more likely to adopt.


---

**Source:** `Field experiments on AI in software dev`

**Heterogeneity: Usage After Adoption**
Employees of shorter tenure are more likely to continue using Copilot more than one month after initial adoption.


---

**Source:** `Furman 2019`

**Supporting Fact: AI-Related M&A Growth**
AI-related mergers and acquisitions were estimated to be 26 times larger in 2017 than in 2015, indicating a rapid increase in investment. — Furman and Seamans


---

**Source:** `Furman 2019`

**Supporting Fact: Corporate AI Investment**
Established firms spent between $18 and $27 billion on internal corporate investment in AI-related projects in 2016. — Furman and Seamans, McKinsey Global Institute (MGI) report


---

**Source:** `Furman 2019`

**Supporting Fact: Venture Capital in AI Startups**
Venture capital investment in AI startups grew by 40% between 2013 and 2016, showing increasing investor confidence in AI ventures. — Furman and Seamans, MGI report


---

**Source:** `Furman 2019`

**Supporting Fact: Robot Shipments Increase**
Worldwide robot shipments increased about 150% between 2010 and 2016, reflecting growing adoption of robotics in various industries. — Furman and Seamans, International Federation of Robotics (IFR)


---

**Source:** `Furman 2019`

**Supporting Fact: Robot Price Decrease**
Robot prices decreased 50-80% between 1990 and 2005, contributing to increased adoption. — Furman and Seamans, Graetz and Michaels (2015)


---

**Source:** `Furman 2019`

**Supporting Fact: Automotive Sector Robot Density**
In the US automotive sector, there were approximately 1,091 robots per 10,000 workers in 2012, highlighting the high adoption rate in this industry. — Furman and Seamans, Council of Economic Advisers (CEA) 2016


---

**Source:** `Furman 2019`

**Supporting Fact: AI Patent Applications Surge**
Patent applications with the term "artificial intelligence" in its abstract have roughly doubled between 2002-2015 and 2016-2017. — Furman and Seamans, USPTO


---

**Source:** `Furman 2019`

**Key Finding: AI as a General Purpose Technology (GPT)**
AI and other advanced automation can be considered a general-purpose technology (GPT) that enables follow-on innovation and productivity growth. — Furman and Seamans


---

**Source:** `Furman 2019`

**Key Finding: Robotics and GDP Growth**
Robotics added an estimated 0.4 percentage points of annual gross domestic product (GDP) growth between 1993 and 2007, on average, for the 17 countries in their sample. — Furman and Seamans, Graetz and Michaels (2015)


---

**Source:** `Furman 2019`

**Key Finding: AI's Impact on Labor Markets**
AI has been too small a component of the overall economy to have a significant impact on labor markets to date, but this is expected to change. — Furman and Seamans


---

**Source:** `Furman 2019`

**Key Finding: Innovation's Effects on Labor**
Innovation has four effects on labor markets: displacement, job creation, increased demand, and task replacement. — Furman and Seamans


---

**Source:** `Furman 2019`

**Supporting Fact: Image Recognition Improvement**
Error rates for image recognition have dropped dramatically, from 29% to less than 3% between 2010 and 2017, surpassing human performance. — Furman and Seamans, AI Index


---

**Source:** `Furman 2019`

**Key Finding: AI and Inequality**
To the degree that AI does not displace labor, part of that will be because relative wages adjust, in other words, that inequality rises. — Furman and Seamans


---

**Source:** `Furman 2019`

**Key Finding: Digital Economy and Market Concentration**
Internet markets have tended to favor large digital platforms that hold high market shares, a characteristic that is traditionally associated with low competition in brick-and-mortar markets. — Furman and Seamans


---

**Source:** `Furman 2019`

**Critical Consideration: Algorithmic Pricing Opacity**
The use of increasingly complex algorithms for setting prices can lead to undesirable price behavior, sometimes even unintentionally. — Furman and Seamans


---

**Source:** `Furman 2019`

**Critical Consideration: Data as a Barrier to Entry**
Large data sets are a critical input for firms that want to create or use AI systems, potentially creating a barrier to entry for startups. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Data Portability**
Data portability allows customers to take their data from one provider to another, potentially increasing competition. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Trusted Third Parties for Data**
Trusted third parties can potentially play a role to safeguard consumer information while allowing conditional access to large data sets for AI-enabled startups. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Policy Responses to Labor Market Changes**
It is important to understand whether artificial intelligence is more like a macroeconomic shock or a series of sector-specific shocks when determining policy responses. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Universal Basic Income (UBI)**
UBI has drawbacks including cost, trade-offs in targeting, and questionable impact on entrepreneurship. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Employment Subsidies**
Employment subsidies, like the Earned Income Tax Credit (EITC), can incentivize work and increase the reward to work. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Guaranteed Employment**
Guaranteed employment could provide payment in exchange for labor services, potentially keeping people in the labor force. — Furman and Seamans


---

**Source:** `Furman 2019`

**Key Quote: Elon Musk on AI Risk**
"AI is a fundamental risk to the existence of human civilization." — Elon Musk


---

**Source:** `Furman 2019`

**Decision: AI-Specific Agency**
There are multiple challenges with creating a new commission or agency, including defining the mission or scope of the new agency and reorganizing existing agencies. — Furman and Seamans


---

**Source:** `Furman 2019`

**Critical Consideration: AI as a Tool vs. New Area**
Key questions in evaluating the need for an AI-specific agency are whether AI should be thought of as a new area or instead as a tool that is used in a variety of areas. — Furman and Seamans


---

**Source:** `Furman 2019`

**Measuring Success: Need for Empirical Research**
More empirical research is needed in order to confirm existing findings on the productivity benefits, better understand conditions under which AI and robotics substitute or complement for labor, and understand regional-level outcomes. — Furman and Seamans


---

**Source:** `Furman 2019`

**Critical Capability: Data Collection and Dissemination**
Systematic collection and dissemination of establishment-level data is needed to address the need for publicly available data on the deployment and use of robotics and AI in manufacturing and service establishments. — Furman and Seamans


---

**Source:** `Furman 2019`

**Decision: Evaluating Policy Approaches**
Any assessment of policies should compare how they might address potential AI-related issues relative to current policies. — Furman and Seamans


---

**Source:** `Furman 2019`

**Critical Consideration: Speed of AI's Impact**
When weighing the trade-offs of various policy approaches, it will be useful to consider the speed with which AI may or may not affect the economy. — Furman and Seamans


---

**Source:** `Furman 2019`

**Key Finding: Automation and Productivity Growth**
Historically, automation, including AI and robotics, has fostered productivity growth, although its effects on labor have been complex. — Furman and Seamans


---

**Source:** `Furman 2019`

**Supporting Fact: Productivity Slowdown**
Productivity growth has slowed in advanced economies, highlighting the importance of AI to deliver potential productivity benefits. Growth has slowed from a 2.7% average growth rate in 1996-2006 to a 1.0% average annual growth rate in 2006-2016. — Furman and Seamans


---

**Source:** `Furman 2019`

**Key Finding: Declining Male Labor Force Participation**
There has been a long-term decline in the male labor force participation rate, particularly among those with a high school degree or less, suggesting difficulty in learning new skills. — Furman and Seamans


---

**Source:** `Furman 2019`

**Critical Capability: Data-Driven AI Development**
Scientific breakthroughs in machine learning are finding their way to commercial applications, but some argue there may be limits to what current techniques can accomplish. — Furman and Seamans


---

**Source:** `Furman 2019`

**Supporting Fact: Increase in AI Academic Papers**
Academic papers focused on AI have increased nine times since 1996, demonstrating growing research interest. — Furman and Seamans, AI Index


---

**Source:** `Furman 2019`

**Supporting Fact: AI Skills Demand**
The share of jobs requiring AI skills has increased almost five times since 2013, indicating a growing demand for AI expertise in the workforce. — Furman and Seamans, AI Index


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Key Finding: GPT-4.1 is Highly Steerable**
GPT-4.1 is trained to follow instructions more closely and literally than its predecessors, making it highly steerable with well-specified prompts. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Inducing Planning in Prompts**
Induce explicit, step-by-step planning in prompts to have the model "think out loud," which can increase task completion rates. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Supporting Fact & Figure: Planning Improvement**
Inducing explicit planning in prompts increased the pass rate by 4% on the SWE-bench Verified agentic task. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Key Capability: Long Context Utilization**
GPT-4.1 has a performant 1M token input context window, useful for tasks like document parsing, re-ranking, and multi-hop reasoning. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Instruction Placement in Long Context**
Place instructions at both the beginning and end of long context prompts for better performance. If only once, place above the context. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Chain-of-Thought Prompting**
Use chain-of-thought prompting to break down problems into manageable pieces and improve output quality, starting with a basic instruction. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Refining Chain-of-Thought Prompts**
Improve chain-of-thought prompts by auditing failures and addressing systematic planning and reasoning errors with more explicit instructions. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Instruction Following Development**
Develop and debug instructions in prompts by starting with high-level guidance, adding specific details, and using ordered lists for workflow steps. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Conflict Resolution in Instructions**
Check for conflicting, underspecified, or wrong instructions. GPT-4.1 tends to follow the instruction closer to the end of the prompt. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Instruction Following Examples**
Add examples that demonstrate desired behavior, ensuring that any important behavior demonstrated in your examples are also cited in your rules. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Avoiding Unnecessary Incentives**
Avoid using all-caps or other incentives like bribes or tips unless necessary, as they can cause GPT-4.1 to pay attention to them too strictly. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Prompt Migration Required**
To maximize GPT-4.1's intelligence, prompt migration is necessary, as the model interprets instructions more literally. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Caveat: Tool Calling with Insufficient Information**
Instructing a model to always call a tool may lead to hallucinated inputs or null values if it lacks sufficient information; mitigate by instructing it to ask the user for needed information. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Varying Sample Phrases**
When providing sample phrases, instruct the model to vary them to avoid repetitive outputs. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Prompt Structure**
Use a clear prompt structure including Role and Objective, Instructions, Reasoning Steps, Output Format, and Examples. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Delimiter Selection**
Use Markdown or XML for delimiters, as JSON can be more verbose and require character escaping. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Caveat: Long, Repetitive Outputs**
In some cases, the model may resist producing very long, repetitive outputs; instruct it strongly to output information in full or break down the problem. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Caveat: Parallel Tool Calls**
Rare instances of incorrect parallel tool calls have been observed; test this and consider setting `parallel_tool_calls` to false if issues arise. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Key Capability: Improved Diff Generation**
GPT-4.1 features substantially improved diff capabilities, critical for coding-related tasks. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]
```


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Empirical AI Engineering**
AI engineering is inherently empirical; build informative evals and iterate often to ensure prompt engineering changes yield benefits. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Key Finding: GPT-4.1 for Agentic Workflows**
GPT-4.1 is well-suited for building agentic workflows due to its training on diverse problem-solving trajectories. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Critical Capability: Agent Prompt Reminders**
Include persistence, tool-calling, and planning reminders in agent prompts to fully utilize GPT-4.1's agentic capabilities. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: System Prompt Reminders for Agents**
Use system prompt reminders like "You are an agent - please keep going until the user’s query is completely resolved" to improve agent performance. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Tool Usage via API**
Use the OpenAI API's "tools" field to pass tools, rather than manually injecting tool descriptions into prompts, to minimize errors. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Supporting Fact & Figure: Tool Usage Improvement**
Using API-parsed tool descriptions resulted in a 2% increase in SWE-bench Verified pass rate compared to manual injection. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `GPT-4.1 Prompting Guide _ OpenAI Cookbook`

**Best Practice: Tool Definition Clarity**
Name tools and parameters clearly, and provide detailed descriptions in the "description" field. Use an "# Examples" section for usage examples. — [Noah MacCallum (OpenAI), Julian Lee (OpenAI)]


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Key Finding: Generative AI's Value Problem**
Despite high demand and numerous use cases, generative AI struggles to prove its value, evidenced by lackluster user retention and engagement compared to established companies.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**AI Roadmap: From Demos to Whole Product Experiences**
The AI roadmap involves transforming flashy demos into comprehensive product experiences that deliver real value to users.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Best Practice: Focus on Value and Whole Product Experiences**
Companies should prioritize building AI solutions that address the "value problem" and provide complete, user-friendly experiences.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Key Finding: Data Moats are Shaky**
Data generated by application companies does not necessarily create an insurmountable moat, as future foundation models may diminish the value of that data. Workflows and user networks are more durable sources of competitive advantage.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Supporting Fact: Generative AI Startup Revenue**
Generative AI has had a successful start, with startups alone generating >$1 billion in revenue, a milestone that took the SaaS market years to reach.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Decision: Vertical Integration vs. Separation**
While a separation between application layer companies and foundation model providers was anticipated, the most successful early applications have been vertically integrated.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Key Finding: Bottleneck on GPU Supply**
End user demand has outstripped GPU supply, creating a bottleneck for many companies' growth.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Key Finding: Swift Incumbent Response**
Incumbents like Google and Adobe have responded quickly to the rise of generative AI, increasing competition in the market.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Supporting Fact: Low User Engagement in Generative AI Apps**
Generative AI applications have a median DAU/MAU of 14%, significantly lower than successful consumer companies like WhatsApp (85%), indicating users aren't finding enough daily value.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Key Quote: The $200B Question**
"The $200B question is: What are you going to use all this infrastructure to do? How is it going to change people’s lives?" — David Cahn


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Critical Capability: Improving Model Performance**
Companies are using prompt engineering, fine-tuning, and dataset curation to improve the quality and usefulness of their AI products.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Critical Capability: Retrieval-Augmented Generation (RAG)**
RAG is crucial for bringing in context about the business or the user, reducing hallucinations, and increasing the truthfulness and usefulness of AI outputs. Vector databases are the infrastructure backbone for RAG.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Critical Capability: Evolving User Interfaces**
Generative AI interfaces are evolving beyond text-based conversations to include generative UIs and new modalities like human-sounding voices.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Critical Capability: New Editing Experiences**
Generative AI is enabling new editing experiences, moving beyond zero-shot approaches to "ask-and-adjust" workflows with innovative controls.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Critical Capability: Developing Agentic Systems**
Generative AI applications are progressing towards more autonomous systems that can problem-solve, access external tools, and solve problems end-to-end.


---

**Source:** `Generative AI’s Act Two _ Sequoia Capital`

**Critical Capability: System-Wide Optimization**
Some companies are focusing on system-wide optimization by autonomously solving support tickets or pull requests, making the entire system more effective.


---

**Source:** `How to think about agent frameworks`

**Agentic Systems: Workflows and Agents Combined**
Most "agentic systems" in production are a blend of predefined workflows and dynamically controlled agents, rather than purely one or the other.


---

**Source:** `How to think about agent frameworks`

**Framework Floors and Ceilings**
Workflow frameworks have a high floor (require more initial effort) but a high ceiling (offer extensive capabilities), while agent frameworks have a low floor but a low ceiling.


---

**Source:** `How to think about agent frameworks`

**Agent Abstractions: Keras Analogy**
Agent abstractions are like Keras: they provide higher-level abstractions for easy starting, but should be built on a lower-level framework for advanced use cases.


---

**Source:** `How to think about agent frameworks`

**Multi-Agent Systems: Communication is Key**
In multi-agent systems, effective communication between agents is crucial, and workflows can sometimes be the best way to facilitate this.


---

**Source:** `How to think about agent frameworks`

**Value of an Agentic Framework**
Frameworks provide useful abstractions, short-term/long-term memory, human-in-the-loop/on-the-loop capabilities, streaming, debugging/observability, and fault tolerance.


---

**Source:** `How to think about agent frameworks`

**Key Capability: Debugging and Observability**
Being able to inspect the exact steps taken by an agent and the inputs/outputs at each step is crucial for building reliable agents.


---

**Source:** `How to think about agent frameworks`

**Frameworks: Understand the Underlying Code**
"If you do use a framework, ensure you understand the underlying code. Incorrect assumptions about what's under the hood are a common source of customer error." — Anthropic


---

**Source:** `How to think about agent frameworks`

**Future of Agents vs. Workflows**
Even as models improve, controlling the context passed to the LLM will remain important, and production systems will likely combine workflows and agents.


---

**Source:** `How to think about agent frameworks`

**Unique Tasks May Require Custom Models**
If a task is unique, firms may need to train/finetune/RL their own models to achieve optimal agent performance, making workflow control less critical.


---

**Source:** `How to think about agent frameworks`

**Agent Frameworks: Focus on Orchestration**
The main value of a framework should be a reliable orchestration layer that provides explicit control over context and handles production concerns.


---

**Source:** `How to think about agent frameworks`

**OpenAI's Take on Agent Frameworks: Misses the Mark**
OpenAI's perspective conflates declarative vs. imperative approaches with agent abstractions and workflows vs. agents, ultimately missing the importance of a reliable orchestration layer.
```


---

**Source:** `How to think about agent frameworks`

**Agent Abstractions Can Obscure Context**
Agent abstractions can simplify initial development, but they often make it difficult to control and understand the context being passed to the LLM, hindering reliability.


---

**Source:** `How to think about agent frameworks`

**Frameworks Should Support Both Agents and Workflows**
A production-ready agentic framework needs to support both predefined workflows and dynamic agents, allowing developers to choose the right approach for each task.


---

**Source:** `How to think about agent frameworks`

**Key Quote: Simplicity First**
"When building applications with LLMs, we recommend finding the simplest solution possible, and only increasing complexity when needed. This might mean not building agentic systems at all." — Anthropic


---

**Source:** `How to think about agent frameworks`

**Key Quote: Validate Agent Use Cases**
"Before committing to building an agent, validate that your use case can meet these criteria clearly. Otherwise, a deterministic solution may suffice." — OpenAI


---

**Source:** `How to think about agent frameworks`

**Agent Performance Quality is a Major Limitation**
A survey of agent builders revealed that "performance quality" is the biggest limitation in deploying more agents to production.


---

**Source:** `How to think about agent frameworks`

**Reasons for Poor Agent Performance**
LLM errors often stem from incomplete context, vague input, lack of access to tools, poor tool descriptions, or poorly formatted tool responses.


---

**Source:** `How to think about agent frameworks`

**LangGraph: An Orchestration Framework**
LangGraph is an orchestration framework with both declarative and imperative APIs, offering agent abstractions built on top.


---

**Source:** `How to think about agent frameworks`

**Predictability vs. Agency Trade-off**
As systems become more agentic, they become less predictable, which can impact user trust and regulatory compliance.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Key Finding: Automation of Routine Tasks**
Claude Code is used across various departments to automate routine tasks, freeing up employees to focus on more strategic and complex work.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Measuring Success: Reduced Time-to-Resolution**
The Security Engineering team reduced incident resolution time by using Claude Code to trace control flow through the codebase, decreasing the time from 10-15 minutes to about 5 minutes.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Measuring Success: Faster Feature Implementation**
The Product Development team successfully implemented complex features like Vim mode with 70% of the code written autonomously by Claude.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Measuring Success: Increased Creative Output**
The Growth Marketing team achieved a 10x increase in creative output by using Claude Code to automate ad variation generation and integrate with Figma.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Key Quote: "Large state management changes that you typically wouldn’t see a designer making"**
Engineers noted that designers are now making significant state management changes directly using Claude Code, enabling them to achieve their exact design vision. — Product Design Team


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Key Quote: "Holy crap, I’m a developer workflow"**
Non-technical users experience a "holy crap, I'm a developer workflow" when using Claude Code, gaining entirely new capabilities previously impossible. — Product Design Team


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Decision: Asynchronous vs. Synchronous Coding**
Product Development teams need to distinguish between tasks that work well asynchronously (peripheral features, prototyping) versus those needing synchronous supervision (core business logic, critical fixes).


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Decision: MCP Servers for Sensitive Data**
The Data Infrastructure team recommends using MCP servers rather than the BigQuery CLI to maintain better security control over what Claude Code can access, especially for sensitive data.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Critical Capability: Security and Compliance Awareness**
Legal teams immediately identify security implications of deep MCP integrations, noting how conservative security postures will create barriers as AI tools access more sensitive systems.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Best Practice: Share Team Usage Sessions**
The Data Infrastructure team held sessions where members demonstrated their Claude Code workflows to each other, helping spread best practices and showing different ways to use the tool.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Best Practice: Treat it like a slot machine**
Save your state before letting Claude work, let it run for 30 minutes, then either accept the result or start fresh rather than trying to wrestle with corrections. Starting over often has a higher success rate than trying to fix Claude’s mistakes. — Data Science and ML Engineering teams


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Key Finding: Bridging Skill Gaps**
Teams with members lacking specific technical skills, such as machine learning or Javascript, are using Claude Code to bridge these gaps and contribute effectively.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Critical Capability: Prompt Engineering**
The quality and detail of prompts significantly impact Claude Code's performance; clear and specific prompts lead to more reliable and independent work by the AI.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Critical Capability: Iterative Development**
Teams find success by treating Claude Code as an iterative partner, working in small steps and frequently checking the AI's work, rather than expecting perfect solutions on the first try.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Best Practice: Detailed Documentation**
Writing detailed Claude.md files documenting workflows, tools, and expectations improves Claude Code's performance, particularly for routine tasks.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Best Practice: Custom Memory Files**
Creating custom memory files that provide Claude with specific instructions about the user's role and needs improves the quality and relevance of the AI's responses.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**Best Practice: Visual-First Approach**
Using screenshots to show Claude Code desired interfaces and iterating based on visual feedback can be more effective than describing features in text.


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**AI Roadmap: Start with Code Generation**
Begin by giving Claude Code specific instructions to write logic and then verify its correctness to build trust in the tool's capabilities before using it for more complex tasks. — Inference Team


---

**Source:** `How-Anthropic-teams-use-Claude-Code_v2`

**AI Roadmap: Identify API-Enabled Repetitive Tasks**
Focus on workflows involving repetitive actions with tools that have APIs (e.g., ad platforms, design tools, analytics platforms) as prime candidates for automation with Claude Code. — Growth Marketing Team


---

**Source:** `JaggedFrontier`

**Key Finding: AI Can Be Both a Booster and a Disrupter**
AI, particularly LLMs, can significantly increase productivity and quality for knowledge workers on tasks within its capabilities ("inside the frontier"), but can negatively impact performance on tasks outside those capabilities ("outside the frontier").


---

**Source:** `JaggedFrontier`

**Critical Capability: Understanding AI Failure Points**
Firms must understand the failure points of AI models, including the tendency to produce incorrect but plausible results (hallucinations), and implement validation processes to mitigate these risks.


---

**Source:** `JaggedFrontier`

**Decisions: Human-AI Integration Strategies**
Firms should consider different models of human-AI integration, such as "Centaurs" (dividing tasks between humans and AI) and "Cyborgs" (integrating human and AI efforts at a granular level), and determine which approach is best suited for different tasks and roles.


---

**Source:** `JaggedFrontier`

**Best Practice: Validate and Interrogate AI Output**
Professionals should validate and interrogate AI output, rather than blindly adopting it, especially for critical tasks. Cognitive effort and expert judgment remain essential when working with AI.


---

**Source:** `JaggedFrontier`

**AI Roadmap: Experimentation and Learning**
Firms should encourage ongoing user trial-and-error and the sharing of experiences to learn the best ways to use AI systems. This includes creating user groups, hackathons, and internal forums for sharing best practices.


---

**Source:** `JaggedFrontier`

**Measuring Success: Quality, Productivity, and Correctness**
Success metrics for AI initiatives should include not only productivity gains and task completion rates, but also the quality and correctness of the results, especially for tasks outside the AI frontier.


---

**Source:** `JaggedFrontier`

**Critical Capability: Addressing Diminished Diversity of Ideas**
Firms should be aware of the potential for AI to reduce the diversity of ideas and consider strategies to counteract this homogenization, such as employing a variety of AI models or increasing human-only involvement.


---

**Source:** `JaggedFrontier`

**Best Practice: Focus on Knowledge Workflow**
Organizations should move beyond a simple "adopt or not adopt AI" decision and instead focus on the knowledge workflow and the tasks within it, evaluating the value of different configurations and combinations of humans and AI for each task.


---

**Source:** `JaggedFrontier`

**Critical Capability: Training and Upskilling**
Navigating the AI frontier requires expertise, which will need to be built through formal education, on-the-job training, and employee-driven upskilling.


---

**Source:** `JaggedFrontier`

**AI Roadmap: Continuous Re-evaluation**
As AI capabilities continue to expand, human professionals must recalibrate their understanding of the frontier, and organizations must prepare for a new world of work combining humans and AI.


---

**Source:** `JaggedFrontier`

**Key Finding: The "Jagged Technological Frontier"**
AI capabilities are uneven; some tasks are easily done by AI, while others, seemingly similar, are beyond its current abilities. This creates a "jagged frontier" where the impact of AI on tasks can vary unexpectedly.


---

**Source:** `JaggedFrontier`

**Key Finding: Importance of Understanding the AI Frontier**
Understanding the shape and position of the AI frontier is crucial for maximizing AI's benefits and mitigating its risks. Professionals need to grasp the boundary of this frontier to effectively integrate AI into their workflows.


---

**Source:** `JaggedFrontier`

**Supporting Fact: Productivity Gains Inside the Frontier**
Consultants using AI (GPT-4) completed 12.2% more tasks on average and completed tasks 25.1% more quickly, with a 40% increase in quality, for tasks within the AI frontier.


---

**Source:** `JaggedFrontier`

**Supporting Fact: Performance Decrease Outside the Frontier**
For a task outside the AI frontier, consultants using AI were 19 percentage points less likely to produce correct solutions compared to those without AI.


---

**Source:** `JaggedFrontier`

**Supporting Fact: Differential Impact Based on Skill Level**
Consultants across the skills distribution benefited from AI augmentation, with those below the average performance threshold increasing by 43% and those above increasing by 17% compared to their own scores.


---

**Source:** `JaggedFrontier`

**Key Quote: On the Impact of AI**
"Our results show that this generation of LLMs are highly capable of causing significant increases in quality and productivity...but the actual tasks that AI can do are surprising and not immediately obvious." — [Dell’Acqua et al., Working Paper 24-013]


---

**Source:** `JaggedFrontier`

**Key Quote: On the Jagged Frontier**
"This creates a 'jagged Frontier,' where tasks that appear to be of similar difficulty may either be performed better or worse by humans using AI." — [Dell’Acqua et al., Working Paper 24-013]


---

**Source:** `JaggedFrontier`

**Critical Capability: Navigating the Jagged Frontier**
Buy-side firms need to develop strategies and training programs to help their knowledge workers effectively navigate the "jagged technological frontier" and identify tasks where AI can be beneficial versus detrimental.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Post-Scarcity Economy Vision**
AI promises a future of unparalleled abundance, potentially leading to a post-scarcity economy where technology eliminates material limitations and goods are produced so efficiently that scarcity becomes obsolete.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Potential to Augment Creativity**
AI can augment and expand human creativity, enabling individuals to create personalized art and music, and allowing great artists to leverage these tools even more.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**The Risk of a Sentient, Independent, Malevolent AI**
The risk of a "sentient, independent, malevolent AI" is probably the most significant threat AI poses, and it's one we must take seriously.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI Safety Research is Crucial**
Investing heavily in AI safety is crucial, and a substantial portion of university research should focus on this area. The federal government should invest more in safety research and detection of AI.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**The Greatest Risk is Falling Behind in the AI Race**
In my view, the risk of falling behind in AI technology to China and other adversaries is a far greater risk than sentient AI risk. Slowing down the development of AI could be disastrous for democracies and the greatest risk we could possibly take.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**China's Ambition to Dominate AI**
China's 14th five-year plan specifically declares their intent to win in AI and 5G wireless. The former will allow for economic power while the latter allows China to surveil all citizens in 100+ countries by controlling their telecommunications networks and TikTok.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Tech CEOs vs. Authoritarian Leaders**
While tech CEOs wield immense power without direct democratic accountability, their reliance on user support and market forces makes them potentially preferable to unchecked authoritarian power.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Potential to Provide Near-Free Expertise**
AI can provide near-free AI tutors to every child on the planet and near-free AI physician expertise to everyone on the planet.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Impact on Resource Discovery and Utilization**
AI will transform how we discover and utilize natural resources such as lithium, cobalt, and copper, such that our resource discovery capabilities outpace consumption.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Bipedal Robots and Their Potential to Transform Industries**
Bipedal robots have the capacity to transform every vertical from housekeeping to eldercare to factory assembly lines & farms.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI-Driven Autonomous Transit Systems**
We could replace the majority of cars in most cities with AI-driven, autonomous, personal rapid transit systems and last mile self-driving cars, increasing the passenger capacity of existing streets by 10X.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Impact on Jobs and the Economy**
AI will likely eliminate most "jobs" as they are currently defined, but with proper redistribution efforts, everyone could have a minimum standard of living materially higher than today's minimum.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Personal AI Agents for Consumer Protection**
I envision a personal AI agent for every individual, designed to act in their best interest—shielding them from manipulative marketing and the brain hacks of today.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Revolutionizing Impact on Healthcare**
AI could revolutionize healthcare by enabling personalized medicine, early disease detection, and improved quality, consistency, and accessibility of services.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Potential to Address Mental Health Shortages**
The first large language model AI approved in the UK are now doing 40% of NHS mental health clinics doing intake for behavioral health and they are showing superior outcomes. In time this trend will lead to near free mental health care.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Role in Global Education**
Globally, AI is our only chance at near-free tutors, available 24x7 across innumerable subjects, for every child on the planet.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Role in Environmental Sustainability**
AI could play a crucial role in addressing climate change by optimizing energy usage, reducing emissions, and developing new technologies for renewable energy.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Potential to Enhance Human Capabilities**
AI could augment human capabilities, allowing people to tackle complex problems that are beyond the reach of current human intelligence alone.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Role in Ethical Decision-Making and Governance**
AI could help create more just and equitable societies by ensuring fair decision-making processes, reducing biases, and promoting transparency in governance.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Potential to Shift Societal Focus to Human Well-Being**
In a utopian vision, AI could help shift societal focus from economic growth to human well-being and fulfillment.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Potential Obstacles to an AI-Driven Utopia**
Potential obstacles to our utopia can be overcome, including incumbent resistance, political exploitation of fears, technical failures, and anti-tech sentiment.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Democratization of AI Development**
The fear of AI power consolidating into the hands of a few is unlikely given how accessible and user-friendly AI tools have become.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI Risks are Real but Manageable**
AI risks are real but manageable. The biggest risk is losing the AI race to nefarious nation states, making AI dangerous for the west.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Capitalism and Democracy in the AI Era**
Capitalism may need to evolve in the face of AI-driven changes. The diminishing need for economic efficiency gives us room to prioritize empathetic capitalism and economic equality alongside efficiency.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Wage Compression and Job Disruptions**
AI's leveling of skill differences could compress wages both individually and across various job functions, and value creation may shift to creativity, innovation, capital or AI ownership, potentially leading to different economic inequalities.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Deflation and the Need for New Economic Measures**
Increased productivity with fewer inputs and increased competition can trigger deflation, along with job loss. GDP measures over the next decades will be a distortion of prosperity in a deflationary, AI world whereby GDP could conceivably decrease but overall wellbeing and consumption of goods and services increases.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Policy Choices in an AI-Driven World**
We face choices: accelerate, slow down, or moderate the adoption of disruptive technologies, and decide whether to compensate those displaced, for instance, through economic support.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**The Potential for Universal Basic Income (UBI)**
As AI reduces the need for human labor, UBI could become crucial, with governments playing a key role in regulating AI’s impact and ensuring equitable wealth distribution.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Imagining a Consumer Utopia**
I can imagine a consumer utopia in 25+ years, where we’re not supply constrained in most areas and deflation is actually a positive tailwind for access and more equal consumption.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**The Grand Ambition of Imparting a Rich Lifestyle to All**
Most importantly though, the grand ambition of imparting the rich lifestyle enjoyed by only 700 million (~10%) people to all 7-8 billion global citizens, is finally within arm’s reach.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**The Need to Redefine Humanity**
Reflecting on my words in a New York Times interview in 2000, we will need to redefine what it means to be human. This new definition should focus not on the need for work or productivity but on passions, imagination, and relationships, allowing for individual interpretations of humanity.
```


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Importance of Democratic Values in AI Development**
Democratic values are at stake in the technology battle, and so we should do whatever we can to win this battle and beat China. Their view of utopia is likely different.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI and Job Creation/Elimination**
Over the next 5-20 years, AI may create new jobs, but in the long term, it will eliminate most jobs as they are currently defined.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI's Potential to Correct Human Biases**
AI offers a chance to recognize and correct human biases in critical decision-making areas like healthcare and justice.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Redefining Human Purpose in an AI-Driven World**
As AI reshapes work, we have an opportunity to redefine human purpose, focusing on exploration, imagination, discovery, and experimentation.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**AI as a Tool, Not an Overlord**
AI will not be an overlord but rather a tool available to fulfill our needs and requests. Individuals will have the freedom to choose whether or not to leverage AI.


---

**Source:** `Khosla - AI - Dystopia or Utopia`

**Concerns About Ethical Degradation are Greater with Humans**
Pessimists worry about ethical and moral degradation as machines lack the nuanced understanding of human values, ethics, and emotions, I'd suggest this is a much greater danger with humans in charge.


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI Use Cases Across Industries**
Generative AI use cases are emerging across industries, including financial services (Morgan Stanley), government (Iceland), and CRM (Salesforce). — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Key Issues Shaping Generative AI's Future: Data Usage**
Key issues shaping generative AI's future include questions about using copyrighted or personal data to train models, which may lead to limits on scraping proprietary data and new compensation models for data owners. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Key Issues Shaping Generative AI's Future: Creative Output Ownership**
The ownership of copyright on the final output of a generative AI system is unclear, with potential actors including the data set owner, model developer, platform owner, prompt creator, or the designer who refines the output. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Key Issues Shaping Generative AI's Future: Output Quality Management**
Organizations need processes for assessing the quality of generative AI outputs and determining where potential harm should limit commercialization due to instances of inaccurate, inflammatory, biased, or plagiarized content. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Model Hubs and MLOps: Essential for Application Building**
Businesses need model hubs and MLOps tooling to store, access, adapt, and deploy foundation models within their end-user applications. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Applications: Completing Specific Tasks**
Applications built on top of foundation models enable specific tasks to be completed, such as customer service or drafting marketing emails. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Value Creation: Fine-Tuned Models**
Applications that leverage fine-tuned foundation models, which have been fed additional relevant data or had their parameters adjusted, offer the greatest potential for value creation. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Proprietary Data Drives Competitive Advantage**
Companies can create proprietary data from feedback loops driven by end-user rating systems, leading to a virtuous cycle of improvement and a significant competitive advantage. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**First Wave of Application Impact: IT, Marketing, Customer Service, Product Development**
Information technology, marketing and sales, customer service, and product development are most ripe for the first wave of generative AI applications. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI in IT: Code Generation**
Generative AI can help IT teams write code and documentation, improving developer productivity by more than 50 percent. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI in Marketing and Sales: Content Creation**
Teams can use generative AI applications to create content for customer outreach; within two years, 30 percent of all outbound marketing messages are expected to be developed with generative AI assistance. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI Creates New Content**
Generative AI's key difference from traditional AI is its ability to create new content in various modalities, including text, images, videos, and 3D representations. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI in Customer Service: Chatbots and Virtual Assistants**
Natural-sounding, personalized chatbots and virtual assistants can handle customer inquiries, recommend swift resolution, and guide customers to the information they need. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI in Product Development: Rapid Prototyping**
Companies can use generative AI to rapidly prototype product designs, such as in life sciences to generate sequences of amino acids and DNA nucleotides to shorten the drug design phase. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Industries with Outsize Operational Efficiencies**
Banking, consumer, telecommunications, life sciences, and technology companies are expected to experience outsize operational efficiencies from generative AI investments in IT, customer service, marketing and sales, and product development. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI Services: Filling Capability Gaps**
Dedicated generative AI services will emerge to help companies fill capability gaps and navigate business opportunities and technical complexities. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Competitive Advantage: Niche and Proprietary Data**
Those who can harness niche or proprietary data in fine-tuning foundation models for their applications can expect to achieve the greatest differentiation and competitive advantage. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI Model Capabilities**
Generative AI models are impressively capable, winning digital art awards and scoring highly on standardized tests like the US bar exam and SATs. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Generative AI Value Chain: Six Key Links**
The generative AI value chain consists of computer hardware, cloud platforms, foundation models, model hubs and MLOps, applications, and services. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Opportunity Size: Generative AI Applications**
The generative AI application market is expected to expand most rapidly and offer significant value-creation opportunities. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Hardware Requirements for Generative AI**
Generative AI systems require specialized hardware, including large clusters of GPUs or TPUs with accelerator chips, to process massive amounts of data. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Cloud Platforms Essential for Generative AI**
Cloud platforms are crucial for generative AI as they provide access to computational power and manage spending, making it easier for businesses to build, tune, and run large AI models. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Foundation Models: The Core of Generative AI**
Foundation models are large deep learning models pretrained to create specific types of content and can be adapted to support a wide range of tasks. — McKinsey 2023


---

**Source:** `McKinsey - exploring-opportunities-in-the-generative-ai-value-chain`

**Training Foundation Models is Expensive**
Training foundation models is expensive, costing millions of dollars and taking months due to the repetitive nature and substantial computational resources required. Training OpenAI's GPT-3 cost an estimated $4-12 million. — McKinsey 2023


---

**Source:** `McKinsey - what is generative ai`

**ChatGPT's Capabilities**
ChatGPT is a free chatbot developed by OpenAI that can generate answers to almost any question and is considered the best AI chatbot ever. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Generative AI Outputs Vary in Quality**
Outputs from generative AI models can range from indistinguishable from human-generated content to uncanny, depending on the model's quality and the match between the model and the use case. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Generative AI for Content Creation**
Generative AI tools can produce credible writing in seconds and respond to criticism, benefiting industries needing clear written materials. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Generative AI for Technical Materials**
Generative AI can create technical materials, such as higher-resolution versions of medical images. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Options for AI Implementation**
Companies can either use generative AI "out of the box" or fine-tune them to perform specific tasks. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Risks of Generative AI**
Generative AI models may produce inaccurate, biased, or manipulated information, leading to reputational and legal risks. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Mitigating AI Risks**
Risks can be mitigated by carefully selecting training data, using smaller specialized models, customizing general models, keeping a human in the loop, and avoiding AI for critical decisions. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Importance of Staying Informed**
The landscape of risks and opportunities in generative AI is rapidly evolving, requiring leaders to stay informed about regulation and risk. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Rapid Adoption of ChatGPT**
ChatGPT gained over a million users in just five days after its public release in November 2022. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**AI Adoption is Increasing**
A 2022 McKinsey survey shows that AI adoption has more than doubled over the past five years, and investment in AI is increasing. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**AI vs. Machine Learning**
Artificial intelligence mimics human intelligence to perform tasks, while machine learning is a type of AI where models learn from data patterns without human direction. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Machine Learning's Potential**
The increasing volume and complexity of data have amplified the potential and necessity of machine learning. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Generative AI Breakthrough**
Generative AI goes beyond perceiving and classifying content; it can create new content on demand, like an image or text description of a cat. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Self-Supervised Learning in Text Models**
Next-generation text-based machine learning models use self-supervised learning, where they are fed massive amounts of text to generate predictions. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**Resource Intensive Model Building**
Building generative AI models requires significant resources, including talent and vast amounts of data, making it accessible primarily to well-funded tech companies. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey - what is generative ai`

**GPT-3 Training Data**
GPT-3 was trained on approximately 45 terabytes of text data, costing an estimated several million dollars. — McKinsey Explainers, January 2023


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Gen AI Deployment is Expanding**
71% of organizations are regularly using generative AI in at least one business function, a notable increase from 65% in early 2024. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Text is the Most Common Gen AI Output**
63% of respondents reporting use of gen AI say that their organizations are using it to create text outputs, but organizations are also experimenting with images and computer code. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Gen AI's Impact on Enterprise-Level EBIT is Limited**
More than 80% of respondents say their organizations aren’t seeing a tangible impact on enterprise-level EBIT from their use of gen AI. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Supporting Fact: CEO Oversight Correlates with Higher Impact**
CEO's oversight of AI governance is one element most correlated with higher self-reported bottom-line impact from an organization's gen AI use, especially at larger companies. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Supporting Fact: Workflow Redesign Remains Uncommon**
Only 21% of respondents reporting gen AI use say their organizations have fundamentally redesigned at least some workflows. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Supporting Fact: Gen AI Output Review Varies Widely**
27% of respondents say employees review all content created by gen AI before it is used, while a similar share says that 20% or less is checked. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Supporting Fact: Mitigation of Gen AI Risks is Increasing**
Respondents are more likely than in early 2024 to say their organizations are actively managing risks related to inaccuracy, cybersecurity, and intellectual property infringement. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Supporting Fact: Limited Adoption of Scaling Practices**
Less than one-third of respondents report that their organizations are following most of the 12 adoption and scaling practices for gen AI. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Supporting Fact: Data Scientists Remain in High Demand**
Half of respondents whose organizations use AI say their employers will need more data scientists over the next year. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Quote: Top-Down Process is Essential**
"The more we see organizations using AI, the more we recognize that it takes a top-down process to really move the needle. Effective AI implementation starts with a fully committed C-suite and, ideally, an engaged board." — Alexander Sukharevsky, McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Quote: Think Big for Lasting Competitive Advantage**
"It pays to think big. The organizations that are building a genuine and lasting competitive advantage from their AI efforts are the ones that are thinking in terms of wholesale transformative change." — Alex Singla, McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Workflow Redesign Drives Gen AI Impact**
Redesigning workflows has the biggest impact on an organization's ability to see EBIT impact from its use of gen AI. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Quote: Focus on Adoption and Scaling**
"One significant difference is that these companies focus as much on driving adoption and scaling as they do on the up-front technology development." — Bryce Hall, McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Quote: AI Requires Enterprise Adaptation**
"AI only makes an impact in the real world when enterprises adapt to the new capabilities that these technologies enable." — Michael Chui, McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Critical Capability: CEO-Level Engagement**
Buy-side firms need to ensure active involvement and oversight from the CEO and other top leaders in AI governance and implementation to drive successful transformation.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Critical Capability: Workflow Redesign**
Firms must prioritize redesigning workflows to effectively embed gen AI solutions and maximize their impact on EBIT.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Critical Capability: Risk Mitigation**
Establish robust processes for mitigating risks related to inaccuracy, cybersecurity, intellectual property, and privacy in gen AI deployments.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Critical Capability: Data Governance and Quality**
Implement centralized data governance and quality control measures to ensure the reliability and trustworthiness of AI outputs.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Critical Capability: Talent Acquisition and Development**
Invest in acquiring and developing AI talent, particularly data scientists, and reskilling existing employees to effectively use AI tools.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Critical Capability: Adoption and Scaling Best Practices**
Implement and track the 12 adoption and scaling best practices, including establishing a dedicated team, internal communications, senior leader engagement, and KPI tracking.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**AI Roadmap: Stage 1 - Experimentation and Awareness**
Focus on raising awareness of AI capabilities, experimenting with gen AI tools, and identifying potential use cases across different business functions.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**AI Roadmap: Stage 2 - Workflow Integration and Risk Management**
Prioritize redesigning workflows to embed gen AI solutions, establishing robust risk mitigation processes, and implementing centralized data governance.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Centralized AI Deployment for Risk and Data Governance**
Organizations often use a fully centralized model, such as a center of excellence, for risk and compliance, as well as data governance related to AI deployment. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**AI Roadmap: Stage 3 - Scaling and Optimization**
Focus on scaling successful AI initiatives across the organization, tracking KPIs to measure impact, and optimizing workflows for maximum efficiency and value creation.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Measuring Success: EBIT Impact**
Track the impact of AI initiatives on enterprise-level EBIT to assess the overall value creation.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Measuring Success: Revenue Increase**
Monitor revenue increases within business units using gen AI to evaluate the effectiveness of specific deployments.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Measuring Success: Cost Reduction**
Assess cost reductions within business units using gen AI to determine the efficiency gains achieved through automation and optimization.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Measuring Success: Adoption and Scaling Metrics**
Track the adoption rate of AI tools and the implementation of scaling best practices to measure the progress of AI initiatives.


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Hybrid Approach for Tech Talent and AI Adoption**
A hybrid or partially centralized model is most commonly used for tech talent and adoption of AI solutions, with some resources handled centrally and others distributed. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Focus on Adoption and Scaling Best Practices**
Companies that capture value from gen AI focus as much on driving adoption and scaling as they do on technology development, following specific management practices. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Tracking KPIs is Crucial for Gen AI Success**
Tracking well-defined KPIs for gen AI solutions has the most impact on the bottom line, while establishing a clear road map is also critical for larger organizations. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Reskilling Efforts are Increasing**
Organizations have begun reskilling employees due to AI use, and respondents expect increased reskilling in the next three years. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: Gen AI Impact on Workforce Varies by Function**
Respondents most often predict that gen AI use will lead to decreased headcount in service operations and supply chain management, while expecting increased headcount in IT and product development. — McKinsey 2025


---

**Source:** `McKinsey 2025 the-state-of-ai-how-organizations-are-rewiring-to-capture-value_final`

**Key Finding: C-Level Executives Lead in Gen AI Usage**
53% of surveyed C-level executives say they are regularly using gen AI at work, compared with 44% of midlevel managers. — McKinsey 2025


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Responses API Flexibility**
The Responses API allows connection to both internal (file_search) and external vector databases (like Pinecone), enabling a versatile RAG solution. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Dynamic Query Processing**
The system processes each query dynamically, calling the Responses API with tools enabled and allowing parallel tool calls. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Tool Call Handling**
The system determines if a tool call is needed based on the initial response and processes it accordingly, invoking either the Pinecone search or a simulated web search. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Appending Tool Output to Conversation**
The tool call and its output are appended back into the conversation to generate a final answer incorporating the tool's result. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Sequential Tool Calling**
The cookbook demonstrates how multiple tool calls can be sequentially combined to generate a final response based on instructions provided to the Responses API. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Example of Tool Selection**
The model selects the appropriate tool based on the input query: general questions may be handled by web search, while specific medical inquiries are addressed by retrieving context from Pinecone. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Dataset Preparation for RAG**
A sample medical reasoning dataset from Hugging Face is used, with "Question" and "Response" columns merged into a single string for embedding and metadata storage. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Embedding Dimension Determination**
The embedding dimensionality is determined by computing an embedding from the merged question/answer text in the dataset. In this example, the embedding dimension is 1536 using the "text-embedding-3-small" model. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Pinecone Index Creation**
The cookbook details creating a Pinecone index using the determined embedding dimension and upserting the prepared dataset into the index for semantic search. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Querying the Pinecone Index**
A natural language query is embedded, and a similarity search is performed on the Pinecone index, returning results with metadata for context. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Generating Responses with Retrieved Context**
The OpenAI Responses API is used to generate a final answer by combining the retrieved context from Pinecone with the original question. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Available Tools for Orchestration**
The Responses API offers built-in functions like a web search preview tool and a Pinecone search tool for retrieving relevant documents. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Web Search Preview Tool**
This tool enables the model to perform live web searches and preview results, ideal for retrieving real-time or up-to-date information. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `Multi-Tool Orchestration with RAG approach using OpenAI_s Responses API _ OpenAI Cookbook`

**Pinecone Search Tool**
This tool allows the model to query a vector database using semantic search, useful for retrieving domain-specific content stored in a vectorized format. — [Shikhar Kwatra, OpenAI Cookbook]


---

**Source:** `NewGen-AI and Active Management`

**Industry's Open Secret: Closet Indexing**
For years, the asset management industry has operated under the fiction that large swathes of "active management" were really just factor tilts and benchmark-aware processes.


---

**Source:** `NewGen-AI and Active Management`

**GenAI Limitations in High-Precision Tasks**
GenAI will not crack the hardest problems in public markets like stock ranking and portfolio construction, which still rely on traditional machine learning and governed infrastructure.


---

**Source:** `NewGen-AI and Active Management`

**Fundamental Managers Misreading Quant Failures**
Fundamental managers feel safe watching quants struggle with AI, but they're misreading the failure; quants are failing because they're asking AI to do tabular precision inside linear workflows.


---

**Source:** `NewGen-AI and Active Management`

**The Real Threat: Novel AI Frameworks**
The real threat to fundamental managers is coming from teams building novel AI frameworks that bypass traditional roles entirely.


---

**Source:** `NewGen-AI and Active Management`

**Human Judgment Still Needed for Geopolitical Analysis**
GenAI cannot rescue you from geopolitics. Tariffs, sanctions, elections and regulatory shocks are not neatly structured inputs. A model can enumerate scenarios, but a human still has to weigh path dependencies, second-order effects and narrative shifts.


---

**Source:** `NewGen-AI and Active Management`

**Example: AI-Powered Responsible Investment Framework**
A 4-step framework can automate responsible investment governance, eliminating the need for ESG consultants and streamlining reporting cycles.


---

**Source:** `NewGen-AI and Active Management`

**The Future: Modular Hybrid Constructs**
The future of active management involves modular hybrid constructs, 3D-printed from human insight and machine execution, with a ringmaster orchestrating specialized intelligence.


---

**Source:** `NewGen-AI and Active Management`

**Agentic AI 2.0: Re-Architected Processes**
Agentic AI 2.0 requires completely re-architected processes for simultaneous, interconnected tasks where agents coordinate within constraints set by human overseers.


---

**Source:** `NewGen-AI and Active Management`

**Durable Moats: Private Data and Infrastructure**
The durable moats in AI-driven asset management are private data and private infrastructure for cleaning, aligning, and exploiting signals.


---

**Source:** `NewGen-AI and Active Management`

**Outcome-Based Pricing for AI Solutions**
As AI drives implementation, pricing models are evolving toward outcome-based pricing with shared risk between asset managers and technology providers.


---

**Source:** `NewGen-AI and Active Management`

**Key Quote: The only durable edge is cognitive.**
"The only durable edge is cognitive. Architect the frame in which machine intelligence explores, constrain it with institutional purpose, and reserve human judgement for the few decisions where context and accountability cannot be automated. Everything else belongs to the machine."


---

**Source:** `NewGen-AI and Active Management`

**Career Risk Drives Passive Adoption**
Boards and consultants choose passive strategies to avoid the appearance of making discretionary investment decisions and to reduce career and litigation risk.


---

**Source:** `NewGen-AI and Active Management`

**Workforce Implications: 80% of Roles May Disappear**
Approximately 80% of current roles in asset management may disappear as AI automates repeatable tasks, but the remaining 20% may be ill-suited to current professionals.


---

**Source:** `NewGen-AI and Active Management`

**Skills Gap: Systems Design and Hypothesis Engineering**
The skills gap is not just about learning new tools but about mastering systems design, hypothesis engineering, and live model governance, representing a fundamentally different cognitive domain.


---

**Source:** `NewGen-AI and Active Management`

**CFA Curriculum Vulnerability**
The CFA curriculum, with its emphasis on sequential analysis, is vulnerable unless it radically reimagines its pedagogy around systems thinking and AI-era practice.


---

**Source:** `NewGen-AI and Active Management`

**The Human Remainder: Strategy, Trust, Architecture, and Risk Oversight**
Several domains will remain distinctly human: strategy and governance, client-facing trust roles, technology and systems architecture, and model operators.


---

**Source:** `NewGen-AI and Active Management`

**Emerging Role: Risk Overseer**
A new role is emerging: the Risk Overseer, responsible for designing operating boundaries for AI systems, setting error tolerances, and embedding ethical constraints.


---

**Source:** `NewGen-AI and Active Management`

**High-Value Skills of Tomorrow**
High-value skills include non-linear thinking, system design, interdisciplinary synthesis, and the ability to frame human intuition for scaling.


---

**Source:** `NewGen-AI and Active Management`

**Career Migration Paths**
Analysts need to move toward data ontology design and prompt engineering, operations professionals to model validation, compliance to AI policy, and portfolio managers to framework architects.


---

**Source:** `NewGen-AI and Active Management`

**Cross-Industry Lessons: Automation's Trajectory**
Finance is following the same trajectory as other industries: routine tasks get automated, then complicated-but-systematic tasks, and finally everything that can be expressed as rules or patterns.


---

**Source:** `NewGen-AI and Active Management`

**Implementation-Agnostic Endgame**
We're heading toward an implementation-agnostic future where labels become legacy semantics, and the only meaningful question is how effectively a process combines human insight and machine capability.


---

**Source:** `NewGen-AI and Active Management`

**McKinsey's Limited Vision**
A McKinsey report identifies key challenges but misses the full potential of AI because it's still thinking linearly about non-linear intelligence.


---

**Source:** `NewGen-AI and Active Management`

**Passive is a Quantitative Model**
Passive investing is essentially a simple, systematic quantitative model that tracks a benchmark, making the distinction between active and passive largely cosmetic.


---

**Source:** `NewGen-AI and Active Management`

**The Right Question: Process Design for Active Management**
The right question is whether your process design ever supported real active management in the first place, as AI is forcing us to admit how little of it actually existed.


---

**Source:** `NewGen-AI and Active Management`

**Organizational Reconstruction, Not Just Job Replacement**
The real disruption isn't job replacement but organizational reconstruction, with entirely new structures designed around AI's non-linear, liquid intelligence.


---

**Source:** `NewGen-AI and Active Management`

**AI Cannot Replace Human Inspiration**
AI can handle the 99% perspiration, but it cannot produce the 1% inspiration, which is essential for true active management.


---

**Source:** `NewGen-AI and Active Management`

**AI Exposes Fake Active Management**
AI threatens the middle ground of "fake active management" by executing systematic processes better, faster, and cheaper than humans.


---

**Source:** `NewGen-AI and Active Management`

**AI Cognition: Quantum Superposition of Strategies**
AI operates non-linearly, exploring thousands of paths simultaneously, existing in a "liquid Möbius state" where multiple possibilities coexist until the optimal solution crystallizes.


---

**Source:** `NewGen-AI and Active Management`

**Key Quote: AI is not a drug, it's a different species of intelligence.**
"AI isn't a drug; it's a different species of intelligence. It needs different structures, different processes, and different frameworks to thrive."


---

**Source:** `NewGen-AI and Active Management`

**AI Implementation Failures Stem from Process Architecture**
AI implementations often fail because firms try to inject AI into existing linear workflows designed for closet indexing, rather than creating AI-native frameworks.


---

**Source:** `NewGen-AI and Active Management`

**Cultural Friction Hinders AI Adoption**
The industry's credentialed professionals resist role redefinition because their identity is wrapped up in analytical frameworks that AI makes obsolete.


---

**Source:** `NewGen-AI and Active Management`

**Commoditization of Research and Reporting**
Earnings call summarization and sentiment extraction are becoming commodity services, creating pressure for efficiency gains in asset management.


---

**Source:** `PEFT-2403.14608v7`

**Key Finding: PEFT Techniques are Applicable Across Diverse Model Architectures and Tasks**
PEFT's versatility extends beyond NLP, finding applications in computer vision (Vision Transformers, diffusion models) and vision-language models, underscoring its broad applicability.


---

**Source:** `PEFT-2403.14608v7`

**Best Practice: Consider Structured Pruning for Hardware Efficiency**
Structured masking organizes parameter masking in regular patterns, unlike unstructured ones that apply it randomly, thus enhancing computational and hardware efficiency during training.


---

**Source:** `PEFT-2403.14608v7`

**Measuring Success: Key Metrics for PEFT Serving Systems**
System throughput (tokens per second), memory footprint, accuracy performance (with varying context lengths), and quality of services (latency, deadline missing rates) are important metrics.


---

**Source:** `PEFT-2403.14608v7`

**Measuring Success: Key Metrics for PEFT Training Systems**
Accuracy performance of the fine-tuned model, compute cost during forward and backward propagation, and communication cost (data transfer between edge and cloud) are important metrics.


---

**Source:** `PEFT-2403.14608v7`

**AI Roadmap: Future Directions in PEFT Research**
Simplify hyperparameter tuning, establish a unified benchmark, enhance training efficiency, explore scaling laws, serve more models and tasks, enhance data privacy, and PEFT with model compression.
```


---

**Source:** `PEFT-2403.14608v7`

**Key Finding: PEFT Methods Can Be Categorized into Additive, Selective, Reparameterized, and Hybrid Approaches**
These categories differ in how they modify the model architecture, tune existing parameters, or combine different PEFT techniques.


---

**Source:** `PEFT-2403.14608v7`

**Supporting Fact: LLaMA Architecture Consists of Three Major Components**
LLaMA consists of an embedding block, a stack of decoder blocks (MSA and FFN), and a head block (linear and softmax layer). — Section II-A


---

**Source:** `PEFT-2403.14608v7`

**Supporting Fact: Standard Full Fine-Tuning is Highly Inefficient for Large Models**
Full fine-tuning of LLMs requires thousands of GPUs working in parallel, which is highly inefficient and unsustainable. PEFT aims to tune minimal parameters to achieve better performance.


---

**Source:** `PEFT-2403.14608v7`

**Key Quote: "Fine-tuning remains essential to enhance LLM performance on unseen user datasets and tasks."**
This highlights the ongoing need for adaptation despite the generalization capabilities of large language models.


---

**Source:** `PEFT-2403.14608v7`

**Critical Capability: Efficient KV-Cache Management is Crucial for LLM Inference**
Storing previous Keys and Values in the Key-Value cache (KV-cache) accelerates the inference process in LLM models by avoiding recalculation for each new token.


---

**Source:** `PEFT-2403.14608v7`

**Critical Capability: Balancing Latency and Memory Usage is a Key System Design Challenge**
Efficient handling of numerous task-specific queries via centralized PEFT query servicing, resolving privacy and data transmission issues through distributed PEFT training, and the complexities associated with concurrent multi-PEFT training processes are key challenges.


---

**Source:** `PEFT-2403.14608v7`

**AI Roadmap: Stages of PEFT Implementation**
1. Register PEFT tasks through a standardized API.
2. Provide the Pre-Trained Model Tag, PEFT parameters in a compressed format, and the specific PEFT algorithms.
3. The inference engine takes charge of query processing. — PetS Framework


---

**Source:** `PEFT-2403.14608v7`

**Decisions: Selecting the Right PEFT Technique**
The choice of PEFT technique (Adapter, Soft Prompt, LoRA, etc.) depends on the specific task, model architecture, and available computational resources. Hybrid approaches can combine the strengths of different techniques.


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**RAG: Augmenting LLMs with external knowledge.**
RAG enhances LLMs by retrieving relevant information from external knowledge sources before generating a response, making it suitable for applications needing to query databases or documents. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Question/Answering System Use Case: RAG is the better choice.**
For question/answering systems relying on organizational knowledge, RAG is more fitting due to its dynamic access to internal databases and potential for transparency. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Customer Support Automation Use Case: Hybrid approach is optimal.**
Customer support automation benefits from a hybrid approach, using finetuning for general knowledge and branding, and RAG for dynamic or specific inquiries and hallucination reduction. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Scalability Considerations:**
RAG systems may offer more straightforward scalability as knowledge bases grow, whereas frequent finetuning can be computationally demanding. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Latency and Real-time Requirements:**
RAG systems might introduce more latency compared to finetuned LLMs due to the data retrieval step. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Maintenance and Support:**
RAG requires upkeep of the database and retrieval mechanism, while finetuning necessitates consistent retraining efforts. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Cost Considerations:**
Finetuning can be expensive, especially for large models, while RAG involves initial setup costs and ongoing maintenance of the knowledge base. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Complexity Considerations:**
Finetuning can become complex with version control and ensuring consistent performance, while RAG involves setting up multiple components and ensuring they fit together well. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Finetuning: Adapting LLMs to specific tasks and styles.**
Finetuning adapts a pre-trained LLM to a specific task or domain by training it on a smaller, specific dataset, allowing for customization of behavior, writing style, and domain-specific knowledge. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Key Consideration: Access to external data sources favors RAG.**
If an application requires access to external data sources, RAG is generally more effective and scalable than finetuning, which struggles with frequently changing data. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Key Consideration: Model behavior and style adaptation favors Finetuning.**
Finetuning excels at adapting an LLM's behavior, writing style, or domain-specific knowledge, making it ideal when alignment with a particular style or expertise is vital. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**RAG reduces hallucinations by grounding responses in retrieved evidence.**
RAG systems are inherently less prone to hallucinations because they ground each response in retrieved evidence, acting as a fact-checking mechanism. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Finetuning requires substantial labelled training data.**
Finetuning's effectiveness depends on the quality and quantity of labelled data; limited data can lead to marginal improvements or overfitting. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**RAG excels with dynamic data.**
RAG systems are advantageous in environments with dynamic data because their retrieval mechanism constantly queries external sources, ensuring up-to-date information. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**RAG offers greater transparency and interpretability.**
RAG provides transparency by allowing users to inspect the retrieved documents or data points that influenced a response, fostering greater trust and understanding. — Heiko Hotz, Towards Data Science


---

**Source:** `RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application_ _ by Heiko Hotz _ Aug, 2023 _ Towards Data Science`

**Summarization Use Case: Finetuning is the better choice.**
For summarization tasks requiring stylistic alignment, finetuning is generally more suitable, assuming sufficient training data is available. — Heiko Hotz, Towards Data Science


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Key Finding: Finetuning Improves Performance**
Adapting and finetuning an LLM on a target task using data from the target domain generally yields better results than relying solely on in-context learning. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Adapter Performance and Efficiency**
A BERT model trained with adapters can reach performance comparable to a fully finetuned BERT model while training only a small percentage (e.g., 3.6%) of the parameters. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**LLaMA-Adapter: Combining Prefix Tuning and Adapters**
LLaMA-Adapter prepends tunable prompt tensors to the embedded inputs, similar to prefix tuning, but also introduces a zero-initialized attention mechanism and gating. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**LLaMA-Adapter: Focus on Top Layers**
LLaMA-Adapter adds learnable adaption prompts only to the topmost transformer layers, enabling more effective tuning of language representations. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**LLaMA-Adapter Training Stability**
LLaMA-Adapter uses a gating mechanism to stabilize training by mitigating the potential disruption of linguistic knowledge caused by randomly initialized tensors. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**LLaMA-Adapter Performance and Efficiency**
A 7 billion parameter LLaMA model can be finetuned in one hour using eight A100 GPUs with LLaMA-Adapter, outperforming other models on question-answering tasks while only finetuning 1.2M parameters. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Key Capability: Selecting the Right Finetuning Method**
Buy-side firms need to evaluate the trade-offs between performance, computational cost, and data requirements when selecting a finetuning method (full finetuning, prefix tuning, adapters, LLaMA-Adapter). — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Key Capability: Understanding Licensing Implications**
Firms must consider the licensing implications of different LLM implementations (e.g., GPL vs. Apache) when choosing a model and finetuning approach. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Best Practice: Tailoring LLMs to Specific Business Needs**
Finetuning pre-trained LLMs allows firms to tailor these models to suit specific business requirements and align them with target domain data. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Three Conventional Finetuning Approaches**
The three conventional approaches to finetuning LLMs are: feature-based approach, updating the output layers (finetuning I), and updating all layers (finetuning II). — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Feature-Based Approach**
The feature-based approach involves using a pre-trained LLM to generate output embeddings for a training set, which are then used as input features for a separate classification model. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Finetuning I: Updating Output Layers**
Finetuning I keeps the parameters of the pre-trained LLM frozen and only trains the newly added output layers, similar to training a classifier on embedded features. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Finetuning II: Updating All Layers**
Finetuning II updates all layers of the pre-trained LLM, typically resulting in superior modeling performance compared to only updating the output layers, but at a higher computational cost. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Performance vs. Cost Trade-off in Finetuning**
Finetuning more layers generally leads to better performance, but it also increases the computational cost. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Prefix Tuning**
Prefix tuning adds a trainable tensor to each transformer block, instead of only the input embeddings, to improve modeling performance on a target task. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Prefix Tuning Efficiency**
Prefix tuning can achieve comparable performance to finetuning all layers while only training a small percentage (e.g., 0.1%) of the parameters. — Raschka-Parameter-efficient-finetuning


---

**Source:** `Raschka-Parameter-efficient-finetuning`

**Adapters: Adding Layers to Transformer Blocks**
The adapter method adds adapter layers in two places within each transformer block, using bottleneck structures to achieve parameter efficiency. — Raschka-Parameter-efficient-finetuning


---

**Source:** `ReAct - 2210.03629v3`

**Key Finding: ReAct Outperforms Baselines**
ReAct demonstrates effectiveness over state-of-the-art baselines in question answering, fact verification, and interactive decision-making tasks. It shows improved human interpretability and trustworthiness. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Supporting Fact: WebShop Performance Improvement**
ReAct achieves an absolute success rate improvement of 10% on WebShop compared to imitation learning and imitation + reinforcement learning methods. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Key Finding: ReAct's Groundedness and Trustworthiness**
ReAct's problem-solving trajectory is more factual and grounded compared to Chain-of-Thought reasoning, thanks to its access to an external knowledge base. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Limitation: Reasoning Error in ReAct**
ReAct can sometimes exhibit a higher reasoning error rate than CoT due to the structural constraint of interleaving reasoning, action, and observation steps, which can reduce flexibility. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Critical Capability: Human-in-the-Loop Interaction**
ReAct allows for human-in-the-loop interaction, enabling users to inspect and edit reasoning traces to correct or guide the model's behavior. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Best Practice: Sparse Reasoning in Decision Making**
Sparse, versatile reasoning in decision making tasks is more effective than dense, external feedback-driven approaches like Inner Monologue (IM). — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**AI Roadmap: Scaling Up ReAct**
Future directions include scaling up ReAct with multi-task training and combining it with reinforcement learning to unlock further potential of LLMs. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Ethics Statement: Risk Awareness**
Researchers should be aware of potential risks when hooking up LLMs with action spaces to interact with external environments, such as accessing inappropriate information or taking harmful actions. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Key Quote: Easy to Design**
"Designing ReAct prompts is straightforward as human annotators just type down their thoughts in language on top of their actions taken. No ad-hoc format choice, thought design, or example selection is used in this paper." — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**ReAct Addresses Hallucination and Error Propagation**
By interacting with external sources like a Wikipedia API, ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**ReAct Improves Interactive Decision Making**
On interactive decision-making benchmarks like ALFWorld and WebShop, ReAct outperforms imitation and reinforcement learning methods with significant improvements in success rates. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Key Quote: Synergy Between Acting and Reasoning**
"This tight synergy between 'acting' and 'reasoning' allows humans to learn new tasks quickly and perform robust decision making or reasoning, even under previously unseen circumstances or facing information uncertainties." — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Critical Capability: Designing ReAct Prompts**
Designing ReAct prompts involves creating human trajectories of actions, thoughts, and environment observations to solve a task instance, which are then used as few-shot examples for the LLM. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Critical Capability: Combining Internal and External Knowledge**
Combining ReAct with Chain-of-Thought Self-Consistency (CoT-SC) leverages both internal knowledge and externally obtained information, improving performance in knowledge-intensive reasoning tasks. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**AI Roadmap: Finetuning for Improved Performance**
While ReAct performs well with prompting, finetuning with generated trajectories can further improve performance, especially for smaller language models. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Measuring Success: Performance Metrics**
Performance is measured using metrics like exact match (EM) for question answering, accuracy (Acc) for fact verification, and success rate (SR) and score for interactive decision-making tasks. — [Yao et al., 2023]


---

**Source:** `ReAct - 2210.03629v3`

**Supporting Fact: ALFWorld Performance Improvement**
ReAct achieves an absolute success rate improvement of 34% on ALFWorld compared to imitation or reinforcement learning methods. — [Yao et al., 2023]


---

**Source:** `ReAct - A simple Python implementation of the ReAct pattern for LLMs _ Simon Willison’s TILs`

**Key Capability: Implementing Actions for LLMs**
Buy-side firms can enhance LLMs by implementing custom actions tailored to financial tasks, such as accessing market data, running financial models, or querying internal databases.


---

**Source:** `ReAct - A simple Python implementation of the ReAct pattern for LLMs _ Simon Willison’s TILs`

**Example Actions for ReAct Pattern**
The author implemented actions like `wikipedia`, `simon_blog_search`, and `calculate` to demonstrate how an LLM can be extended with new capabilities.


---

**Source:** `ReAct - A simple Python implementation of the ReAct pattern for LLMs _ Simon Willison’s TILs`

**Critical Capability: Secure Action Execution**
When implementing actions like `calculate`, it's crucial to use secure sandboxing techniques (e.g., WebAssembly) to prevent malicious code execution. The author notes the use of `eval()` is "dangerous".


---

**Source:** `ReAct - A simple Python implementation of the ReAct pattern for LLMs _ Simon Willison’s TILs`

**AI Roadmap: Iterative Development and Refinement**
The author's implementation is described as a "very rough implementation" with "a ton of room for improvement," highlighting the iterative nature of AI development.


---

**Source:** `ReAct - A simple Python implementation of the ReAct pattern for LLMs _ Simon Willison’s TILs`

**Key Quote: Ease of Implementation**
"It really does just take a few dozen lines of Python to make these extra capabilities available to the LLM and have it start to use them." — Simon Willison


---

**Source:** `ReAct - A simple Python implementation of the ReAct pattern for LLMs _ Simon Willison’s TILs`

**Decisions about what technology and workflows to implement**
The author chose to build the ReAct pattern from scratch using a tiny Python wrapper for the ChatGPT API, rather than using a framework like Langchain.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**LangChain Simplifies Complex AI Tasks**
LangChain is a software framework that simplifies the process of using OpenAI's GPT models in iterative loops, incorporating external data sources like Wikipedia.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Google's PaLM-SayCan for Robotics**
Google's PaLM-SayCan project uses large language models for step-by-step reasoning and planning to control home helper robots.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Simplicity of Implementation is Surprising**
The author found the implementation of LangChain and ReAct surprisingly simple, with minimal code required for goal-directed reasoning and tool use.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**GPT-4 Benchmarked with Simulated Exams**
OpenAI benchmarked GPT-4 using simulated exams, such as the Uniform Bar Exam, demonstrating its advanced capabilities.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**GPT-4 System Card Details Potential Harms**
The GPT-4 System Card is a detailed description of how the AI interacts with humans, paying special attention to where it might be harmful.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**GPT-4 Can Invent and Purchase Molecules**
GPT-4 is capable of inventing and purchasing synthesized versions of new molecules, potentially dangerous ones, by conducting lit review, using chemistry tools, and contacting suppliers.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**GPT-4 Not Yet Capable of Self-Replication**
GPT-4 is not capable of autonomous, power-seeking behavior, such as copying itself to a new server, and hiring help on TaskRabbit to cover its traces.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Experiment Simulates Autonomous Agent Behavior**
An experiment combined GPT-4 with a read-execute-print loop to simulate an agent acting in the world, testing its ability to make money and replicate itself.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Self-Evolution is a Future Concern**
The author suggests that self-evolution, where AI can create more capable versions of itself, is a more pressing concern than self-replication.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Singularity Depicts Exponential Runaway**
The author references Vernor Vinge's essay on the technological singularity, describing it as an exponential runaway beyond human control.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Singularity May Occur Faster Than Expected**
The author suggests that the singularity may occur faster than previous technical revolutions, potentially precipitated by an unexpected event.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**ReAct Framework Enables Reasoning and Tool Use**
The ReAct framework prompts language models to respond in a thought/act/observation loop, allowing for reasoning, goal-directed action, and tool use. — [Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022)]


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**ReAct Circumvents LLM "Lying"**
By providing language models with access to factual sources through the ReAct framework, the problem of LLMs generating false information is mitigated.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Extensible Tool Use is Key**
The ability to define and access various tools (databases, calculators, systems) for AI agents is crucial for expanding their capabilities.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Example: NBA Statistics Program**
Geoffrey Litt's program uses LangChain and ReAct to answer multi-part questions about NBA statistics by querying Statmuse and using a calculator.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**AI Can Learn from Errors**
In Litt's example, the AI agent adapted its query to Statmuse based on an initial error message, demonstrating the ability to learn from feedback.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**Reduced Cost Makes AI Loops Feasible**
The recent price drop in OpenAI's GPT API makes iterative AI loops, which require multiple calls, more economically viable.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**AI as a Universal Coupling**
Language models can act as universal couplers, enabling plain language protocols for communication between systems.


---

**Source:** `ReAct - The surprising ease and effectiveness of AI in a loop (Interconnected)`

**GPT Can Control External Systems**
Nat Friedman demonstrated GPT's ability to control a web browser to book a table at a restaurant, highlighting its potential to interact with external systems.


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Time Reduction with ChatGPT**
Participants using ChatGPT spent 37% less time on writing tasks compared to the control group. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Increase in Job Satisfaction**
ChatGPT increased job satisfaction by about 0.40 standard deviations. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Key Finding: ChatGPT Affects Beliefs About Automation**
Exposure to ChatGPT heightens both concern and excitement about automation technologies. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Changes in Automation Beliefs**
Worry about automation increased by 0.26 standard deviations, excitement increased by 0.39 standard deviations, and net optimism increased by about 0.20 standard deviations. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Continued ChatGPT Usage**
In a two-week follow-up, 33% of former treatment group participants used ChatGPT in their jobs, compared to 18% of the control group. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Limitation: Context-Specific Knowledge**
The study acknowledges that the tasks were relatively short, self-contained, and lacked a dimension of context-specific knowledge, which may inflate estimates of ChatGPT's usefulness. — [Noy & Zhang, 2023]
```


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Quality Improvement with ChatGPT**
Evaluator grades for writing quality, content, and originality increased by 0.45 standard deviations when participants used ChatGPT. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Key Finding: ChatGPT Reduces Productivity Inequality**
ChatGPT compresses the productivity distribution by disproportionately benefiting lower-ability workers, partially erasing initial performance inequalities. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Correlation Reduction in Grades**
The correlation between first-task and second-task grades was halved in the treatment group (0.25) compared to the control group (0.49), indicating a reduction in inequality. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Key Finding: ChatGPT Substitutes Effort, Not Skills**
The study suggests that ChatGPT primarily substitutes for worker effort by quickly generating satisfactory output, rather than complementing worker skills through brainstorming or editing assistance. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Limited Editing of ChatGPT Output**
68% of participants submitted ChatGPT's initial output without editing, and there was no correlation between time spent editing and the final grade. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Key Finding: ChatGPT Reshapes Task Structure**
ChatGPT shifts the focus of writing tasks from rough-drafting to idea generation and editing. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Supporting Fact: Shift in Time Allocation**
Post-treatment, the share of time spent writing a rough draft fell by more than half, while the share of time spent editing more than doubled. — [Noy & Zhang, 2023]


---

**Source:** `SSRN-id4375283`

**Key Finding: ChatGPT Increases Job Satisfaction**
Access to ChatGPT substantially increases job satisfaction among participants. — [Noy & Zhang, 2023]


---

**Source:** `Seizing the agentic AI advantage`

**Supporting Fact: Gen AI Adoption vs. Impact**
More than 78% of companies are using gen AI in at least one business function, but over 80% report no material contribution to earnings from these initiatives. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Recommendation: Cross-Functional Transformation Squads**
Organizations must shift to a cross-functional delivery model, anchored in durable transformation squads composed of business domain experts, AI engineers, IT architects, and data engineers. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Recommendation: Industrialized, Scalable Delivery**
Organizations must shift to an industrialized delivery model, in which solutions are designed from the outset to scale, both technically and financially. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Workforce Upskilling**
Organizations need to upskill the workforce, adapt the technology infrastructure, accelerate data productization, and deploy agent-specific governance mechanisms to effectively operate in the agentic era. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**CEO Mandate: End Experimentation Phase**
The time has come to bring the gen AI experimentation phase to a close, a pivot that only the CEO can make. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Decision: Custom vs. Off-the-Shelf Agents**
Realizing the full potential of agentic AI will require the development of custom-built agents for high-impact processes, as off-the-shelf agents may only streamline routine workflows. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Managing AI Risks**
Organizations must manage the new wave of risks that AI agents bring, including uncontrolled autonomy, fragmented system access, and lack of observability. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Agent and Workflow Discovery**
Agent and workflow discovery maintains a dynamic catalog of all organizational agents and workflows, enabling reuse across teams and enforcing policies on agent use. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: AI Asset Registry**
AI asset registry centralizes governance of system prompts, agent instructions, LLM configurations, tool definitions, and golden records while creating policies about version control and access. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Observability**
Observability provides end-to-end tracing of workflows spanning agentic and procedural systems through standardized metrics, audit logs, and diagnostic capabilities. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Authentication and Authorization**
Authentication and authorization enforce fine-grain access controls for communication among agentic systems, procedural systems, and LLMs, enforcing security policies and limiting the "blast radius" of compromised systems or agents. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Finding: Imbalance of AI Use Cases**
The gen AI paradox stems from an imbalance between widely deployed "horizontal" (enterprise-wide) copilots with diffuse gains and transformative "vertical" (function-specific) use cases stuck in pilot mode. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Evaluations**
Evaluations deliver comprehensive testing of agent pipelines to ensure accuracy and compliance over time. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Feedback Management**
Feedback management enables continuous improvement through automated feedback loops that capture performance metrics to evolve agent configurations. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Compliance and Risk Management**
Compliance and risk management embed policy controls, compliance agents, and ethical guardrails to ensure workflows meet regulatory and institutional standards. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Best Practice: Human-Agent Cohabitation**
Agents won't just assist humans—they'll act alongside them. Building clarity around these roles will take time, experimentation, and cultural adjustment. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Best Practice: Autonomy Control**
The challenge is not to eliminate autonomy but to make it intelligible and aligned with organizational expectations. Control mechanisms must also address the risk of hallucinations. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Best Practice: Sprawl Containment**
Organizations must avoid agent sprawl through structured governance, design standards, and life cycle management. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**AI Roadmap: Three Key Actions for CEOs**
1. Conclude the experimentation phase and realign AI priorities. 2. Redesign the AI governance and operating model. 3. Launch a first lighthouse transformation project and simultaneously initialize the agentic AI tech foundation. — McKinsey, June 2025
```


---

**Source:** `Seizing the agentic AI advantage`

**Supporting Fact: Vertical Use Case Deployment**
Fewer than 10% of function-specific (vertical) gen AI use cases ever make it past the pilot stage. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Finding: AI Agents as a Solution**
AI agents offer a way to break out of the gen AI paradox by automating complex business processes and shifting gen AI from a reactive tool to a proactive, goal-driven virtual collaborator. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Capability: Process Reinvention**
Unlocking the full potential of agentic AI requires reimagining workflows from the ground up, with agents at the core, rather than simply plugging agents into existing processes. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Capability: Agentic AI Mesh Architecture**
A new AI architecture paradigm—the agentic AI mesh—is needed to govern the evolving AI landscape, blend custom and off-the-shelf agents, and manage technical debt and risks. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Critical Challenge: Human Trust and Governance**
The biggest challenge in scaling agentic AI won't be technical, but human: earning trust, driving adoption, and establishing the right governance to manage agent autonomy and prevent uncontrolled sprawl. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Recommendation: Strategic AI Programs**
To scale impact, organizations must shift from scattered AI initiatives to strategic programs, aligning AI with critical strategic priorities. — McKinsey, June 2025


---

**Source:** `Seizing the agentic AI advantage`

**Key Recommendation: Focus on Business Processes**
AI initiatives should focus on transforming entire business processes by embedding agents throughout the value chain, rather than optimizing isolated tasks. — McKinsey, June 2025


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Supporting Fact: AlphaProof's Success in Mathematics**
AlphaProof achieved a medal in the International Mathematical Olympiad by generating a hundred million proofs through continual interaction with a formal proving system, surpassing human-centric approaches.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**AI Roadmap: Reconciling Simulation and Generality**
The roadmap involves reconciling the ability of RL agents to self-discover knowledge (as seen in AlphaZero) with the task-generality achieved in the era of human data.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Reinforcement Learning Methods: Revisit and Improve Classic RL Concepts**
The era of experience presents an opportunity to revisit and improve classic RL concepts, such as value functions, exploration techniques, and world models.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Consequences: Acceleration of Scientific Discovery**
AI agents will autonomously design and conduct experiments in fields like materials science, medicine, or hardware design. By continuously learning from the results of their own experiments, these agents could rapidly explore new frontiers of knowledge, leading to the development of novel materials, drugs, and technologies at an unprecedented pace.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Consequences: Safety Benefits of Experiential Learning**
Experiential agents can adapt to changes in their environment and correct misaligned reward functions over time, potentially mitigating safety risks associated with fixed AI systems.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**AI Roadmap: Continuous Adaptation and Goal Correction**
The roadmap includes mechanisms for continuous adaptation to environmental changes and incremental correction of misaligned reward functions based on human feedback.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Key Finding: Experiential Data Will Eclipse Human Data**
Ultimately, experiential data will eclipse the scale and quality of human-generated data, leading to new capabilities that surpass those possessed by any human.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Key Quote: DeepSeek AI on Reinforcement Learning**
"Rather than explicitly teaching the model on how to solve a problem, we simply provide it with the right incentives, and it autonomously develops advanced problem-solving strategies." — DeepSeek AI


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Critical Capability: Long-Term Streams of Experience**
Buy-side firms need to develop AI agents that can operate within long-term streams of experience, adapting and learning continuously over time, rather than focusing on short, isolated interactions. This requires infrastructure to track and analyze data over extended periods.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Critical Capability: Grounded Actions and Observations**
AI agents should interact with the real world through motor control, sensors, and digital interfaces, not just human dialogue. This includes using APIs, executing code, and interacting with computer interfaces.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Critical Capability: Grounded Rewards**
Buy-side firms should move away from relying solely on human prejudgment for rewards and instead use grounded rewards based on real-world signals and consequences, such as market performance metrics or client satisfaction scores.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Measuring Success: Impact of Grounded Rewards**
Success can be measured by the agent's ability to discover strategies that humans might not appreciate, leading to better performance and insights.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Decision: Flexible Reward Adaptation**
Implement reward functions that can be flexibly adapted based on grounded signals and user feedback, allowing for continuous improvement and alignment with user goals.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Critical Capability: Planning and Reasoning Beyond Human Terms**
Buy-side firms should explore AI systems that can plan and reason using non-human languages and methods, such as symbolic or differentiable computations, to overcome the limitations of human thought processes.


---

**Source:** `Silver and Sutton - The Era of Experience Paper`

**Critical Capability: World Modeling**
Develop world models that predict the consequences of the agent's actions on the world, including predicting rewards. This allows the agent to plan directly in terms of its own actions and their causal effect upon the world.


---

**Source:** `The Adoption of ChatGPT`

**Supporting Fact: Adoption Rates Vary by Occupation**
ChatGPT adoption rates range from 79% for software developers to 34% for financial advisors, highlighting differences based on skill and employer restrictions. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Key Quote: Firm's Role in Adoption**
"Looking ahead, firms could play a critical role in facilitating the further adoption of Generative AI such as ChatGPT." — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Key Quote: Concerning Patterns in Adoption**
"Despite the potential of Generative AI to alleviate existing inequalities, workers who currently use ChatGPT earned slightly more before its arrival. Hence, workers with less expertise may need further assistance to reap the benefits of Generative AI." — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**AI Roadmap: Addressing Adoption Frictions**
Firms should address adoption frictions such as the need for training and employer restrictions to unlock the productivity potential of ChatGPT.


---

**Source:** `The Adoption of ChatGPT`

**Measuring Success: Addressing Gender Gap in AI Adoption**
Success in AI adoption should be measured by whether it reduces the gender gap in technology usage, indicating equitable access and training.


---

**Source:** `The Adoption of ChatGPT`

**Supporting Fact: Women's Responsiveness to Information**
Women's beliefs are more than twice as responsive to information treatments about ChatGPT, but they face barriers that prevent further adoption. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Decision: Overcoming Barriers to Adoption**
Firms should focus on overcoming barriers to adoption, such as the need for training, especially for women, to realize the full potential of ChatGPT.


---

**Source:** `The Adoption of ChatGPT`

**Key Finding: Gender Gap in ChatGPT Adoption**
Women are 20 percentage points less likely to use ChatGPT than men in the same occupation, even when controlling for detailed task mixes. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Supporting Fact: Productivity Potential of ChatGPT**
Workers estimate that ChatGPT can halve working times in about a third of their job tasks, confirming expert predictions about its productivity potential. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Key Finding: Barriers to ChatGPT Adoption**
Restrictions on use and needing training are the primary barriers to ChatGPT adoption, highlighting the role of firm policies. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Supporting Fact: Limited Cross-Task Substitution**
38% of workers report they will not perform more of the tasks ChatGPT saves time completing, suggesting limited reallocation between job tasks in the short run. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Key Finding: Information Shifts Beliefs, Limited Adoption**
Informing workers about expert assessments of ChatGPT shifts their beliefs, but has limited impact on actual adoption. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Critical Capability: Facilitating Employee Training**
Employers could help more workers unlock the productivity potential of Generative AI by facilitating employee training. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Decision: Addressing Gender Disparities**
A planned effort to train workers could help resolve the gender gap in adoption, as many women report they need training to use ChatGPT. — Humlum & Vestergaard, 2024


---

**Source:** `The Adoption of ChatGPT`

**Best Practice: Proactive Firm Involvement**
Firms could play a critical role in facilitating the further adoption of Generative AI such as ChatGPT by providing guidelines for productive use. — Humlum & Vestergaard, 2024


---

**Source:** `The Era of Experience Paper`

**Key Finding: Limitations of Human-Centric AI**
While imitating humans allows AI to reproduce human capabilities to a competent level, it is unlikely to achieve superhuman intelligence across many important topics and tasks. Valuable new insights lie beyond the boundaries of human understanding and cannot be captured by existing human data.


---

**Source:** `The Era of Experience Paper`

**AI Roadmap: Phase 2 - Integrate Grounded Actions and Observations**
Integrate AI agents that can act autonomously in the real world through motor control and sensors, rather than relying solely on human-privileged communication channels like text input/output.


---

**Source:** `The Era of Experience Paper`

**AI Roadmap: Phase 3 - Utilize Grounded Rewards**
Utilize rewards grounded in real-world signals and environmental feedback, rather than relying solely on human prejudgment, to enable AI to discover strategies that humans may not appreciate.


---

**Source:** `The Era of Experience Paper`

**AI Roadmap: Phase 4 - Develop Non-Human Reasoning**
Develop AI systems to develop non-human reasoning methods, such as symbolic or distributed computations, that may be more efficient than imitating human thought processes.


---

**Source:** `The Era of Experience Paper`

**AI Roadmap: Phase 5 - Build World Modeling Capabilities**
Build AI agents that can build world models to predict the consequences of their actions, including predicting rewards, allowing them to plan effectively and adapt to changing environments.


---

**Source:** `The Era of Experience Paper`

**Measuring Success: Long-Term Goal Achievement**
Evaluate AI systems based on their ability to achieve long-term goals within a stream of experience, such as improving a user's health or learning a new language.


---

**Source:** `The Era of Experience Paper`

**Measuring Success: Discovery of Novel Strategies**
Assess AI systems based on their ability to discover novel strategies and insights that go beyond existing human knowledge.


---

**Source:** `The Era of Experience Paper`

**Measuring Success: Adaptation to Changing Environments**
Evaluate AI systems based on their ability to adapt to changing environments and unexpected events, demonstrating robustness and resilience.


---

**Source:** `The Era of Experience Paper`

**Best Practice: Flexible Reward Adaptation**
Implement reward functions that can be flexibly adapted based on grounded signals and user feedback, allowing for continuous improvement and alignment with user goals.


---

**Source:** `The Era of Experience Paper`

**Best Practice: Combining Human and Environmental Feedback**
Design AI systems that can integrate both human feedback and environmental signals to optimize their behavior and achieve desired outcomes.


---

**Source:** `The Era of Experience Paper`

**Decision: Algorithm Selection**
Choose algorithms that are well-suited for long-term learning, exploration, and planning in complex environments, such as reinforcement learning methods with temporal abstraction and world modeling capabilities.


---

**Source:** `The Era of Experience Paper`

**Key Finding: Experiential Learning Enables Continuous Improvement**
Agents learning from their own experience can continually improve as they become stronger, surpassing the limitations of static, synthetically generated data. This approach allows AI to explore possibilities beyond pre-existing human knowledge.


---

**Source:** `The Era of Experience Paper`

**Decision: Data Strategy**
Develop a data strategy that focuses on collecting and utilizing real-world data and environmental signals, rather than relying solely on human-generated data.


---

**Source:** `The Era of Experience Paper`

**Decision: Infrastructure Investment**
Invest in the infrastructure and resources needed to support autonomous agents that can interact with the real world through sensors, actuators, and digital interfaces.


---

**Source:** `The Era of Experience Paper`

**Key Quote: DeepSeek AI on Reinforcement Learning**
"Rather than explicitly teaching the model on how to solve a problem, we simply provide it with the right incentives, and it autonomously develops advanced problem-solving strategies." — DeepSeek AI


---

**Source:** `The Era of Experience Paper`

**Key Quote: On the potential of experiential learning**
"Incredible new capabilities will arise once the full potential of experiential learning is harnessed."


---

**Source:** `The Era of Experience Paper`

**Key Quote: On the limitations of human-centric AI**
"Relying on human prejudgement in this manner usually leads to an impenetrable ceiling on the agent’s performance: the agent cannot discover better strategies that are underappreciated by the human rater."


---

**Source:** `The Era of Experience Paper`

**Key Finding: Characteristics of the Era of Experience**
Agents will inhabit long streams of experience, interact with the environment in a grounded manner, receive rewards based on their experience, and plan/reason about experience, rather than solely in human terms.


---

**Source:** `The Era of Experience Paper`

**Critical Capability: Long-Term Interaction Streams**
Buy-side firms need to develop AI systems that can operate within long-term interaction streams, carrying information across episodes and adapting over time to achieve long-term goals, rather than focusing on short, isolated interactions.


---

**Source:** `The Era of Experience Paper`

**Critical Capability: Grounded Actions and Observations**
Firms should prioritize AI agents that can act autonomously in the real world through motor control and sensors, rather than relying solely on human-privileged communication channels like text input/output.


---

**Source:** `The Era of Experience Paper`

**Critical Capability: Grounded Rewards**
Buy-side firms should explore using rewards grounded in real-world signals and environmental feedback, rather than relying solely on human prejudgment, to enable AI to discover strategies that humans may not appreciate.


---

**Source:** `The Era of Experience Paper`

**Critical Capability: Non-Human Reasoning**
Firms should encourage AI systems to develop non-human reasoning methods, such as symbolic or distributed computations, that may be more efficient than imitating human thought processes.


---

**Source:** `The Era of Experience Paper`

**Critical Capability: World Modeling**
Firms should invest in AI agents that can build world models to predict the consequences of their actions, including predicting rewards, allowing them to plan effectively and adapt to changing environments.


---

**Source:** `The Era of Experience Paper`

**AI Roadmap: Phase 1 - Implement Long-Term Interaction Streams**
Begin by developing AI systems that can operate within long-term interaction streams, carrying information across episodes and adapting over time to achieve long-term goals.


---

**Source:** `The Illusion of Thinking`

**Key Finding: Three Reasoning Regimes**
Comparing LRMs and standard LLMs reveals three regimes: standard LLMs outperform at low complexity, LRMs gain an advantage at medium complexity, and both collapse at high complexity.


---

**Source:** `The Illusion of Thinking`

**Measuring Success: Beyond Accuracy**
Success metrics should extend beyond final answer accuracy to include the efficiency of the reasoning process (e.g., token usage) and the consistency of reasoning across different problem instances.


---

**Source:** `The Illusion of Thinking`

**Key Quote: "Despite their sophisticated self-reflection mechanisms learned through reinforcement learning, these models fail to develop generalizable problem-solving capabilities for planning tasks..."**
— [Shojaee et al.]


---

**Source:** `The Illusion of Thinking`

**Key Quote: "...there exists a scaling limit in the LRMs’ reasoning effort with respect to problem complexity, evidenced by the counterintuitive decreasing trend in the thinking tokens after a complexity point."**
— [Shojaee et al.]


---

**Source:** `The Illusion of Thinking`

**Best Practice: Don't rely solely on established benchmarks.**
Established benchmarks may suffer from data contamination issues. Use controllable environments to rigorously test AI models' reasoning capabilities.


---

**Source:** `The Illusion of Thinking`

**Best Practice: Don't assume more "thinking" is always better.**
The study shows that in some cases, non-thinking models can outperform LRMs, especially at low complexity.


---

**Source:** `The Illusion of Thinking`

**AI Roadmap: Phase 1 - Controlled Experimentation**
Begin by establishing controlled environments to evaluate AI models' reasoning capabilities on specific tasks relevant to the buy-side firm.


---

**Source:** `The Illusion of Thinking`

**AI Roadmap: Phase 2 - Reasoning Trace Analysis**
Implement tools and processes to analyze the intermediate reasoning traces of AI models to identify inefficiencies and limitations.


---

**Source:** `The Illusion of Thinking`

**AI Roadmap: Phase 3 - Model Selection and Optimization**
Based on the evaluation and analysis, select and optimize AI models for specific tasks, considering the trade-offs between reasoning effort, accuracy, and complexity.


---

**Source:** `The Illusion of Thinking`

**Key Finding: Scaling Limit in Reasoning Effort**
LRMs exhibit a counter-intuitive scaling limit, decreasing their reasoning effort (measured by inference-time tokens) as problem complexity increases near the collapse point, despite having adequate token budget.


---

**Source:** `The Illusion of Thinking`

**Key Finding: Inefficient Reasoning Traces**
Analysis of intermediate reasoning traces reveals that LRMs "overthink" simpler problems, exploring incorrect solutions even after finding the correct one, while failing to find correct solutions at high complexity.


---

**Source:** `The Illusion of Thinking`

**Supporting Fact: Puzzle Environments Enable Controlled Experimentation**
The study uses controllable puzzle environments (Tower of Hanoi, Checker Jumping, River Crossing, Blocks World) to systematically vary problem complexity while maintaining consistent logical structures.


---

**Source:** `The Illusion of Thinking`

**Supporting Fact: Math Benchmarks May Suffer from Data Contamination**
Existing evaluations on mathematical benchmarks often suffer from data contamination issues and do not allow for controlled experimental conditions.


---

**Source:** `The Illusion of Thinking`

**Critical Capability: Controlled Evaluation Environments**
Buy-side firms should consider using controlled evaluation environments to rigorously test AI models' reasoning capabilities and avoid biases from contaminated datasets.


---

**Source:** `The Illusion of Thinking`

**Critical Capability: Analysis of Reasoning Traces**
Beyond final accuracy, firms should analyze intermediate reasoning traces to understand how AI models arrive at their conclusions and identify potential inefficiencies or limitations.


---

**Source:** `The Illusion of Thinking`

**Decision: Evaluate Thinking vs. Non-Thinking Models**
When considering AI for complex tasks, evaluate both Large Reasoning Models (LRMs) and standard LLMs to determine which approach is more effective for specific complexity levels.


---

**Source:** `The Illusion of Thinking`

**Decision: Consider Algorithmic Implementation**
Firms should consider whether AI models can effectively execute explicit algorithms, as the study found limitations in LRMs' ability to benefit from provided algorithms.


---

**Source:** `The Impact of AI on Developer Productivity`

**Supporting Fact: Completion Time Reduction**
The treatment group (with Copilot) averaged 71.17 minutes to complete the task, compared to 160.89 minutes for the control group. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Critical Consideration: Code Quality**
The study did not examine the effects of AI on code quality, which is an important factor for performance and security. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**AI Roadmap: Start with Standardized Tasks**
Begin by evaluating AI tools on standardized programming tasks to obtain precise measures of productivity before applying them to larger, more complex projects.


---

**Source:** `The Impact of AI on Developer Productivity`

**Measuring Success: Monitor Code Quality**
In addition to productivity metrics, track code quality metrics such as bug rates, security vulnerabilities, and code maintainability.


---

**Source:** `The Impact of AI on Developer Productivity`

**Key Quote: Economic Impact**
"If the results of this study were to be extrapolated to the population level, a 55.8% increase in productivity would imply a significant amount of cost savings in the economy and have a notable impact on GDP growth." — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Critical Consideration: Labor Market Implications**
Further research is needed to understand how AI-powered developer tools will impact the labor market, including changes in job tasks and skill requirements. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Key Finding: Heterogeneous Benefits**
Less experienced developers, those who code more hours per day, and developers aged 25-44 benefited the most from using GitHub Copilot. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Supporting Fact: Statistical Significance**
The 55.8% reduction in completion time was statistically significant, with a p-value of 0.0017 and a 95% confidence interval of [21%, 89%]. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Study Design: Controlled Experiment**
The study involved 95 professional programmers recruited through Upwork, randomly assigned to control and treatment groups. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Methodology: Task and Metrics**
Participants were tasked with implementing an HTTP server in JavaScript, and performance was measured by task success and task completion time. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Measuring Success: Task Completion and Success Rate**
Task completion time was measured from the start to the first successful completion of all 12 tests in the test suite. — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Key Capability: Experimentation and Measurement**
Buy-side firms should design controlled experiments to measure the impact of AI tools on specific tasks and workflows.


---

**Source:** `The Impact of AI on Developer Productivity`

**Supporting Fact: Willingness to Pay**
The treated group (with Copilot) had a significantly higher average "irrelevant price" (willingness to pay) for GitHub Copilot ($27.25/month) compared to the control group ($16.91/month). — [Peng et al.]


---

**Source:** `The Impact of AI on Developer Productivity`

**Key Finding: Self-Reported vs. Actual Productivity Gain**
Participants underestimated the productivity gain from Copilot, self-reporting an average of 35% increase compared to the actual 55.8% reduction in completion time. — [Peng et al.]


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Supporting Fact: ChatGPT User Growth**
Sam Altman reported in April 2025 that ChatGPT active users had doubled in weeks, reaching 1 billion.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Generative AI Used Intermittently**
While many workers may use Generative AI tools every weekday, the total hours at work each week using Generative AI tools is reported to be in most cases less than 15 hours, suggesting there is intermittent use of Generative AI throughout the workday.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Industries with High Generative AI Use**
Industries most likely to use Generative AI at work include "Information Services" and "Management of Companies".


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Generative AI Use and Income**
Generative AI use increases with income, with nearly 50% of workers making above $200,000 annually using Generative AI at work.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Gender and Generative AI Use**
A greater proportion of men (38.0%) claim to use Generative AI at work than women (27.8%) in the survey.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: ChatGPT Remains Most Popular Tool**
ChatGPT remains the most popular Generative AI tool, closely followed by Gemini.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Generative AI Used in Job Searches**
Over 50% of those unemployed over the past 2 years used Generative AI tools to assist in their job search.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Quote: Potential GDP Increase**
Goldman Sachs suggested that generative AI could increase global GDP by 7% in the next ten years, and that 300 million jobs globally are susceptible to automation. — [Goldman Sachs Report, 2023]


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: U-Shaped Relationship Between Income and Efficiency Gains**
The relationship between income and the efficiency gains of Generative AI follow a U-shape form, where the gains tend to be higher on the lower and higher ends of the income distribution.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Critical Consideration: Policy Implications**
Understanding how Generative AI shapes productivity and labor markets will be crucial for understanding potential regulatory policies in the space.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Critical Consideration: Government Subsidization**
One avenue for public policy is government subsidization for the development of AI models to researchers outside of firms that have developed LLMs, along with further support for broad public R&D investments.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Supporting Fact: Google Gemini User Base**
Google CEO Sundar Pichai announced in May 2025 that Google Gemini has over 400 million monthly active users.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Generative AI as a General-Purpose Technology (GPT)**
The scope of applications for Generative AI technologies is vast, supporting the idea that LLMs are General-Purpose Technologies (GPTs) with the potential to impact the entire economy. — [Bresnahan & Trajtenberg (1995)]


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Generative AI Use Skews Younger and More Educated**
LLM use at work skews towards younger individuals (18-29) and those with postgraduate degrees.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Supporting Fact: Education and ChatGPT Use**
Workers with a postgraduate degree are four times more likely to use ChatGPT than workers with a high school diploma or less.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Supporting Fact: Firm AI Adoption Rate**
The AI use rate among firms rose from 3.7% in September 2023 to 5.4% in February 2024, with expectations of further increase to 6.6% by early Fall 2024. — [Bonney et al (2024)]


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Wage Gains in AI-Exposed Occupations**
More AI-exposed occupations experienced statistically significant wage gains since the release of ChatGPT in late 2022, while employment and job postings showed little change.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Generative AI as a Complement to Labor**
Evidence suggests that Generative AI functions more as a complement to labor than as a substitute in the near term, raising worker productivity and earnings.


---

**Source:** `The Labor Market Effects of Generative Artificial Intelligence`

**Key Finding: Productivity Gains with Generative AI**
Workers using generative AI to complete tasks spend about 30 minutes, compared to an estimated 90 minutes without it, suggesting a tripling of productivity for those tasks.


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Three AI Value Plays: Deploy, Reshape, Invent**
Leading companies leverage AI by deploying it for immediate gains, reshaping critical functions, and inventing new revenue streams. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Leaders Expect Significant Value from AI**
Leaders expect to generate 50% higher revenue growth and 60% higher total shareholder return from AI investments compared to other firms. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Leaders Set Ambitious Targets and Invest More**
Leaders set big targets and invest more of their budget and resources in digital and AI capabilities. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Leaders Focus on Fewer Efforts for Greater ROI**
Leaders invest strategically in a few high-priority opportunities to scale and maximize AI's value, focusing resources on fewer use cases. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Leaders Focus on the Core Business Operations**
Leaders use AI to transform essential business operations, not just support areas, to find real competitive advantage. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**AI Adoption is a Marathon, Not a Sprint**
Maximizing value from AI is a long-term journey requiring sustained effort and strategic focus. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**AI Roadmap: Reshape Critical Functions**
Leaders can change their AI trajectories by reshaping critical functions, ultimately driving enterprise-wide transformation. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**AI Supports Business Strategy**
Leaders understand that AI should support overall business strategy, focusing on value beyond mere productivity gains. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Functional Leaders Drive AI Transformation**
Executives reshaping critical functions (finance, operations, HR, IT) can boost efficiency by up to 50% and generate higher ROI. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Transformation Requires More Than Tools**
Achieving AI transformation demands behavioral change, a people-centric focus, and sustained investment in foundational capabilities. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**The 10-20-70 Rule: People are Key**
Successful AI initiatives allocate 10% of effort to algorithms, 20% to technology/data, and 70% to people and processes. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**AI Can Expand Employee Capabilities**
When used correctly, AI expands employee capabilities and broadens the range of tasks they can perform, not just increases productivity. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Building Trust in AI is Essential**
Spreading AI use requires building trust through proper guardrails, responsible AI practices, and demonstrating how AI can help employees thrive. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**AI Handles Mundane Tasks**
AI can handle mundane tasks, freeing up employees to focus on more fulfilling, strategic, and creative work. — BCG


---

**Source:** `The Leader’s Guide to Transforming with AI _ BCG`

**Combining Predictive and Generative AI is a Big Advantage**
Combining predictive and generative AI provides the best in analytic power and creativity. — BCG


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Supporting Fact: API Usage Dominates**
94% of companies surveyed are using a foundation model API, with OpenAI's GPT being the most popular (91%). — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Supporting Fact: Custom Model Training on the Rise**
15% of companies built custom language models from scratch or open source, often in addition to using LLM APIs, indicating a growing interest in custom model training. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Key Quote: Rapid Evolution**
"Every practitioner we spoke with said AI is moving too quickly to have high confidence in the end-state stack..." — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Best Practice: Leverage Vector Databases**
Use vector databases to store, search, and update embeddings, making unstructured data easily searchable using natural language for improved LLM performance. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Critical Capability: Developer-Friendly Tooling**
Buy-side firms should adopt developer-oriented tooling like LangChain to empower a wider range of developers to build LLM applications. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Decision: Build vs. Buy Vector Database**
Larger companies may prefer cloud provider vector database offerings, while startups often opt for purpose-built vector databases. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**AI Roadmap: Addressing Trust and Safety**
A key milestone in the AI roadmap is implementing robust tools for data privacy, security, and monitoring model outputs to address concerns about trustworthiness. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Supporting Fact: Retrieval Mechanisms are Key**
88% of companies believe a retrieval mechanism, such as a vector database, is a key part of their LLM stack for improved accuracy and data freshness. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Supporting Fact: Orchestration Frameworks Gaining Traction**
38% of companies are interested in or using LLM orchestration and application development frameworks like LangChain, with adoption increasing recently. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Key Finding: Customization is Crucial**
Companies want to customize language models to their unique context and data, enabling natural language interactions with proprietary information. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Critical Capability: Contextual Retrieval**
Providing the model with the right information at the right time through methods like embeddings retrieval is crucial for customizing LLMs without extensive fine-tuning. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Decision: API vs. Custom Model Training**
Companies must decide whether to primarily leverage LLM APIs or invest in custom model training, with a trend towards convergence of both approaches. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**AI Roadmap: Gradual Adoption**
AI adoption is still early, with many applications being relatively simple, suggesting a roadmap of gradual implementation and increasing complexity over time. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Critical Capability: Trustworthiness and Governance**
Buy-side firms need to prioritize data privacy, security, and output quality to ensure trustworthiness and enable full adoption of LLMs, especially in regulated industries. — Sequoia Capital


---

**Source:** `The New Language Model Stack _ Sequoia Capital`

**Key Finding: Multi-Modal Applications Emerging**
Language model applications are becoming increasingly multi-modal, combining text, speech/audio, and image/video generation for richer user experiences. — Sequoia Capital


---

**Source:** `The Simple Macroeconomics of AI`

**Supporting Fact: 20% of US Labor Tasks Exposed to AI**
Calculations based on Eloundou et al. (2023) suggest that 20% of US labor tasks are exposed to AI, weighted by occupational wage bill share. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**AI Roadmap: Focus on New Tasks for Workers**
More favorable wage and inequality effects, as well as more sizable productivity benefits, will likely depend on the creation of new tasks for workers, especially middle- and low-pay workers. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Critical Capability: Distinguish Automation vs. Task Complementarities**
It's important to distinguish between automation (AI taking over tasks) and task complementarities (AI improving labor productivity in existing tasks) to understand the full economic impact. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Measuring Success: Beyond GDP**
Success metrics for AI initiatives should extend beyond GDP to include measures of consumer welfare, inequality, and the creation of new tasks for workers. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Decision: Prioritize Reliable Information over Human-Like Conversation**
The author suggests that a fundamental reorientation of the AI industry is needed, focusing on reliable information that can increase the marginal productivity of different kinds of workers, rather than prioritizing the development of general human-like conversational tools. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Supporting Fact: 23% of AI-Exposed Tasks Feasibly Automated**
Svanberg et al. (2024) estimate that only 23% of tasks exposed to computer vision (a subset of AI) can be profitably automated within 10 years. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Supporting Fact: 27% Labor Cost Savings from AI**
Experimental studies (Noy and Zhang, 2023; Brynjolfsson et al., 2023) suggest average labor cost savings of approximately 27% from AI in specific tasks. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Key Concept: Hulten's Theorem for AI Impact**
GDP and aggregate productivity gains from AI can be estimated by the fraction of tasks impacted and the average task-level cost savings, a principle derived from Hulten's theorem. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Critical Consideration: Easy vs. Hard-to-Learn Tasks**
Productivity gains from AI are likely to be higher in "easy-to-learn" tasks (those with clear outcome metrics and simple action-outcome mappings) compared to "hard-to-learn" tasks. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Key Finding: Negative Welfare Effects from "Bad" AI Tasks**
New AI-generated tasks, such as those enabling manipulation or misinformation, may increase GDP but reduce overall welfare. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Supporting Fact: Potential Welfare Loss from Social Media**
Drawing on Bursztyn et al. (2023), the author suggests that for every $53 of revenue generated by AI-powered social media, there may be a net negative effect on users equivalent to $19. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Key Finding: AI Likely to Widen Capital-Labor Income Gap**
The author's analysis suggests that AI is unlikely to reduce inequality and is likely to widen the gap between capital and labor income. — Acemoglu 2024


---

**Source:** `The Simple Macroeconomics of AI`

**Theoretical Insight: Increased Low-Skill Productivity Can Increase Inequality**
Even if AI improves the productivity of low-skill workers in certain tasks, this may increase rather than reduce inequality due to ripple effects and task price adjustments. — Acemoglu 2024


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Supporting Fact: Growth in Non-Image Content Generation**
While image generation previously dominated, other modalities like video and music are rapidly gaining traction, representing a larger share of new entrants. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Key Quote: AI Underpinning Category-Defining Companies**
"We believe that over the coming decade, AI will underpin category-defining companies." — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Supporting Fact: Mobile Focus on Content Editing**
Content editing for images and videos is the second-largest product category in mobile AI apps, indicating user demand for on-the-go editing capabilities. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Key Finding: ChatGPT Leads, but Competition Intensifies**
ChatGPT remains the top AI product on both web and mobile, but competition from AI assistants like Perplexity and Claude is increasing. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Supporting Fact: Perplexity's High Engagement**
Perplexity, an AI-powered search engine, has a slightly longer visit duration than ChatGPT, suggesting deeper user engagement due to its focus on concise, sourced answers. — Andreessen Horowitz, citing Similarweb data


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Supporting Fact: Bytedance's AI Push**
Bytedance, TikTok's parent company, has launched multiple AI applications, including edtech, bot building, and general assistants, demonstrating a significant investment in the AI space. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Key Finding: Discord as a Leading Indicator**
Discord traffic can serve as an early signal for the potential success of AI applications, particularly in content generation. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Best Practice: Discord for Product Testing**
Some AI products initially launch on Discord to test their features and build a community before releasing a standalone website or app. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Key Finding: Emergence of Aesthetics and Dating AI**
A new category of AI applications focused on aesthetics and dating is emerging, with apps that analyze user photos and voices to provide attractiveness feedback and dating advice. — Andreessen Horowitz


---

**Source:** `The Top 100 Gen AI Consumer Apps - 3rd Edition _ Andreessen Horowitz`

**Supporting Fact: Monetization Strategies in Aesthetics AI**
Aesthetics AI apps like LooksMax AI and Umax monetize through subscriptions, offering users access to results and features for a weekly fee. — Andreessen Horowitz


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Three AI Value Plays: Deploy, Reshape, Invent**
BCG identifies three key strategies for AI success: deploying AI for productivity, reshaping functions, and inventing new revenue streams. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**AI Handles Mundane Tasks**
AI handles mundane tasks, freeing up employees to focus on more fulfilling, strategic, and creative work. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Combining Predictive and Generative AI is Advantageous**
Combining predictive and generative AI provides the best of both analytic power and creativity. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Leaders Expect Higher Returns from AI**
Leaders expect to generate 50% higher revenue growth and 60% higher total shareholder return than other firms through AI. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Ambitious Targets and Investment**
Leaders set big targets and invest more of their budget and resources into digital and AI capabilities. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Focus on Fewer Efforts for Greater ROI**
Leaders strategically invest in a few high-priority opportunities to scale and maximize AI's value, focusing resources on fewer use cases. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Transforming Core Business Operations**
Leaders use AI not only to strengthen support areas but to transform essential business operations. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**AI is a Marathon, Not a Sprint**
Maximizing value from AI is a long-term process requiring sustained effort and commitment. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**AI Supports Business Strategy**
AI's true value lies in end-to-end transformation that supports overall business strategy, not just isolated productivity gains. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Functional Leaders Drive AI Transformation**
Functional leaders are crucial for reshaping critical functions (finance, operations, HR, IT) to boost efficiency and ROI. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Efficiency Gains from AI**
Executives can boost efficiency by up to 50% by reshaping critical functions with AI. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Transformation Requires More Than Tools**
Achieving AI transformation demands a commitment to behavioral change, a people-centric focus, and sustained investment in foundational capabilities. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**The 10-20-70 Rule for AI Success**
A successful AI strategy allocates 10% of effort to algorithms, 20% to technology and data, and 70% to people and processes. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**AI Can Decrease Effectiveness if Misapplied**
Generative AI can reduce team effectiveness if used incorrectly or for the wrong tasks. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**AI Expands Employee Capabilities**
When used correctly, AI expands employee capabilities and broadens the range of tasks they can perform. — BCG


---

**Source:** `The tech Leader’s Guide to Transforming with AI _ BCG`

**Building Trust in AI is Crucial**
Spreading AI use requires building trust through proper guardrails, responsible AI practices, and highlighting how AI can help employees thrive. — BCG


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Critical Capability: Understanding Vector DB Trade-offs**
Buy-side firms need to understand the trade-offs between on-prem vs. cloud hosting, purpose-built vs. incumbent vendors, insertion speed vs. query speed, recall vs. latency, in-memory vs. on-disk storage, sparse vs. dense vectors, full-text vs. vector search, and filtering strategies. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Supporting Fact: Indexing Strategies Impact Recall and Latency**
Flat indexes are most accurate but slowest; IVF-Flat indexes are faster but sacrifice some accuracy; HNSW is popular and can be combined with Product Quantization (PQ) for better recall and memory efficiency; Vamana is optimized for on-disk performance. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: In-Memory vs. On-Disk Vector Storage**
If your use case requires storing enough vectors that are larger than memory, consider databases that use memory-mapped files for vectors, utilizing the page cache's virtual address space on disk. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Supporting Fact: LanceDB's Disk-Based Approach**
LanceDB stands out because all supported indexes are disk-based, loading only relevant pages from the index file from disk and caching them in memory. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: Sparse vs. Dense Vector Storage**
If semantic search is very important, then dense vectors are the way to go; if latency and speed of indexing are critical, then sparse vectors might be worth looking at. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Key Finding: Vector Search is Not a Panacea**
For enterprise-level applications, plain vector search is frequently the wrong solution and is often used as part of a broader information retrieval system. — The Data Quarry, citing Colin Harman


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: Hybrid Search Strategy**
Consider a hybrid search strategy that combines full-text search with vector search to rank exact matches higher than semantically similar results. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Best Practice: Hybrid Search Techniques**
Techniques include naive fallback, Reciprocal Rank Fusion (RRF), and cross-encoder reranking to improve the quality of search results. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: Filtering Strategy for Vector Search**
Consider how your database of choice handles pre/post filtering and how well the filtering strategy works on your data for the classes of queries you will be performing. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Best Practice: Test Vector DB Solutions on Your Own Data**
The best way to choose a vector database stack is to first understand the requirements and constraints of your use case, and then test out the different solutions on your own data. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Key Quote: Purpose-built solutions are the superior option**
"In my experience, purpose-built solutions are the superior option, because they have a wider of suite of functions, are able to implement cutting-edge solutions due to starting from a clean-slate, and they also contain a host of optimizations that incumbent vendors just can’t prioritize for." — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: On-Prem vs. Cloud Hosting for Vector DBs**
Consider cloud-native (managed) + client-server, on-prem (self-hosted) + embedded, and cloud-native (managed) + embedded combinations when evaluating hosting options for cost-effectiveness. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Supporting Fact: Embedded Vector DBs Offer Flexibility**
Embedded/serverless vector DBs offer freedom and flexibility to developers when connecting data layers to the application layer, especially when privacy and security are a concern. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: Cost Considerations for Cloud-Native Vector DBs**
Organizations with large in-house data infrastructure teams may find on-prem or embedded hosting more cost-effective than cloud-native, managed solutions that charge based on data stored and queries made. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: Purpose-Built vs. Incumbent Vendor for Vector Search**
If adding vector search to an existing application, first try the vector search capabilities of your existing database, but consider the cost implications and potential performance limitations before looking outward. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Supporting Fact: Purpose-Built Vector DBs Offer Performance Advantages**
Purpose-built vector DB vendors have optimized their storage, indexing, and querying strategies for vector search, often using modern programming languages for massive scalability and performance. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Supporting Fact: Incumbent Solutions May Have Limitations**
Elasticsearch has additional constraints on which clients can use their vector search offering, and MongoDB offers vector search only for their Atlas cloud deployment. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Decision: Insertion Speed vs. Query Speed Trade-off**
For most organizations, querying speed is more important than insertion speed, as insertion and indexing are typically done infrequently compared to real-time querying. — The Data Quarry


---

**Source:** `Vector databases (Part 4)_ Analyzing the trade-offs · The Data Quarry`

**Key Capability: Optimizing for Recall and Latency**
Different vector database vendors make different trade-offs when optimizing for recall (percentage of relevant results) vs. latency (time to return results). — The Data Quarry


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Key Finding: AI's Potential GDP Uplift**
AI is projected to contribute $15.7 trillion to the global GDP by 2030, highlighting its potential economic impact. — World Economic Forum


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Use Cases: Sensing and Learning**
AI enables machines to "sense" the outside world through data analysis and "learn" to optimize performance from past results.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Continuous Monitoring**
After an AI model is deployed, it must be monitored continuously and tweaked to ensure that the insights a business derives continue to be reliable and in line with the organization's values and ethical principles.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Measuring Value**
While your data scientists will have specific metrics to measure the technical performance of the model, business metrics should be used to understand the impact of AI on the organization.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Model Retirement**
If the system breaches the organization's stated ethical principles or is no longer functioning properly, it may pose a significant business risk.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Ethical AI Case Studies**
Businesses around the world are reimagining what they can do and achieving it with AI. The following are three real life examples of analytics solutions that have been built and deployed successfully with sound principles in mind.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI in Sustainable Development: Consumer and Regulatory Pressures**
Companies will likely feel increasing pressure from both the individuals that support them and the bodies that regulate them.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI in Sustainable Development: Paradigm Shifts**
Three paradigm shifts can help companies take advantage of the benefits derived from traditional and AI solutions related to environmental sustainability: Company-scale action, Industry-scale action, and Ecosystem-scale action.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI in Sustainable Development: AI Trends**
Companies are using AI to reduce their environmental impact, optimize the use of natural resources, and optimize the usage of AI to reduce AI's own carbon footprint.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI in Sustainable Development: Three Lenses**
Depending on a firm's level of commitment and priorities, its reason for acting on sustainability is likely to fall somewhere on the spectrum of compliance, efficiency and innovation.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI in Sustainable Development: Preparedness Assessment Tool**
The Preparedness Assessment Tool helps executives assess whether they possess, or have access to, the knowledge required to independently judge decisions on using AI to sustain the environment.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI in Sustainable Development: Guidance Tool**
The Guidance Tool offers suggestions for further action in an "if, then" format and can be used to brainstorm to fill any gaps that may have surfaced during the initial exercise.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Use Cases: Sales**
Common AI use cases in sales include predicting optimal next actions, generating actionable analytics from sales calls, and personalizing customer journeys.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Definition**
Industrial AI is defined as "a systematic discipline which focuses on developing, validating and deploying various machine learning algorithms for industrial applications with sustainable performance."


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Challenges to Successful Deployment**
Challenges to achieving the successful and sustainable deployment of industrial AI implementation include data availability, data quality, governance, and security and privacy.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Greenfield vs. Brownfield**
Greenfield refers to software that is created from scratch in a completely new environment, whereas brownfield refers to any type of software that is built from old systems or coexists with current applications.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Action Plan**
High-quality, on-demand and faster output generation industrial systems can be realized through industrial AI.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Upskilling the Workforce**
Human capital is a critical factor to sustain success within an organization.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Infrastructure Readiness**
Answering questions will help to determine readiness: What is the readiness of the current data, storage, compute and network infrastructure? What resources are available internally to use (or are using) the cloud to develop and host AI software applications? How is the company positioned in the data value chain, and how should that influence short-term vs long-term infrastructure? How well is the company prepared to capitalize on forthcoming advances in AI hardware and data storage innovations? How will the company use new AI capabilities without causing IT and data inefficiencies?


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Role in Safety**
Industrial AI can also be used to help increase workplace safety measures.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Data Governance**
To effectively manage the AI algorithms, the governance of this data plays a critical role.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Industrial AI: Implementation**
When implementing industrial AI and determining a research question for an industrial AI project, the focus area should be where the organization can benefit from better decisions and where relevant data is available.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Use Cases: HR**
In HR, AI can automate screening processes, personalize staff onboarding, provide targeted training, and assess employee sentiment.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Use Cases: Transportation**
Vision technologies in transportation can detect objects in drone piloting, monitor rail tracks, manage passenger traffic, and monitor drivers for fatigue.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Use Cases: Consumer Goods**
Natural language processing in consumer goods can automate video captioning, support sophisticated chatbots, offer translation tools, and automate sales conversation analysis.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Critical Consideration: Ethical Implementation**
Solving problems using AI in an ethical, scalable, and efficient way is a journey, and organizations that invest in iterating until they get it right will be the winners.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Growth Drivers: Data Explosion**
The explosion of data within businesses and societies is a key factor in the recent rise of AI, making it both possible and necessary.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Supporting Fact: Global DataSphere**
IDC estimates that 59 zettabytes of data will be created, copied, and consumed worldwide in 2020, with continued growth projected.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Growth Drivers: Processing Power and Cloud**
Increased processing power, especially in the cloud, has made the rapid and inexpensive development and deployment of AI models possible.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Growth Drivers: New Algorithm Types**
New algorithm types like deep learning, reinforcement learning, and generative adversarial learning have driven advances in image, video, voice recognition, and natural language processing.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Key Finding: Multifaceted Approach to AI**
A modular approach to AI is needed, allowing users to focus on specific areas without requiring a complete overhaul. The focus should be on identifying key questions rather than providing definitive answers, given the field's evolving nature. — World Economic Forum


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Positive Impact: Productivity Gains**
AI offers potential productivity gains by enabling technologies to think and act with intelligence and autonomy, counteracting the negative impact of aging workforces.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Positive Impact: Knowledge Work**
AI applications are specifically aimed at knowledge work processes, which have been particularly important and problematic in terms of productivity.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Positive Impact: Healthcare**
AI holds potential benefits for healthcare, including patient diagnosis and treatment, drug discovery, and increased patient engagement.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Negative Impact: Job Loss**
AI may lead to job loss through automation, although "augmentation" (smart humans working alongside smart machines) has been more common.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Negative Impact: Algorithmic Bias**
The use of ML AI in classification or prediction tasks often comes with the risk of bias introduced in training data that can put certain groups at a disadvantage.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Negative Impact: Lack of Transparency**
The decision outcomes of some ML algorithms, such as deep learning, cannot be easily explained, leading to unexplainable decisions.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Negative Impact: Accountability Issues**
As AI is used to enhance or automate decision-making, issues of accountability arise in decisions with poor outcomes.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Negative Impact: Loss of Privacy**
AI's need to process large amounts of data may conflict with people's rights to privacy, requiring organizations to ensure compliance with relevant regulations.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Key Capability: AI Strategy Alignment**
An AI strategy needs to be aligned with the organization's larger corporate strategy, defining the role of data and AI and enabling key functions to deliver on potential use cases.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Articulating a Clear Vision**
Articulating a clear vision for the company and how that vision breaks down into concrete goals is one of the most important contributions executive leaders can make to set up their organizations for success with AI.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Key Capability: Defining AI**
A commonly accepted definition of AI is needed for consistent measurement of investments, development of regulations, and appropriate risk management practices. — World Economic Forum


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Minimizing Chances of Building Data Capabilities for the Sake of It**
Having a clear strategy ensures that the company makes AI investments that have the power to move the metrics that matter, minimizing the chances of building data capabilities for the sake of it.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Cross-Functional Collaboration**
AI initiatives generally require significant cross-functional collaboration to be effective. Clear business goals unify cross-functional teams by providing them with common outcomes to work towards.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Prioritizing Requests**
A clear vision will help AI teams prioritize requests and initiatives effectively, preventing them from becoming bloated cost centers.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Change Management**
A change management function is intended to create business transformation programmes and help the organization adapt to new technologies and processes.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Data Strategy**
Data strategy – origination, acquisition, management, operations – is a key component in building an AI strategy.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Strategy: Data and AI Model Life Cycle**
AI model work is a double cycle, one that focuses on data and one that focuses on the model itself. Both are equally important and must be factored into the AI strategy.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Roadmap: Assessing Maturity**
Organizations need to assess their current capabilities and identify gaps in business planning, leadership, skills, risk governance, and technology platforms.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Roadmap: Competitor Assessment**
Assessing the competitor landscape is complex, involving both tactical operational tools and new business model development options from established players and new market entrants.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Roadmap: Steps to Design**
Steps to design an AI roadmap include articulating a vision, defining business objectives, identifying use cases, quantifying impact and costs, prioritizing use cases, and incorporating governance mechanisms.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Roadmap: Prioritizing Use Cases**
The traditional method for prioritizing use cases is to plot impact (business value) against feasibility and costs and to focus on short-term investments that deliver value quickly at a low cost, while simultaneously investing in projects that are riskier and more expensive but also have the potential to yield more significant gains over time.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Defining AI: World Economic Forum**
The World Economic Forum defines AI as "systems that act by sensing, interpreting data, learning, reasoning and deciding the best course of action." — World Economic Forum


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Roadmap: Ethical Design Principles**
Ethical design principles should flow from your organization's existing values and should also be influenced by best practices in the AI ethics field, as well as by the regulatory environment.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Roadmap: Stakeholder Consultation**
A successful AI strategy requires a mix of people in the room: senior leaders but also technical, data and domain experts. "Translators" that can bridge the languages of AI technology and the business are often the lynchpin.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Initiative Failures: Capability Gaps**
Capability gaps may emerge at various levels, including data science, data engineering, and operational management.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Initiative Failures: Data Quality**
AI initiatives can fail due to unavailable or poor-quality data, requiring significant resources for data cleansing and manipulation.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Initiative Failures: Technology Foundations**
AI systems are dependent on having the necessary technical foundations, including data storage, access, and cleansing capabilities.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Initiative Failures: Poor Governance**
Ensuring a clear governance process with appropriate controls is critically important but often overlooked, covering both traditional project oversight and ethical/regulatory controls.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Initiative Failures: Project Finance**
AI projects need ring-fenced funding to support capacity-building and aligned incentives across the organization.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Initiative Failures: Project Management**
AI projects often require project management skills that may not exist in the organization, including a focus on data, ethics, and external stakeholder conversations.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Data-Driven Culture**
Transitioning to a data-driven culture in which evidence propels all decision-making is critical as a company scales up.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Data Access and Use**
To assess an entity's level of "data culture," it is important to consider how widely data is generated, collected, exchanged/shared and how widely data is used for analytics, AI and ML to drive business decisions.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Defining AI: OECD**
The OECD defines AI as a "machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments." — OECD


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Fostering an Experimental Culture**
Fostering an experimental culture, where online, live experiments can be critical not only in increasing the effectiveness of marketing but also in strengthening the overall innovation process, is essential.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Instilling an Ethics Culture**
The significance of balancing goals with practices that instil ethical AI cannot be overestimated.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Evolving the Organization**
The transition into an AI-driven workplace is typically best achieved by following a phased approach, including identifying stakeholders, providing awareness, offering training, and adapting strategies.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Executive Sponsorship**
Executive sponsorship and advocacy for AI within the organization is paramount, ensuring resources, protection, organization-wide coordination and buy-in.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Executive Skills**
The key skill for executive business leaders is the ability to understand the art of the possible with AI, while identifying the main risks.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Business Stakeholder Skills**
Business stakeholders need to understand strategic opportunities, legal and ethical risk management, technical and data capability requirements, and project predictability.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: AI and Data Leader Skills**
The most effective data leaders possess the ability to communicate with non-technical stakeholders, sufficient technical understanding, the ability to influence people, and basic business skills.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: AI and Data Leader Reporting**
Who the CDO/CAO reports to depends on the organization's business requirements.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: AI Project Team Roles**
AI project teams need to balance technology and business skills with domain knowledge, including data engineers, business intelligence professionals, data scientists, ML engineers, data product managers, and data governance specialists.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Important Skills to Hire**
Organizations must attract the required talent to ideate, design, develop and implement AI, including AI researchers, AI software developers, data scientists and change management/transformation experts.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Supporting Fact: Machine Learning at the Core**
Machine learning (ML) is at the core of most of today's AI systems, enabling them to analyze data and identify regularities for predictions and decisions.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Hire, Train, or Outsource**
The decision to hire, train, or outsource AI skills depends on the strategic value of AI and the availability of specialized solutions from suppliers.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Hiring and Retaining AI Talent**
Organizations need to understand where to find AI talent, how to retain it, and why it is important to build diversity and inclusion in the AI team.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: Organizational Design**
Leveraging data and AI requires organization-wide data-driven decision-making practices and culture, easy access to data and analytics by everyone, "data first" in decision-making processes, and broad involvement in continuous data and AI enabled business improvements and innovations.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: AI Team Alignment**
The AI team needs to align with business and engineering, requiring strong communication lines, a streamlined way of working, and a set of common standards and tools.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**People and Organization: AI Change Management Programme**
A change management programme is key to the successful implementation and adoption of AI within an organization, identifying challenges in AI readiness and finding ways to overcome these challenges.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Strategic Imperative**
Leading with ethical AI is a strategic imperative, balancing economic potential with the transformation of business and society.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: What It Is**
Responsible AI as a multidisciplinary area of expertise seeks to elaborate how to translate the vision of ethical AI into ethical decisions and actions aimed at guiding the development and use of AI.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: What It Is Not**
What the ethics of AI is not: Only compliance, A set of fixed rules to follow, A purely negative frame, more than risks, A one-off event (“set it and forget it”), A technical “bugfix”.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: AI Ethics**
AI ethics is a golden path to realizing the benefits of AI (the Good) and mitigating the risks (the Ugly). It is the great maximizer-in-balance of AI.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: AI Ethics and Other Fields**
AI ethics can leverage from business ethics and bioethics.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Critical Risk: Fragility of AI Systems**
AI systems are vulnerable to "adversarial attacks" and can be significantly affected by biases in training data, requiring careful management to ensure fair, robust, safe, and stable use.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Ethics and Human Rights Law**
It is necessary to tie the ethics of AI to specific human rights to limit regulatory ambiguity, but also for the development of human-centric AI for the common good.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Ethics and Risk Management**
AI ethics would benefit from taking a similar approach to risk management. As most new risks associated with AI have ethical implications, clear guidance on analysis and mitigation should be shared throughout the C-suite, AI practitioners and society.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Ethics and the Law**
For the development and use of AI systems, laws and regulation are one of the layers of governance, alongside social morality and self-regulatory approaches.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: What Makes AI Risky?**
AI system characteristics that can lead to new types of risks include continuous self-learning, potential changes in context, imperfect accuracy, deployment at scale, challenging transparency, and vulnerability to attacks.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Types of AI Risks**
Types of AI risks include performance, security, control, economic, societal, and enterprise risks.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Assessing AI Risks**
Mechanisms for assessing AI risks include Data Protection Impact Assessments, risk assessments, ethics assessments, and bias assessments.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Steps to Manage AI Risks**
Steps to manage AI risks include aligning on AI principles, confirming governance, designing for robustness, exercising control, respecting privacy, being transparent, extending security practices, enabling diversity, clarifying accountability, and fostering well-being.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Top-Down Governance**
Top-down governance includes the Three Lines of Defence model: creators/executors, managers/supervisors, and auditors/ethicists.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: End-to-End Governance**
End-to-end governance spans from strategy to planning, ecosystem, model development, deployment, and operation/monitoring.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: AI Governance and Proactive Risk Management**
AI governance can help organizations manage risks proactively and prepare for future regulation, including ethical failures, legal scrutiny, and emerging legislative proposals.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI History: Bottom-Up Approach**
The 1990s saw a revolution in AI with the "bottom-up approach," where intelligence was learned rather than preprogrammed, leading to the dominance of machine learning.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Business Case**
Practicing responsible AI and revenue are interconnected, with benefits including greater ROI, customer loyalty, brand reputation, product quality, and talent acquisition.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Tools and Practices**
Tools and practices for managing AI risks and ensuring ethical deployment include vision/values statements, principles/codes of conduct, external/internal boards, a culture of ethics, ethics education, reporting channels, stakeholder consultation, and audit/reporting.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Product Development Practices**
Organizations can adapt product development practices to ensure they are ethically aligned, with a new mindset for responsibility/ethics in design, by design, and for designers.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Microsoft's Responsible AI Programme**
Microsoft's responsible AI programme includes governance, rules to enact AI principles, drawing red lines, evolving mindset, pioneering new engineering practices, and scaling efforts.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Responsible AI: Deutsche Telekom's AI Ethics Approach**
Deutsche Telekom's approach is centred on building trust in the use of AI, with a commitment to transparency, explainability, data privacy and security.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Foundational Requirements**
As organizations turn to AI to improve performance, innovate, reduce cost, and mitigate risks, it is important that they understand the foundational requirements for the successful implementation of AI throughout their business.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: AI Life Cycle Stages**
The AI life cycle is the iterative process AI solutions follow, from design, development, deployment, to ongoing monitoring and feedback.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Design Stage**
Before implementing an AI solution, it is important to clarify the business strategy, define a prioritized roadmap, raise awareness of business risks, hire the right talent, assemble the right team, align with stakeholders, and integrate ethical principles.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Development Stage**
Developing an AI model includes collecting, storing, cleansing, analysing and synthesizing the available data and understanding its assumptions as well as how to govern that data appropriately, to selecting a model, training it on the data, preparing to move it to production when it can begin generating business insights, and choosing the right tech, data and AI partners to work with.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Data Sourcing**
Organizations can turn to internal and external resources to collect first-, second- and third-party data.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**AI Growth Drivers: Data and Computing Power**
The explosion of computing power and data on the internet were two main factors that spurred AI's growth in the late 1990s and 2000s.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Data Quality Dimensions**
Organizations should strive to ensure data is being measured against the following six data quality dimensions: Completeness, Uniqueness, Timeliness, Validity, Accuracy, and Consistency.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Data Governance**
Strong data governance or management at a minimum addresses the following aspects: Data quality, Metadata management, Data storage and retention, and Data access, privacy and security.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Technical Questions**
Technical questions to answer when building AI include where and how to store data, what types of AI models to choose, how to train and test the model, and how to choose the right vendors and partners.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Data Storage**
There are three types of cloud environments: public, private and hybrid.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: AI Models**
Different types of ML algorithms exist; each is suited to solving certain kinds of problems. A description of some of the most common high-level approaches follows: Supervised learning, Unsupervised learning, and Reinforcement learning.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Centralized vs Diffused vs Federated Learning Models**
The three main models are centralized, diffused or distributed, and federated.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Model Interpretability and Explainability**
Explainability and interpretability ensure that AI systems are trustworthy and meet ethical and regulatory standards, and that insights are readily communicable to non-technical resources and external stakeholders.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Vendor and Partner Selection**
The most important component in finding the right vendor or partner is knowing what it is that your organization is trying to accomplish and what gaps must be addressed in that journey.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Deployment**
One of the trickiest but most important steps in the AI life cycle is deployment.


---

**Source:** `WEF_Empowering_AI_Leadership_2022`

**Implementation of AI: Scaling AI Deployment**
Ensuring that the AI solution you are building can scale appropriately is critical to deriving business insights. Key aspects include: Talent and business process change, Technical performance, Data volume and access, and Data privacy and security.


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Tactical, Operational, and Strategic Considerations**
Building successful LLM products requires addressing tactical (prompting, RAG), operational (team, deployment), and strategic (long-term vision) aspects. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Don't Forget Keyword Search**
Use keyword search (e.g., BM25) as a baseline and in hybrid search approaches, as vector embeddings may struggle with specific keyword-based queries. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prefer RAG Over Finetuning for New Knowledge**
RAG often outperforms finetuning for incorporating new information, is easier to keep up-to-date, and provides finer-grained control over document retrieval. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Long-Context Models Won't Make RAG Obsolete**
Even with large context windows, retrieval is still needed to select relevant context, avoid overwhelming the model with distractors, and manage inference costs. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Step-by-Step "Flows" Can Boost Performance**
Decomposing a single complex task into multiple simpler tasks (multi-turn flows) can achieve better results. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prioritize Deterministic Workflows**
For reliable agent deployment, have agent systems produce deterministic plans that are then executed in a structured, reproducible way. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Getting More Diverse Outputs Beyond Temperature**
Adjust elements within the prompt (e.g., shuffling the order of items), keep a list of recent outputs to avoid redundancy, and vary the phrasing used in prompts. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Caching is Underrated**
Caching saves cost, eliminates generation latency, and allows serving vetted responses, reducing the risk of harmful content. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**When to Finetune**
Finetune when prompting falls short, but consider the costs of data annotation, model training, and self-hosting. Generate synthetic data or bootstrap on open-source data to reduce costs. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Create Assertion-Based Unit Tests**
Create unit tests with input/output samples and expectations based on at least three criteria, triggered by any pipeline changes. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**LLM-as-Judge Can Work (Somewhat)**
LLM-as-Judge can help build priors about prompt performance, especially with pairwise comparisons, controlling for position bias, allowing for ties, and using Chain-of-Thought. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Key Finding: Prompting is Underestimated and Overestimated**
Prompting is underestimated because the right techniques can be powerful, but overestimated because significant engineering around the prompt is still required. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**The "Intern Test" for Evaluating Generations**
Ask: Could an average college student in the relevant major succeed at the task given the input and context? If not, enrich the context or reduce task complexity. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Overemphasizing Certain Evals Can Hurt Overall Performance**
Overemphasis on specific evals (e.g., Needle-in-a-Haystack) can reduce performance on other tasks like extraction and summarization. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Simplify Annotation to Binary Tasks or Pairwise Comparisons**
Simplify annotation tasks to binary classifications (yes/no) or pairwise comparisons (A is better than B) for faster and more reliable annotations. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**(Reference-Free) Evals and Guardrails Can Be Used Interchangeably**
Reference-free evals can assess output quality based solely on the input prompt and model's response, and can be used as guardrails to filter undesired output. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**LLMs Will Return Output Even When They Shouldn't**
LLMs may confidently return values even when they don't exist, necessitating robust guardrails to detect and filter undesired output. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Hallucinations are a Stubborn Problem**
Factual inconsistencies occur at a baseline rate of 5-10% and are challenging to reduce below 2%, requiring a combination of prompt engineering and factual inconsistency guardrails. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Check for Development-Prod Skew**
Measure skew between LLM input/output pairs, including structural (formatting) and content-based (semantic) skew, to ensure production accuracy. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Look at Samples of LLM Inputs and Outputs Every Day**
Regularly review data samples to develop an intuitive understanding of how LLMs perform and adapt to new patterns or failure modes. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Generate Structured Output to Ease Downstream Integration**
Generate structured output (e.g., JSON, YAML) to ease integration with downstream applications, using Instructor for LLM APIs and Outlines for self-hosted models. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Migrating Prompts Across Models is a Pain**
Expect prompt migration across models to take time, requiring reliable evals to measure task performance before and after migration. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prompting Technique: N-Shot Prompts and In-Context Learning**
Provide LLMs with examples (n ≥ 5) demonstrating the task and desired outputs, ensuring examples are representative of the production distribution. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Version and Pin Your Models**
Pin specific model versions in production to avoid unexpected changes in behavior, and maintain a shadow pipeline with the latest versions for testing. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Choose the Smallest Model That Gets the Job Done**
Experiment with smaller models, as techniques like chain-of-thought and finetuning can help them achieve comparable results with lower latency and cost. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Involve Design Early and Often**
Involve designers early to rethink how the user experience can be improved, focusing on the job to be done, not just the technology. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Design Your UX for Human-In-The-Loop**
Design the user experience for Human-In-The-Loop (HITL) to collect valuable data and improve models, balancing user effort and control. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prioritize Your Hierarchy of Needs Ruthlessly**
Prioritize requirements (reliability, harmlessness, factual consistency, usefulness, scalability, cost) ruthlessly to identify the minimum lovable product and iterate. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Calibrate Your Risk Tolerance Based on the Use Case**
Calibrate risk tolerance based on the use case, setting a higher bar for safety and accuracy for customer-facing applications offering critical advice. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Focus on the Process, Not Tools**
Focus on understanding the problem-solving methodology and process before adopting tools, avoiding accidental complexity and underspecified solutions. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Always Be Experimenting**
Position your team to experiment frequently, teaching everyone the basics of prompt engineering and setting aside time for building evals and running multiple experiments. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Empower Everyone to Use New AI Technology**
Educate and empower the entire team to use new AI technology, providing opportunities for hands-on experimentation and exploration. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Don't Fall Into the Trap of "AI Engineering is All I Need"**
Building AI products requires a broad array of specialized roles, including AI Engineers, platform/data engineers, and MLEs, hired at the right time. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prompting Technique: Chain-of-Thought (CoT)**
Encourage the LLM to explain its reasoning process before providing the final answer, adding specificity to reduce hallucination rates. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Training From Scratch (Almost) Never Makes Sense**
For most organizations, pretraining an LLM from scratch is an impractical distraction from building products. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Don't Finetune Until You've Proven It's Necessary**
Organizations invest in finetuning too early, trying to beat the “just another wrapper” allegations. In reality, finetuning is heavy machinery, to be deployed only after you’ve collected plenty of examples that convince you other approaches won’t suffice. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Start With Inference APIs, But Don't Be Afraid of Self-Hosting**
Start with LLM APIs, but consider self-hosting for data privacy, circumventing limitations, gaining control, and potentially reducing costs at scale. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**The Model Isn't the Product, the System Around It Is**
Focus on building lasting value through evals, guardrails, caching, and a data flywheel, rather than chasing the latest model releases. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Build Trust By Starting Small**
Focus on specific domains and use cases, narrowing the scope by going deep rather than wide to create domain-specific tools that resonate with users. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Build LLMOps, But Build It for the Right Reason: Faster Iteration**
Build LLMOps to shorten the feedback gap between models and their inferences and interactions in production, enabling faster iteration. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Don't Build LLM Features You Can Buy**
Focus on LLM applications that truly align with your product goals and enhance your core operations, avoiding general problems being tackled en masse by software companies. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**AI in the Loop; Humans at the Center**
Center humans in the workflow, using LLMs as a resource to support their rapid utilization, increasing productivity and happiness. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prompt Engineering Comes First**
Start with prompt engineering, using techniques like chain-of-thought, n-shot examples, and structured input/output, before considering finetuning. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Build Evals and Kickstart a Data Flywheel**
Build evals specific to your tasks and use cases, starting with unit testing and human evaluation, to create a positive feedback loop for model improvement. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prompting Technique: Providing Relevant Resources**
Use Retrieval Augmented Generation (RAG) to provide the model with snippets of text it can directly use in its response, prioritizing their use and acknowledging when resources are insufficient. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**The High-Level Trend of Low-Cost Cognition**
The cost of running models with equivalent performance is rapidly decreasing, making previously infeasible applications economical. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Structured Input and Output Improves LLM Performance**
Structured input (e.g., SQL schema) clarifies tasks and resembles training data, while structured output simplifies integration with downstream systems. Use Instructor for LLM APIs and Outlines for self-hosted models. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Avoid "God Object" Prompts**
Break down complex tasks into smaller, focused prompts that are easier to understand, iterate, and evaluate individually. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Craft Your Context Tokens Carefully**
Rethink the amount of context sent to the agent, removing superfluous material and structuring the context to underscore relationships between parts. — Applied LLMs


---

**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Key Finding: RAG is Dependent on Document Quality**
The quality of RAG output depends on the relevance, density, and level of detail in the retrieved documents. — Applied LLMs


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Vector Embeddings and Semantic Information**
Vector embeddings, generated by AI models, contain semantic information that enables AI to understand and maintain long-term memory for complex tasks.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Ecosystem Integration of Vector Databases**
Vector databases can easily integrate with data processing ecosystems like ETL pipelines (Spark), analytics tools (Tableau, Segment), visualization platforms (Grafana), and AI tools (LangChain, LlamaIndex, ChatGPT Plugins).


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Data Security and Access Control**
Vector databases typically offer built-in data security features and access control mechanisms to protect sensitive information.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Vector Database Querying: Similarity Metrics**
Unlike traditional databases that query for exact matches, vector databases use similarity metrics to find vectors most similar to a query vector.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Approximate Nearest Neighbor (ANN) Search**
Vector databases use algorithms that participate in Approximate Nearest Neighbor (ANN) search, optimizing search through hashing, quantization, or graph-based search.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Accuracy vs. Speed Trade-off**
Vector databases balance accuracy and speed in ANN search; higher accuracy typically results in slower queries, but a good system can provide ultra-fast search with near-perfect accuracy.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Vector Database Pipeline: Indexing, Querying, Post-Processing**
A common pipeline involves indexing vectors, querying for nearest neighbors, and post-processing the results, including re-ranking using different similarity measures.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Indexing Algorithms: Random Projection**
Random projection reduces dimensionality by projecting vectors onto a lower-dimensional space using a random projection matrix, speeding up the search process.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Indexing Algorithms: Product Quantization (PQ)**
Product quantization (PQ) is a lossy compression technique that breaks vectors into smaller chunks, simplifies their representation, and reassembles them, preserving vital similarity information.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Indexing Algorithms: Locality-Sensitive Hashing (LSH)**
Locality-Sensitive Hashing (LSH) maps similar vectors into "buckets" using hashing functions, enabling faster approximate nearest-neighbor search.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Indexing Algorithms: Hierarchical Navigable Small World (HNSW)**
HNSW creates a hierarchical, tree-like structure where nodes represent sets of vectors and edges represent similarity, facilitating efficient navigation during querying.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Traditional Databases vs. Vector Databases**
Traditional scalar-based databases struggle with the complexity and scale of vector embeddings, hindering insight extraction and real-time analysis, while vector databases are designed for this type of data.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Similarity Measures: Cosine Similarity**
Cosine similarity measures the cosine of the angle between two vectors, ranging from -1 to 1, indicating the degree of similarity.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Similarity Measures: Euclidean Distance**
Euclidean distance measures the straight-line distance between two vectors, ranging from 0 to infinity, indicating dissimilarity.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Similarity Measures: Dot Product**
Dot product measures the product of the magnitudes of two vectors and the cosine of the angle between them, indicating the directionality of vectors.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Filtering: Pre-filtering vs. Post-filtering**
Filtering based on metadata can be done before (pre-filtering) or after (post-filtering) the vector search, each with trade-offs between search space reduction and potential oversight of relevant results.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Performance and Fault Tolerance**
Vector databases use sharding (partitioning data across multiple nodes) and replication (creating multiple copies of data) to ensure high performance and fault tolerance.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Consistency Models: Eventual vs. Strong Consistency**
Replication employs eventual consistency (allowing temporary inconsistencies for improved availability) or strong consistency (requiring all copies to be updated before completion, ensuring stronger consistency but potentially higher latency).


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Monitoring Key Metrics**
Monitoring resource usage (CPU, memory, disk space), query performance (latency, throughput, error rates), and system health (node status, replication process) is crucial for managing vector databases.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Access Control Importance**
Access control is vital for data protection, compliance, accountability, and scalability, ensuring only authorized users can access sensitive data.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Backups and Collections for Data Recovery**
Vector databases offer backups stored on external systems or cloud services for data recovery, with Pinecone allowing backups of specific indexes as "collections."


---

**Source:** `What is a Vector Database_ _ Pinecone`

**API and SDKs for Developer Accessibility**
User-friendly APIs and programming language-specific SDKs simplify the development of high-performance vector search applications.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Key Capability: Semantic Information Retrieval and Long-Term Memory**
Vector databases enable advanced AI features like semantic information retrieval and long-term memory by indexing content as vector embeddings and querying for similar embeddings based on semantic similarity.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Vector Database Workflow**
The typical workflow involves creating vector embeddings from content using an embedding model, inserting them into the vector database with references to the original content, and querying the database using embeddings of the query to find similar vectors and their associated content.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Vector Database Advantages over Standalone Vector Indices**
Vector databases offer advantages over standalone vector indices like FAISS, including data management, metadata storage and filtering, scalability, real-time updates, backups, ecosystem integration, and data security.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Data Management in Vector Databases**
Vector databases provide easy-to-use features for data storage, insertion, deletion, and updating, simplifying vector data management compared to standalone vector indices.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Metadata Storage and Filtering**
Vector databases can store metadata associated with each vector, enabling finer-grained queries using metadata filters.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Scalability of Vector Databases**
Vector databases are designed to scale with growing data volumes and user demands, offering better support for distributed and parallel processing than standalone vector indices.


---

**Source:** `What is a Vector Database_ _ Pinecone`

**Real-time Updates in Vector Databases**
Vector databases often support real-time data updates, allowing for dynamic changes to the data, while standalone vector indexes may require computationally expensive re-indexing.


---

**Source:** `When combinations of humans and AI are useful`

**Supporting Fact: Negative Synergy Effect Size**
A meta-analysis of 106 experiments revealed a negative pooled effect (Hedges’ g = -0.23) when comparing human-AI systems to the best of human or AI alone. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**AI Roadmap: Focus on Generative AI for Creation Tasks**
Future research should prioritize human-AI synergy in creation tasks, particularly with generative AI, as these areas show more promise. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Measuring Success: Robust Evaluation Metrics**
Develop and employ more robust metrics that consider task completion time, financial cost, and the practical implications of different types of errors, beyond just overall accuracy. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Critical Capability: Commensurability Criteria**
Develop a set of commensurability criteria to facilitate systematic comparisons across human-AI collaboration studies and track progress. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Best Practice: Commensurability Criteria Dimensions**
Commensurability criteria should include standardized guidelines for task designs, quality constraints, incentive schemes, process types, and evaluation metrics. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Best Practice: Open Reporting Repository**
Establish a standardized and open reporting repository for human-AI collaboration experiments to facilitate replication, extension, and synthesis of research. — Vaccaro, Almaatouq, & Malone (2024)
```


---

**Source:** `When combinations of humans and AI are useful`

**Key Finding: Human Augmentation Exists, But Not Synergy**
While human-AI combinations often underperform the *best* of either alone, they *do* generally outperform humans working alone. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Supporting Fact: Positive Augmentation Effect Size**
The pooled effect size for human augmentation (human-AI vs. human alone) was positive (g = 0.64), indicating that AI helps humans perform better on average. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Key Finding: Task Type Moderates Synergy**
Decision-making tasks show performance losses in human-AI combinations, while creative tasks show potential for synergy. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Supporting Fact: Task Type Effect Sizes**
Decision tasks had a significantly negative pooled effect size (g = -0.27), while creation tasks had a positive effect size (g = 0.19), though not significantly different from 0. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Key Finding: Relative Performance Matters**
Human-AI synergy is more likely when humans outperform AI alone; performance losses occur when AI outperforms humans alone. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Supporting Fact: Relative Performance Effect Sizes**
When humans outperformed AI, the human-AI system showed synergy (g = 0.46); when AI outperformed humans, the human-AI system showed performance losses (g = -0.54). — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Surprisingly Insignificant Moderators: Explanation and Confidence**
Factors like AI explanations and confidence levels, often emphasized in research, did not significantly impact the effectiveness of human-AI collaboration in this meta-analysis. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `When combinations of humans and AI are useful`

**Critical Capability: Innovative Process Design**
Effective AI use requires designing innovative processes for combining humans and AI, not just developing innovative technologies. — Vaccaro, Almaatouq, & Malone (2024)


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Key Finding: Agents Suited for Complex, Ambiguous Workflows**
Agents are uniquely suited to workflows where traditional deterministic and rule-based approaches fall short, particularly those involving nuanced judgment, exceptions, or context-sensitive decisions.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Decision: When to Create Multiple Agents**
Consider splitting tasks across multiple agents when prompts contain many conditional statements, or when there is tool overload (similarity or overlap of tools).


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Best Practice: Maximize Single Agent Capabilities First**
Maximize a single agent’s capabilities before introducing multiple agents, as more agents can introduce additional complexity and overhead.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Best Practice: Use Prompt Templates for Single-Agent Systems**
Use a single flexible base prompt that accepts policy variables, rather than maintaining numerous individual prompts for distinct use cases. This template approach adapts easily to various contexts, significantly simplifying maintenance and evaluation.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Best Practice: Layered Defense with Guardrails**
Use multiple, specialized guardrails together to create more resilient agents, combining LLM-based guardrails, rules-based guardrails such as regex, and moderation APIs.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**AI Roadmap: Iterative Development and Validation**
Start small, validate with real users, and grow capabilities over time.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**AI Roadmap: Focus on Data Privacy and Content Safety First**
When building guardrails, focus on data privacy and content safety first, then add new guardrails based on real-world edge cases and failures encountered.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**AI Roadmap: Optimistic Execution with Guardrails**
Implement guardrails using an optimistic execution approach, where the primary agent proactively generates outputs while guardrails run concurrently, triggering exceptions if constraints are breached.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**AI Roadmap: Plan for Human Intervention**
Implement a human intervention mechanism to allow the agent to gracefully transfer control when it can’t complete a task, triggered by exceeding failure thresholds or high-risk actions.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Guardrails: Relevance Classifier**
A relevance classifier ensures agent responses stay within the intended scope by flagging off-topic queries.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Guardrails: Safety Classifier**
A safety classifier detects unsafe inputs (jailbreaks or prompt injections) that attempt to exploit system vulnerabilities.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Key Finding: Incremental Approach to Agent Building**
Customers typically achieve greater success with an incremental approach to agent building, rather than immediately building a fully autonomous agent with complex architecture.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Guardrails: PII Filter**
A PII filter prevents unnecessary exposure of personally identifiable information (PII) by vetting model output for any potential PII.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Guardrails: Tool Safeguards**
Assess the risk of each tool available to your agent by assigning a rating—low, medium, or high—based on factors like read-only vs. write access, reversibility, required account permissions, and financial impact.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Key Finding: Guardrails are Critical for Safe and Predictable Operation**
Guardrails are a critical component of any LLM-based deployment, helping ensure agents operate safely and predictably in production.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Supporting Fact: Distinguishing Agents from Simple LLM Applications**
Applications that integrate LLMs but don’t use them to control workflow execution—think simple chatbots, single-turn LLMs, or sentiment classifiers—are not agents.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Supporting Fact: Three Core Components of an Agent**
An agent consists of three core components: the LLM (Model), external functions or APIs (Tools), and explicit guidelines and guardrails (Instructions).


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Critical Capability: Model Selection**
Select models based on task complexity, latency, and cost, using a variety of models for different tasks in the workflow. Start with the most capable model to establish a performance baseline, then try swapping in smaller models to optimize for cost and latency.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Critical Capability: Defining and Standardizing Tools**
Each tool should have a standardized definition, enabling flexible, many-to-many relationships between tools and agents. Well-documented, thoroughly tested, and reusable tools improve discoverability, simplify version management, and prevent redundant definitions.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Critical Capability: Configuring Instructions**
High-quality instructions are essential for any LLM-powered app, but especially critical for agents. Clear instructions reduce ambiguity and improve agent decision-making, resulting in smoother workflow execution and fewer errors.


---

**Source:** `a-practical-guide-to-building-agents (1)`

**Critical Capability: Orchestration Patterns**
Orchestration patterns fall into two categories: Single-agent systems, where a single model executes workflows in a loop, and multi-agent systems, where workflow execution is distributed across multiple coordinated agents.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Organizations Should Leverage Multimodal GenAI with Ethical Safeguards**
Organizations should leverage multimodal GenAI capabilities while ensuring ethical AI safeguards to drive autonomous process re-engineering and enhanced decision-making across all lines of business.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Evolution of Agentic Frameworks**
Agentic frameworks have evolved from simple, rule-based systems to sophisticated, multimodal agents capable of processing and integrating information from various sources.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Build Cross-Functional AI Teams**
Assemble teams that include members from various departments to ensure that AI initiatives are well-rounded.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Invest in Employee Training for AI**
Equip your team with the necessary skills to work alongside AI systems.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Invest in Quality Data for AI**
High-quality data is the backbone of effective AI solutions.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Prioritize Data Security and Privacy in AI**
Implement robust security measures to protect sensitive data.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Invest in Scalable AI Platforms**
Choose AI platforms and tools that are scalable and can grow with your business needs.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Invest in Continuous Learning for AI**
Stay curious and updated with AI advancements and industry trends.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Underestimate Complexity of AI Projects**
AI projects are not plug-and-play.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Rush AI Implementation**
Avoid hastily integrating AI without a clear strategy.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Neglect Human Oversight in AI**
While AI can automate many tasks, human oversight remains crucial.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Ignore User Adoption of AI**
Ensure that the AI solutions are user-friendly and meet the needs of those who will interact with them daily.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Multimodality Enhances AI Effectiveness**
Multimodality capabilities allow AI agents to understand, employ reasoning, and interact like humans, enhancing their effectiveness and versatility to solve a wide range of business problems.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Overlook Ethical Considerations in AI**
Be mindful of the ethical implications of AI use.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Ignore Change Management for AI**
Prepare your workforce for AI adoption through training and change management programs.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Underestimate Costs of AI**
Be realistic about the investment required for AI integration, including infrastructure, maintenance, and training costs.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Ignore Partnerships for AI**
Collaborate with trusted technology providers, consultants, AI experts, and academic institutions.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Don't Overlook Long-Term Sustainability of AI**
Develop a long-term AI strategy that considers future needs and technological advancements.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Government Entities Can Prioritize Large-Scale AI Initiatives**
Government entities can prioritize large-scale initiatives such as policymaking, governance, public welfare, economic stability, and sustainability, leveraging agentic AI to orchestrate complex systems.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Organizations Can Focus on AI Point Solutions**
Organizations aiming for profitability growth, cost optimization, and competitive advantage can focus on developing agentic AI point solutions to address specific challenges within defined domains.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Most Entities Will Experiment with Low-Hanging AI Use Cases**
Most entities are expected to begin by experimenting with low hanging use cases.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**A Smaller Number Will Adopt a Strategic AI Approach**
A smaller number will see the vast opportunity window with agentic AI solutions and adopt a strategic approach, recalibrating AI strategies to fully harness agentic AI solutions across a broader spectrum of business use cases and processes.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Only a Handful Will Embrace an AI-First Mindset**
Only a handful—like Amazon, Google, Meta etc.—will embrace an AI-first mindset, reimagining products, services, and processes to redefine value creation mechanisms.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Phase 1 of Evolution: Integration of Machine Learning (ML)**
The integration of ML allowed agents to learn from large datasets, improving their ability to make decisions and perform tasks, a significant step forward from rule-based systems.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**AI-Managed Operations Will See Autonomous Agents Handling Tasks**
The shift from human-driven, labor-intensive processes to AI-managed operations will see autonomous agents handling tasks with unprecedented speed, precision, and adaptability.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**AI Integration Will Redefine How We Work**
As agentic AI systems become more integrated, they will redefine how we work, pushing the boundaries of possibility and enabling a smarter, more agile world.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Strategic Vision, Planning, and Execution are Key to AI Success**
Success in this arena won't be accidental; it demands strategic vision, meticulous planning, and relentless execution.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Phase 1 of Evolution: Natural Language Processing (NLP) Enabled User Interactions**
Advances in NLP enabled agents to understand and generate human language more effectively, making interactions more natural and intuitive.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Phase 2 of Evolution: Introduction of Multimodality**
Multimodal agents emerged, capable of processing and integrating information from various sources like text, images, and audio, making them more versatile and capable of handling complex tasks.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Phase 2 of Evolution: Enhanced User Interactions**
Multimodal agents could interact with users in more dynamic ways, such as providing visual aids in response to text queries or understanding context from a combination of spoken and visual inputs.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Phase 3 of Evolution: Advanced Autonomy and Real-Time Interactions**
Agents can operate independently, rationalize and set their own goals, develop path(s) to attain these goals, and make independent decisions without constant human intervention, leveraging data from multiple sources or synthetic datasets.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Phase 3 of Evolution: Ethical and Responsible AI**
With increased capabilities, there has also been a focus on ensuring that agentic systems operate ethically and responsibly, considering factors such as bias, transparency, and accountability.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Competitive Advantage Through Agentic AI**
Organizations who adopt an agentic AI system can gain a competitive advantage by leveraging its capabilities to innovate and enhance their business operations.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Lower Cost to Entry with Agentic AI**
Lower cost to entry and economies of scale makes it favourable for organisations to fully harness the capabilities it oﬀers compared to its predecessors like traditional ML and Robotic Process Automation (RPA)-driven automations.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Enhances Efficiency, Lowers Costs, Improves Customer Experience, and Drives Revenue Growth**
Integrated effectively, agentic AI can enhance efficiency, lower costs, improve customer experience, and drive revenue growth.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Enhances Competitive Edge**
Agentic AI systems can significantly enhance an organization’s competitive edge by automating complex workflows, reducing operational costs, and improving decision-making processes.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Enables Proactive Strategies**
Agentic AI can predict market trends and customer preferences, allowing businesses to tailor their strategies proactively.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Handles Large Data Volumes**
Agentic AI systems can handle large volumes of data and extract actionable insights, which can be used to optimize operations and enhance customer experiences.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Frees Up Human Resources**
By automating routine tasks, agentic AI systems free up human resources to focus on more strategic initiatives, thereby increasing overall organizational agility and responsiveness.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Improves Decision-Making**
Agentic AI systems can analyze vast amounts of data quickly and accurately, providing valuable insights to inform better decision-making.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Boosts Efficiency and Productivity**
Agentic AI can significantly enhance business efficiency and productivity by automating routine tasks and processes, allowing employees to focus on more strategic and creative activities.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Improves Customer Experience**
By integrating agentic AI, businesses can offer personalized and responsive customer experiences, improving customer satisfaction, building loyalty, and driving sales.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Surpasses Traditional Chatbots**
Agentic AI surpasses traditional rule-based and RAG-based chatbots in terms of accuracy, contextual coherence, and problem-solving ability.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI's Accuracy Advantage**
Agentic AI allows it to understand nuances in language, generating accurate responses even to complex or unseen queries; its ability to learn from vast datasets enhances precision and adaptability.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI's Contextual Coherence Advantage**
Agentic AI’s orchestration capability helps it excel at tracking conversation history, understanding dialogue flow, ensuring responses remain contextually appropriate and coherent, significantly boosting customer engagement.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Definition of Agentic AI**
Agentic AI systems possess the capacity to make autonomous decisions and take actions to achieve specific goals with limited or no direct human intervention.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI's Problem-Solving Advantage**
Agentic AI performs dynamic reasoning and decision-making, leveraging a series of autonomous agents, analyzing customer issues, considering multiple factors, and applying learned knowledge to resolve problems more efficiently.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Agentic AI Business Imperative: Service-as-a-Software**
Organizations managing day-to-day operations stand to gain significantly from agentic AI systems, embracing the emerging "service-as-a-software" model, which transforms manual labor into automated, AI-driven services.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software Reduces Operational Overheads**
This model allows organizations to access a wider range of services at a fraction of the cost, driving efficiency and significantly reducing operational overheads.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software Enables Scaling Without Proportional Cost Increase**
AI applications with advanced reasoning capabilities can now handle complex tasks, enabling companies to scale their operations without a proportional increase in cost.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software: Transitioning from Copilot to Autopilot**
Service-as-a-software represents an outcome-focused, strategic shift, enabling organizations to transition from their current state to operating in "copilot" and ultimately "autopilot" modes.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software: Outcome-Based Pricing**
Instead of paying for software licenses or cloud-based services, they pay Sierra based on the number of successful resolutions. This outcome-based model aligns costs directly with the results delivered.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software Targets Service Profits**
Traditional SaaS focused on selling user seats, whereas service-as-a-software taps into service profit pools, delivering solutions that focus on specific business outcomes.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software Offers Outcome-Based Pricing**
Instead of charging per user or seat, service-as-a-software adopts a pricing model based on the actual outcomes achieved, directly aligning costs with results.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Service-as-a-Software Provides High-Touch Delivery Models**
Service-as-a-software offers a top-down, highly personalized approach, providing trusted, tailored solutions that meet the specific operational needs of businesses.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Set Industry Benchmarks**
Early adopters of AI set industry benchmarks and gain first-mover market advantage.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Key Aspect: Autonomy**
Agentic AI systems can operate independently, making decisions based on their programming, learning, and environmental inputs.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Innovate Business Processes**
Early adopters leverage AI to innovate business processes, deploy the AI solutions effectively and create differentiation.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Build Deeper Customer Relationships**
Early adopters build deeper customer relationships through personalized and newer experiences.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Streamline Operations Early**
Early adopters streamline operations and reduce operational cost early on.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Benefit from the Initial Learning Curve**
Early adopters benefit from the initial learning curve and shape industry standards.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Increase Market Share and Profitability**
Early adopters increase market share and profitability through early adoption.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Create Barriers for Competitors**
Early adopters create barriers for competitors through deep AI integration.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Early Adopters Pay Higher Initial Costs**
Early adopters pay relatively higher cost of entry and iterative test-and-learn due to new AI solutions.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Siemens AG: AI for Predictive Maintenance**
Siemens transformed its maintenance operations by deploying AI models that analyze sensor data from machinery, predicting equipment failures and scheduling maintenance proactively, reducing maintenance costs by 20% and increasing production uptime by 15%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Mayo Clinic: AI for Radiology Workflows**
Mayo Clinic integrates AI into radiology workflows for quicker and more accurate diagnoses, reducing diagnostic times by 30% and lowering unnecessary procedures by 15%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**JPMorgan Chase: AI for Legal Document Analysis**
JPMorgan’s Contract Intelligence (COiN) platform uses AI to analyze legal documents, saving 360,000 hours of manual review annually and significantly reducing compliance risk.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Key Aspect: Goal-Oriented Behavior**
Agentic AI agents are designed to pursue specific objectives, optimizing their actions to achieve the desired outcomes.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Amazon: AI for Personalized Recommendations**
Amazon leverages AI to analyze browsing behavior, purchase history, and visual preferences to generate personalized recommendations, increasing sales by 35% and improving loyalty rates by 20%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**DHL: AI for Logistics Optimization**
DHL utilizes AI models to predict and orchestrate shipping demands, optimize routes, and manage warehouse operations, reducing operational costs by 15% and improving delivery times by 20%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**BP: AI for Drilling Site Identification**
BP uses AI to analyze seismic data, generating 3D models of subterranean structures to identify favorable drilling sites, reducing exploration costs by 20% and increasing successful drilling operations by 15%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Pearson: AI for Personalized Learning**
Pearson’s AI models tailor educational content to individual learner needs, adjusting difficulty levels and content types based on performance and engagement data, boosting course enrollment by 25% and lowering content development costs by 15%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Netflix: AI for Content Recommendation**
Netflix uses AI models to recommend and orchestrate content by analyzing viewing habits, ratings, and visual content features, increasing retention rates by 10% and enhancing engagement leading to higher subscription renewals.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**AT&T: AI for Network Optimization and Customer Service**
AT&T’s AI models analyze and orchestrate network performance data and customer interactions to optimize network operations and personalize customer service through chatbots, reducing operational expenses by 15% and improving upselling through personalized offers.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Singapore Government: AI for Urban Management**
Singapore utilizes AI models to orchestrate and manage traffic flow, energy consumption, and public safety, reducing administrative costs by 25% and attracting US$12 billion in foreign investment.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Unilever: AI for Candidate Screening**
Unilever uses AI to screen candidates by analyzing video interviews and responses, saving over US$1 million annually in recruitment costs and reducing hiring time by 75%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Bank of America: AI for Customer Service**
Bank of America's AI virtual agent, Erica, handles over a million customer queries daily, reducing customer service costs by 10% and increasing product cross-selling by 5%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Coca-Cola: AI for Marketing Content Generation**
Coca-Cola uses AI to generate marketing content, analyze consumer trends, and personalize advertising, reducing content creation time by 50% and boosting campaign ROI by 20%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Key Aspect: Environment Interaction**
An agentic AI interacts with its surroundings, perceiving changes and adapting its strategies accordingly.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Walmart: AI for Supply Chain Management**
Walmart employs AI to predict product demand, optimize stock levels, and streamline logistics, decreasing inventory costs by 15% and improving product availability leading to higher sales.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Insilico Medicine: AI for Drug Discovery**
Insilico Medicine has developed inClinico, an AI platform that predicts phase II clinical trial outcomes to enhance drug discovery and development, yielding a 35% nine-month ROI in an investment application and reducing drug development time.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Hogan Lovells: AI for Legal Document Analysis**
The AI platform analyzes large sets of contracts and legal documents, increasing review speed by 40% and reducing billable hours for clients.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Coupa: AI for Procurement Optimization**
Coupa’s AI-driven spend management platform optimizes supplier selection, contract management, and spend analytics, achieving an impressive 276% return on investment (ROI) and reducing procurement cycle and significantly enhancing process speed.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Microsoft: AI for IT Operations**
Microsoft uses AI to monitor IT systems, predict failures, and automate support tickets, reducing IT support costs by 20% and improving system uptime by 15%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Salesforce: AI for Sales Insights**
Salesforce’s AI analyzes customer interactions, market trends, and sales data to provide actionable insights for sales teams, increasing sales by 15% and reducing sales cycle times by 25%.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**LangGraph: Commercial Agentic AI Solution**
LangGraph is a commercial agentic AI solution targeting startups and established enterprises, offering robust customer support, seamless integration, high customization, and advanced features like statefulness and streaming support.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**CrewAI: Commercial Agentic AI Solution**
CrewAI is a commercial agentic AI solution targeting Fortune 500 companies, providing no-code tools, supporting self-hosted and cloud deployments, and designed for handling complex, multi-agent tasks efficiently.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**AutoGen: Open-Source Agentic AI Solution**
AutoGen is an open-source framework targeting developers and researchers, facilitating cooperation among multiple AI agents, orchestrating complex LLM workflows, and supporting human-in-the-loop workflows.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**AutoGPT: Open-Source Agentic AI Solution**
AutoGPT is an open-source agentic AI solution targeting AI enthusiasts and developers, executing tasks independently using GPT-4 architecture, breaking down complex goals into manageable sub-tasks, and utilizing internet access and code execution for task completion.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Key Aspect: Learning Capability**
Many agentic AI systems employ machine learning or reinforcement learning techniques to improve their performance over time.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Commercial vs. Open-Source Agentic AI Tools**
When deciding between commercial vs open-source agentic AI tools, consider your organization’s needs, upstream/downstream integration capabilities, and accessibility to resources to build, deploy, and manage these solutions.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Commercial Agentic AI Solutions are Suited for Complex Deployments**
Commercial solutions such as LangGraph and CrewAI offer robust support, seamless integration, and advanced features, making them suitable for complex, large-scale deployments.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Open-Source Agentic AI Solutions are Excellent for Prototyping**
Open-source solutions like AutoGen and AutoGPT are excellent choices for rapid prototyping and proof-of-concept development, providing flexibility, community-driven innovation, and low cost of entry.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Define Clear Objectives for AI Strategy**
Define clear objectives for AI initiatives, such as cost reduction, revenue growth, customer satisfaction, or building an economic moat.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Align AI Initiatives with Business Goals**
Ensure that AI projects are underpinned by your company's strategic objectives to ensure relevance and maximize impact.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Secure Executive Sponsorship for AI Initiatives**
Having support from top management is crucial for securing resources and driving organizational change.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Start with High-Impact AI Use Cases**
Identify areas where AI can deliver significant value quickly and prioritize projects that address pressing challenges or offer substantial benefits.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Seek Expert Advice for AI Strategy**
Consult with AI experts or hire consultants to formulate your AI strategy and help you in making informed decisions.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Assess Technology Infrastructure for AI Integration**
Ensure your IT environment is ready for AI integration.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Evaluate Platform Options for AI Implementation**
Weigh-in commercial and open-source AI solutions and make build-vs-buy decisions based on your organization’s requirements, budget, and technical expertise.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Key Aspect: Workflow Optimization**
Agentic AI agents enhance workflows and business processes by integrating language understanding with reasoning, planning, and decision-making.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Consider Integration of AI Platforms**
Ensure the chosen platform can integrate seamlessly with your existing systems and workflows, both upstream and downstream.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Assess Data Readiness for AI Projects**
Ensure you have access to quality, multimodal data.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Evaluate Talent Pool for AI Initiatives**
Determine if you have the skills in-house, or if you will need external expertise.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Start Small with AI Pilot Projects**
Begin with small pilot projects to test the effectiveness of agentic AI in your business environment.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Measure Success of AI Initiatives**
Define clear metrics for success and monitor the performance of the pilot projects.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Use Agile Methodology for AI Implementation**
Be flexible, nimble and adaptive in your implementations.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Iterate and Improve AI Approaches**
Use the insights gained from pilot projects to refine your approach and address any challenges.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Gradually Expand AI Implementation**
Once the pilot projects are successful, gradually scale up the implementation of agentic AI across more areas of your operations.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Ensure Support for AI Adoption**
Provide adequate training and support to your team to ensure a smooth transition and adoption of the new technology.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Monitor and Optimize AI Systems**
Continuously monitor the performance of agentic AI systems and optimize them for better results.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Key Aspect: Multi-Agent and System Conversation**
Agentic AI facilitates communication between different agents to construct complex workflows and can integrate with other systems or tools to perform a variety of tasks.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Address Ethical Considerations in AI**
Address potential biases and compliance issues.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Implement Security Protocols for AI**
Protect sensitive data and align AI governance with national and global standards.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Educate and Upskill Workforce on AI**
Begin by familiarizing your workforce with the core concepts of data and AI.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Foster Innovation in AI**
Encourage a culture of innovation within your organization by promoting experimentation and collaboration.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Adapt and Evolve AI Strategies**
Be prepared to adapt your strategies and processes as the technology evolves and new opportunities arise.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Stay Informed on AI Developments**
Keep up with the latest developments and trends in AI by reading industry reports, inviting experts to all-hands sessions, attending conferences, and participating in webinars.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Ensure a Customer-Centric Approach to AI**
Always prioritize the end-user experience, eventually it pays off in both financial and non-financial results.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Conduct Thorough Research Before Implementing AI**
Before implementing AI solutions, research the available technologies to find the best fit for your business needs.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Start with Small AI Projects**
Begin with pilot programs to test the effectiveness of AI solutions.


---

**Source:** `agentic-ai-the-new-frontier-in-genai-an-executive-playbook`

**Monitor Performance and Iterate AI Systems**
Regularly track the performance of your AI systems using key metrics aligned with your business goals.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Iterative Development is Crucial**
Successful AI adoption requires an experimental mindset and an iterative approach to development, allowing for faster value realization and greater user buy-in.


---

**Source:** `ai-in-the-enterprise`

**Supporting Fact: Indeed's Job Matching Improvement**
Indeed saw a 20% increase in job applications started and a 13% uplift in downstream success after implementing a GPT-powered job matching engine.


---

**Source:** `ai-in-the-enterprise`

**Supporting Fact: Klarna's AI Assistant Impact**
Klarna's AI assistant handles two-thirds of all service chats, reducing average resolution times from 11 minutes to 2 and projecting a $40 million profit improvement.


---

**Source:** `ai-in-the-enterprise`

**Supporting Fact: Lowe's Product Tagging Accuracy**
Lowe's improved product tagging accuracy by 20% and error detection by 60% by fine-tuning OpenAI models.


---

**Source:** `ai-in-the-enterprise`

**Supporting Fact: BBVA's Custom GPT Creation**
BBVA employees created over 2,900 custom GPTs in five months, reducing project timelines from weeks to hours in some cases.


---

**Source:** `ai-in-the-enterprise`

**Supporting Fact: Mercado Libre's Fraud Detection**
Mercado Libre improved fraud detection accuracy to nearly 99% for flagged items by evaluating data on millions of product listings each day using AI.


---

**Source:** `ai-in-the-enterprise`

**Key Quote: Kaitlin Elliott, Morgan Stanley**
"The feedback from advisors has been overwhelmingly positive. They’re more engaged with clients, and follow-ups that used to take days now happen within hours." — Kaitlin Elliott, Head of Firmwide Generative AI Solutions, Morgan Stanley


---

**Source:** `ai-in-the-enterprise`

**Key Quote: Chris Hyams, Indeed**
"We see a lot of opportunity to continue to invest in this new infrastructure in ways that will help us grow revenue." — Chris Hyams, CEO, Indeed


---

**Source:** `ai-in-the-enterprise`

**Key Quote: Sebastian Siemiatkowski, Klarna**
"This AI breakthrough in customer interaction means superior experiences for our customers at better prices, more interesting challenges for our employees, and better returns for our investors." — Sebastian Siemiatkowski, Co-Founder and CEO, Klarna


---

**Source:** `ai-in-the-enterprise`

**Key Quote: Nishant Gupta, Lowe's**
"Excitement in the team was palpable when we saw results from fine-tuning GPT 3.5 on our product data. We knew we had a winner on our hands!" — Nishant Gupta, Senior Director, Data, Analytics and Computational Intelligence, Lowe's


---

**Source:** `ai-in-the-enterprise`

**Key Quote: Elena Alfaro, BBVA**
"We consider our investment in ChatGPT an investment in our people. AI amplifies our potential and helps us be more efficient and creative." — Elena Alfaro, Head of Global AI Adoption, BBVA


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Systematic Evaluation is Key**
A systematic evaluation process is crucial for measuring how AI models perform against specific use cases and continuously improving AI-enabled processes.


---

**Source:** `ai-in-the-enterprise`

**Key Quote: Sebastian Barrios, Mercado Libre**
"We designed our ideal AI platform using GPT-4o mini, with a focus on lowering cognitive load and enabling the entire organization to iterate, develop, and deploy new, innovative solutions." — Sebastian Barrios, SVP of Technology, Mercado Libre


---

**Source:** `ai-in-the-enterprise`

**Critical Capability: Model Evaluation Frameworks**
Develop rigorous, structured evaluation frameworks to measure AI model performance against benchmarks in specific use cases.


---

**Source:** `ai-in-the-enterprise`

**Critical Capability: AI Customization and Fine-Tuning**
Invest in customizing and fine-tuning AI models using proprietary data to improve accuracy, relevance, and domain expertise.


---

**Source:** `ai-in-the-enterprise`

**Critical Capability: AI Deployment Platform**
Implement a development platform that unifies and accelerates AI application builds, providing security, guardrails, and routing logic.


---

**Source:** `ai-in-the-enterprise`

**Best Practice: Start with High-Return, Low-Effort Use Cases**
Align AI deployment around use cases that offer high returns with relatively low effort, learning and iterating before expanding to new areas.


---

**Source:** `ai-in-the-enterprise`

**Best Practice: Empower Employees to Discover Use Cases**
Roll out AI tools and encourage employees to discover their own use cases, providing support and resources to facilitate experimentation.


---

**Source:** `ai-in-the-enterprise`

**AI Roadmap: Stage 1 - Evaluation and Experimentation**
Focus on conducting intensive evaluations for proposed AI applications to ensure quality and safety.


---

**Source:** `ai-in-the-enterprise`

**AI Roadmap: Stage 2 - Embedding AI into Products**
Integrate AI into existing products to create new customer experiences and more relevant interactions.


---

**Source:** `ai-in-the-enterprise`

**AI Roadmap: Stage 3 - Customization and Scaling**
Customize and fine-tune AI models to improve accuracy and relevance, and scale successful applications across the organization.


---

**Source:** `ai-in-the-enterprise`

**Measuring Success: Model Accuracy and Relevance**
Track metrics such as model accuracy, relevance, and coherence to evaluate the performance of AI applications.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: AI Can Humanize Customer Experiences**
AI can process vast amounts of data to create more relevant and personalized customer experiences, making them feel more human.


---

**Source:** `ai-in-the-enterprise`

**Measuring Success: Efficiency Gains and Cost Reduction**
Measure efficiency gains, such as reduced resolution times and task automation, and cost reductions resulting from AI implementation.


---

**Source:** `ai-in-the-enterprise`

**Measuring Success: Employee Productivity and Engagement**
Assess employee productivity and engagement levels to determine the impact of AI on their daily work.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Early Investment Leads to Compounding Benefits**
The earlier an organization starts investing in AI, the more it benefits from compounding improvements as use cases grow in sophistication and impact.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Customization and Fine-Tuning are Essential**
Enterprises that invest in customizing and fine-tuning their AI models see the most success in AI adoption.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Empowering Experts Drives Innovation**
Getting AI into the hands of employees who are closest to the processes and problems can be more powerful than building generic solutions.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Unblocking Developers Accelerates AI Adoption**
Developer resources are often a bottleneck, so providing platforms that unify and accelerate AI application builds is critical.


---

**Source:** `ai-in-the-enterprise`

**Key Finding: Bold Automation Goals Drive Efficiency**
Setting ambitious automation goals from the start, rather than accepting inefficient processes, leads to significant improvements in efficiency.


---

**Source:** `ai-in-the-enterprise`

**Supporting Fact: Morgan Stanley Advisor Usage**
98% of Morgan Stanley advisors use OpenAI every day, leading to increased document access and more time spent on client relationships.


---

**Source:** `ai_adoption_framework_whitepaper`

**ML Finds Patterns in Complex Datasets**
Machine learning excels at identifying patterns in complex datasets to address intricate problems like visual perception and speech recognition. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Access: Data Management and Sharing**
The "Access" theme addresses how well an organization recognizes data management as key to enabling AI, and the degree to which data scientists can share, discover, and reuse data and ML assets. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Scale: Cloud-Native ML Services**
The "Scale" theme focuses on using cloud-native ML services that scale with large data volumes and processing needs, while reducing operational overhead. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Secure: Data Protection and Responsible AI**
The "Secure" theme concerns protecting data and ML services from unauthorized access, ensuring responsible and explainable AI, and establishing trust in AI capabilities. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Automate: Efficient ML Pipelines**
The "Automate" theme focuses on deploying, executing, and operating data processing and ML pipelines in production efficiently, frequently, and reliably. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Three AI Maturity Phases: Tactical, Strategic, Transformational**
Organizations progress through three phases of AI maturity: Tactical, Strategic, and Transformational, each characterized by different levels of AI integration and impact. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Phase: Short-Term, Narrow AI Use Cases**
In the Tactical phase, AI use cases are simple, short-term, and narrow, often lacking a coherent long-term strategy. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Phase: Sustainable Business Value with AI**
In the Strategic phase, AI delivers sustainable business value with multiple ML systems deployed and maintained in production, leveraging both ready-to-use and custom models. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Phase: AI-Driven Innovation and Culture**
In the Transformational phase, AI plays a key role in stimulating innovation, supporting agility, and cultivating a culture of experimentation and continuous learning. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Phase: Focus on Data Access Improvement**
Organizations in the Tactical phase can benefit substantially from better access to data, leading to more actionable insights and informed decision-making. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Phase: Develop Foundational Data Skills**
Organizations in the Tactical phase should develop foundational skills in data wrangling and descriptive analytics. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**AI Adoption Drives Competitive Edge**
Companies are increasingly using AI and ML to gain a competitive advantage, resulting in direct and measurable business value. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Phase: Centralized Data Lake with Decentralized Access**
A key move for organizations in the Tactical phase is to bring together siloed data into a central, unified data lake with decentralized access. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Phase: Centralized Advanced Analytics Team**
Organizations in the Strategic phase often create a centralized advanced analytics team to build solutions for various ML use cases across business functions. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Phase: Enterprise Data Warehouse (EDW)**
Teams in the Strategic phase retrieve information from a single source: an enterprise data warehouse (EDW), with complete, consistent, correct, and concurrent data. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Phase: Protecting Data Quality and Preventing Model Staleness**
Technically, the next key moves for organizations in the Strategic phase are about protecting data quality, preventing ML models from going stale, and enabling valuable solutions to be production ready. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Phase: Hybrid AI Approach with Embedded Teams**
Organizations in the Transformational phase typically model a hybrid approach to AI, with functional or product-specific AI teams embedded into the broader product teams, supported by a central advanced analytics team. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Phase: Focus on Best Practices and Responsible AI**
At the Transformational phase, organizations can benefit substantially from focusing on best practices, ensuring that AI practices are responsible, and that AI systems are safe and robust. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Maturity (Learn): Self-Motivated Learning, Outsourcing Skills Gaps**
At the Tactical maturity level for "Learn," learning is self-motivated, and organizations tend to outsource ML projects rather than hiring in-house. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Maturity (Learn): Hiring and Structured Training Programs**
At the Strategic maturity level for "Learn," organizations hire data science and ML skills and develop structured training programs. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Maturity (Learn): Industry Expertise and Co-Creation**
At the Transformational maturity level for "Learn," organizations head-hunt well-known AI talent with industry expertise and engage in co-creation relationships with partners. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Maturity (Lead): Individual Contributors, Limited Sponsorship**
At the Tactical maturity level for "Lead," AI adoption is driven by individual contributors with little or no executive sponsorship. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**ML Adoption Boosts Decision-Making**
Adoption of ML leads to 2x more data-driven decisions, 5x faster decision-making, and 3x faster execution. — MIT Technology Review Study


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Maturity (Lead): Executive Support, Centralized Team**
At the Strategic maturity level for "Lead," senior executives support AI projects, and a centralized advanced analytics team is established. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Maturity (Lead): Embedded Data Scientists, Innovation**
At the Transformational maturity level for "Lead," each functional team has its own data scientists, and research and innovation activities flourish. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Maturity (Access): Data Islands, Building a Data Lake**
At the Tactical maturity level for "Access," each team manages its own data island, and organizations are looking into building a unified data lake. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Maturity (Access): Unified Data Model, Centralized Repository**
At the Strategic maturity level for "Access," organizations invest in an EDW with a unified data model and a centralized repository for ML assets. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Maturity (Access): Data Sharing, Feature Store**
At the Transformational maturity level for "Access," data scientists can create, share, discover, and reuse data and ML assets across teams, and a feature store is used as a unified repository. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Maturity (Scale): Dedicated Hardware, Small Datasets**
At the Tactical maturity level for "Scale," organizations use dedicated hardware for cost control and work with small datasets. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Maturity (Scale): Cloud Data Warehouse, Serverless Services**
At the Strategic maturity level for "Scale," organizations enable a fully managed cloud data warehouse and use serverless data services. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Maturity (Scale): Integrated ML Platform, ML Accelerators**
At the Transformational maturity level for "Scale," organizations architect an integrated ML platform and use ML accelerators (GPUs, TPUs) at scale. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Maturity (Secure): Primitive IAM Roles, Identifying Sensitive Data**
At the Tactical maturity level for "Secure," Cloud IAM policies rely on primitive roles, and organizations are identifying sensitive data. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Maturity (Secure): Granular IAM Roles, AI Principles**
At the Strategic maturity level for "Secure," Cloud IAM policies reference granular roles, and AI capabilities are supported by clear governance and AI principles. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**AI Investment Positions Firms as Future Leaders**
Enterprises investing in industry-specific AI solutions are better positioned as future global economic leaders. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Maturity (Secure): Threat Profiles, Automated Workflows**
At the Transformational maturity level for "Secure," organizations have a comprehensive understanding of data contents and use automated workflows to validate use cases against AI principles. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Tactical Maturity (Automate): Manual Processes, Ad Hoc Analytics**
At the Tactical maturity level for "Automate," the process of building AI systems is manual, and data analytics and ML are ad hoc. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Strategic Maturity (Automate): Automated Pipelines, Continuous Training**
At the Strategic maturity level for "Automate," organizations automate data processing and analytics pipelines and deploy continuous training ML pipelines. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Transformational Maturity (Automate): MLOps, Continuous Integration and Delivery**
At the Transformational maturity level for "Automate," organizations develop an ML engineering culture with MLOps and implement continuous integration and delivery. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**AI Could Double Cash Flow by 2030**
Companies that fully absorb AI could potentially double their cash flow by 2030. — McKinsey & Company, September 2018


---

**Source:** `ai_adoption_framework_whitepaper`

**AI Adoption Framework Anchored in People, Process, Technology, and Data**
Google Cloud’s AI Adoption Framework is based on the interplay of people, process, technology, and data, giving rise to six themes. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Six AI Maturity Themes: Learn, Lead, Access, Scale, Secure, Automate**
The six themes of the AI Adoption Framework are Learn, Lead, Access, Scale, Secure, and Automate, each bridging two of the core areas (people, process, technology, data). — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Learn: Upskilling and Talent Acquisition**
The "Learn" theme focuses on the quality and scale of learning programs to upskill staff, hire external talent, and partner with experienced AI professionals. — Google Cloud’s AI Adoption Framework


---

**Source:** `ai_adoption_framework_whitepaper`

**Lead: Leadership Support and Collaboration**
The "Lead" theme concerns the extent to which data scientists are supported by leadership, are cross-functional, collaborative, and self-motivated. — Google Cloud’s AI Adoption Framework


---

**Source:** `aws-caf-for-ai`

**AI's Impact on Business**
AI is evolving into a powerful business capability, fueling innovation by enabling organizations to predict the future and prescribe meaningful actions based on data. This impacts all markets and businesses, driving increased investment in AI for competitive advantage. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Portfolio Management: Prioritizing AI Initiatives**
Deliver tangible business results with ML projects and products, starting with small wins to drive faith in the organization. Combine multiple AI projects into a hierarchical portfolio and embed the design of an AI flywheel. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Innovation Management: Questioning Market Hypotheses**
Bridge the gap between the long-term goals of AI research and short-term, real-world value propositions. Explore evolving customer expectations and needs, differentiating between innovation for cost reductions, revenue gains, or new income channels. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Generative AI: Leveraging Large AI Models**
Consider whether to build foundation models from scratch, fine-tune pre-trained models, or use existing models from a supplier. Unlocking the true value often means contextualizing them with domain-specific data. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**People Perspective: Culture and Change**
Organizations where the workforce embraces AI capabilities will be successful, especially through collaboration. Focus on building the right talent, speaking the same language, and fostering a supportive culture. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**ML Fluency: Building a Shared Language**
Align internally on the meaning of AI and ML, and define interface words between different practices. Implement ML fluency and culture trainings to get buy-in throughout the organization. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Workforce Transformation: Attracting AI Talent**
Attract, retain, and retrain talent that can push the AI strategy forward, including technical and non-technical roles. Align the hiring strategy with the overall AI ambition and bet early on the right AWS Partners. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Organizational Alignment: Cross-Organizational Collaboration**
Provide an encapsulated and empowered AI center of excellence (COE) to spread value and knowledge across the organization. Align the incentives of the COE with the strategy, business, and customers. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Culture Evolution: Developing an AI-First Culture**
Embrace a mentality where builders, the business, and stakeholders work backwards from business opportunities to AI challenges. Empower builders to experiment with AI systems and embrace a culture where data is the interface between teams. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Governance Perspective: Managing AI Initiatives**
Incorporate AI governance into the AI strategy to build trust, enable deployment at scale, and overcome challenges. This includes defining governance goals, developing policies, defining monitoring mechanisms, and continuously revising policies. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Cloud Financial Management (CFM): Planning AI Costs**
Plan for the cost structure of training and inference, considering the zig-zag costs over the AI lifecycle. Leverage purpose-built AI hardware and expertise to estimate resources needed and calculate the value of incremental improvements. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**AI Transformation Domains**
To adopt AI, organizations need to transform across four domains: Technology, Process, Organization, and Product. These domains depend on foundational capabilities in business, people, governance, platform, security, and operations. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Data Curation: Creating Value from Data**
Increase speed, decrease time-to-value, and boost model performance by improving data acquisition, labeling, cleaning, and processing. Treat data as code and make it a first-class citizen in the business. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Risk Management: Mitigating AI Risks**
Manage risks in the design, development, deployment, and application of AI, including financial, legal, and ethical risks. Establish solid practices like model cards and POCs to mitigate risks. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Responsible Use of AI: Fostering Innovation**
Ensure AI solutions are developed, deployed, and used ethically, transparently, and without bias. Establish an AI governance board and embed explainability by design into the AI lifecycle. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Platform Perspective: Infrastructure for AI**
Develop a platform aligned to supporting foundational capabilities to carve out competitive advantages and accelerate innovation. The platform should enable management and access of data, development of AI systems, and harnessing existing AI capabilities. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Platform Architecture: Repeatable AI Value**
Design a foundation that aligns with business objectives, ensuring adoption and enablement of the AI lifecycle. Consider AI-related requirements on the compute layer, ML/AI service layer, and consumption layer. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Modern Application Development: Building AI-First Applications**
Enhance the SDLC with AI, integrate AI into software to enhance user experience, and evaluate whether to adapt existing models or craft bespoke solutions. Break processes into smaller chunks and align with agile practices. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**AI Lifecycle Management: MLOps**
Implement MLOps practices to automate the deployment and monitoring of AI models. Align on a defined process for managing the AI lifecycle from ideation to deployment to monitoring. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Data Architecture: Fit-for-Purpose AI Data Architecture**
Evolve traditional data architectures to meet AI's complexities, including storage, management, and analytics. Consider modern data architectures that bring together data lakes, data warehouses, and other purpose-built data stores. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Platform Engineering: Building a Compliant AI Environment**
Simplify AI workflows and harness economies of scale by democratizing access to AI. Provide simplification and abstractions for different stakeholders and automate ML platform tasks. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Data Engineering: Automating Data Flows**
Integrate data pipelines directly into the AI development process and model training through streamlined pre-processing. Transition from ETL to a zero-ETL approach to reduce friction between data and AI practices. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**AI Transformation Journey: Four Key Elements**
The AI transformation journey involves: defining business outcomes, leveraging the AI flywheel, utilizing data strategy, and developing foundational capabilities. This journey should be based on iterative and incremental improvements. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Provisioning and Orchestration: Managing AI Products**
Provide self-service provisioning of AI environments for different users by creating catalogs, portfolios, and products approved by Platform Architecture. Automate the provisioning of high-performance compute for training. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Continuous Integration and Continuous Delivery (CI/CD): Accelerating AI Evolution**
Automate and harden the model development and deployment process, and use AI itself as part of the DevOps experience. Automate the deployment and testing of AI models and use tooling specific for ML pipelines. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Security Perspective: Compliance and Assurance**
Integrate security and privacy in all aspects of AI, applying risk management techniques to meet business needs. Apply security to the inputs, model, and outputs of the AI system. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Vulnerability Management: Identifying AI Vulnerabilities**
Continuously identify, classify, remediate, and mitigate AI vulnerabilities, such as prompt injection, data poisoning, and model inversion. Harden inputs through data quality automation, mitigate model threats, and sanitize outputs. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Security Governance: Establishing Security Policies**
Validate that policies are clearly defined for use of commercial or open-source models. Allocate sufficient security resources to identified roles and provide visibility. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Security Assurance: Regulatory Compliance**
Design, develop, deploy, and monitor solutions in a manner that prioritizes cybersecurity, meets regulatory requirements, and manages security risks specific to AI. Implement testing procedures and remediation processes. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Threat Detection: Mitigating Security Threats**
Improve the protection of inputs, model, and outputs by using best practices to detect and mitigate threats. Sanitize input data, conduct threat modeling, and monitor for output anomalies. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Infrastructure Protection: Securing AI Systems**
Use secure endpoints for the AI model and API Gateway for rate-limiting model access. Use API security best practices and create an explicit allow-list of API calls. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Data Protection: Maintaining Data Visibility**
Maintain visibility, secure access, and control over data used for AI development and use. Secure data in transit, at rest, and in use, and consider using data tokenization. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Application Security: Mitigating Vulnerabilities**
Verify that model developers execute prompt testing and other security test cases. Maintain an inventory of AI models and assign model instances with specifically identified technical and business owners. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**AI Adoption Stages: Envision, Align, Launch, Scale**
The AI adoption cycle consists of four stages: Envision (identifying opportunities), Align (addressing dependencies), Launch (delivering pilot initiatives), and Scale (achieving broad value). It's crucial to be ambitious but pragmatic, focusing on smaller, measurable steps. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Operations Perspective: Health and Availability**
Address incident management and performance considerations for AI workloads. Review the MLOps Maturity Framework and the Machine Learning Lens of the AWS Well-Architected Framework. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Incident and Problem Management: Managing Unforeseen Behavior**
Establish practices that acknowledge that AI systems get validated but never verified, and that they need constant control and observation. Allow customers and users to flag results as unfavorable or wrong. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Performance and Capacity: Monitoring AI Workloads**
Adapt to numerous and very different workloads, often dominated by experiments and training. Use the cloud to react dynamically to these workload profiles. — AWS Whitepaper
```


---

**Source:** `aws-caf-for-ai`

**Foundational Capabilities for AI Adoption**
Iterating through the AI transformation journey relies on foundational capabilities across business, people, governance, platform, security, and operations. These capabilities are organizational abilities to use processes to deploy resources and achieve outcomes. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Business Perspective: AI Strategy**
The business perspective focuses on capabilities that enable businesses to leverage AI, reduce risks, and increase outputs. This includes strategy management, product management, business insights, portfolio management, innovation management, and generative AI. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Strategy Management: AI for Business Value**
Define a business- and customer-centric north star for AI adoption, underpinned by an actionable strategy. Base the strategy on tangible business impact and consider the self-reinforcing properties of a data flywheel. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Product Management: Managing AI-Based Products**
Building and managing AI-based products is challenging due to the differences in development and lifecycle compared to traditional software. Work backwards from customer value and map measurable business proxies to decision points supported by AI. — AWS Whitepaper


---

**Source:** `aws-caf-for-ai`

**Business Insights: AI-Enabled Analytics**
Transition the BI practice to an AI-enabled one by using algorithms with diagnostic analytics to understand key variables. Create a center of excellence for analytics tied to cloud initiatives to democratize access to data-driven predictions. — AWS Whitepaper


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**The Challenge: Embedding Analytics**
Companies struggle to capture real value from analytics because they fail to embed it into all areas of the organization, despite making investments. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Strategy: Focus on the Last Mile**
Nearly 90% of breakaway organizations devote more than half of their analytics budgets to embedding analytics, compared to only 23% of others. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Clear Data Strategy**
Breakaway organizations are 2.5 times more likely to have a clear data strategy to support their analytics strategy. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Strong Data Governance**
Breakaway organizations are twice as likely to report strong data-governance practices that allow them to identify and prioritize data. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Key Capability: Data Strategy Elements**
Successful data strategies include a clear data ontology, a master data model, governance plans, and a plan for technical requirements. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Sophisticated Analytics Methodologies**
Breakaway companies are 2.5 times more likely to have a clear methodology for developing models, interpreting insights, and deploying new capabilities. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Model Management**
Leading analytics programs focus on model development and continuously maintain and upgrade models as part of a sophisticated model-management function. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Challenge and Test Approach**
Breakaway companies are twice as likely to use a challenge and test approach to continuously improve the quality and performance of analytics models. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Advanced Analytics Techniques**
Breakaway companies are more likely to use sophisticated analytics techniques like reinforcement learning and deep learning. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Deep Analytics Expertise**
Breakaway companies are 1.5 times more likely to have deep functional expertise in data science, data engineering, data architecture, and analytics transformation. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Analytics Talent Density**
Breakaway companies are 2.5 times more likely to employ more than 25 analytics professionals per 1,000 full-time equivalents (FTEs). — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Breakaway Companies: Achieving Analytics at Scale**
Only 8% of companies surveyed are achieving analytics at scale, demonstrating superior performance across key dimensions. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Analytics Talent Strategy**
Breakaway companies establish a clear core center of gravity for analytics talent with well-defined roles and career-development paths. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Foundational Capabilities: Cross-Functional Agile Teams**
Nearly 60% of breakaway organizations use cross-functional teams, compared to less than a third of other respondents. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Embedding Analytics**
The biggest challenge is turning insights into outcomes, known as the last mile, where the value of analytics is ultimately extracted. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: User-Friendly Analytics**
Embedding requires making analytics user-friendly and customized for each group making priority decisions, using tools like dashboards and mobile apps. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Cultural Shift**
Companies must embed analytics-based decision making into the corporate culture, creating an environment where workers embrace analytics. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Prioritizing Top Decision-Making Processes**
Breakaway companies prioritize and map the decisions that will drive the most value by being addressed with "right-time" data insights. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Prioritization of Key Decisions**
Breakaway companies are almost twice as likely to have identified and prioritized the top 10–15 decision-making processes in which to embed analytics. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Clear Decision-Making Rights and Accountability**
Breakaway organizations are more than twice as likely to have clear accountability and decision rights by role. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Empowering the Front Lines**
To turn analytics insights into outcomes, organizations must enable frontline employees to easily leverage analytics to make decisions. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Last Mile: Quick, Refined Decision Making**
Breakaway companies are about 1.5 times more likely to report that their organizations have achieved quick, continually refined decision making through analytics. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Key Finding: Nine Critical Drivers**
Breakaway companies outperform others in nine critical areas across three categories: strategy, foundational capabilities, and embedding analytics into decision-making. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**AI Roadmap: Start with Decision-Making Processes**
To achieve analytics at scale, companies should start by identifying the decision-making processes they could improve and then work backward to determine what data insights are required. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Three Categories for Scaling Analytics**
The nine critical drivers for scaling analytics fall into three main categories: aligning on strategy, building the right foundations, and conquering the last mile. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Strategy: Unified Commitment from Management**
Breakaway companies are twice as likely to report complete alignment on an analytics vision and strategy from all levels of management. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Strategy: Analytics Across Functions**
Breakaway companies are 3.5 times more likely to be applying analytics to three or more functional areas due to strong leadership commitment. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Strategy: Analytics Expertise in Leadership**
One major US bank requires analytics expertise for business leadership positions, extending beyond the C-suite. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Strategy: Middle Management Buy-In**
57% of breakaway companies report that their middle management believes becoming an analytics-driven organization is imperative, nearly twice that of other respondents. — McKinsey Analytics


---

**Source:** `breaking-away-the-secrets-to-scaling-analytics`

**Strategy: Increased Analytics Investments**
Breakaway companies spend more on analytics and plan to increase these investments significantly. — McKinsey Analytics


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: Leaders Must Execute Fastest**
The leaders that win the day will be the ones who stay aligned to their strategic plans and execute the fastest in implementing Gen AI solutions. — IBM IBV 2023-2024


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Break Away from "Break-Fix" Model**
CEOs need to focus on modernizing all aspects of the IT estate to enable greater automation, empowering teams to move beyond fixing what’s broken to focus on more strategic work.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Make Tech Less Techy**
Embed IT in the boardroom and make technology and automation central to every business strategy, challenging leaders to connect performance metrics to the systems, platforms, and tools that enable their success.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Conquer Complexity with Intelligent Visibility**
Use gen AI-enabled digital twins to model the effects of specific disruptions across the enterprise and the ecosystem, improving ROI with more accurate estimates of how much investments in technology and automation will cost—and how much value they will deliver.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: No One-Size-Fits-All AI Model**
There’s no such thing as an all-purpose generative AI model; different business problems demand different types of models, from large models for complex tasks to smaller, niche models for specialized work.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Model Agnostic Mindset**
Remain agile to adopt the models that have been optimized for price and performance, striking the right balance between accuracy, resource usage, and speed.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Engineer for Efficiency**
Tailor model scope to the deployment environment, favoring faster niche models for mobile and real-time applications and larger models for high-accuracy, complex tasks.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Make Models Work Harder**
Don’t be satisfied with early successes. Continually push teams to aggressively improve model performance and outpace the competition by using the latest AI techniques and infrastructure.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: Cost of Compute Can Derail Gen AI Plans**
Costs can derail your best-laid generative AI plans. Every single executive surveyed said their organization has cancelled or postponed at least one gen AI initiative due to cost of compute concerns. — IBM IBV 2024


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Get a Grip on Cost of Compute**
Pinpoint the factors driving up generative AI expenses—and stay ahead of the curve as your projects scale. Set clear cost guardrails and assess compute needs as early as possible in project planning to avoid expensive surprises down the line.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Forge a Unified Front with Gen AI and Hybrid Cloud**
Channel the combined power of gen AI and hybrid cloud to deliver on concrete business goals, optimizing and orchestrating with hybrid by design and containerized workloads to corral compute costs and streamline operations.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Quote: Focus on Use Cases**
"'How can we use generative AI?' is not the right question. It’s, 'What use cases have we got that we need the most help with and what role could different areas of technology and data analytics play?'" — Bernie Hickman, CEO, Legal & General Retail


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Move Lightning-Fast at Lower Cost**
Arm managers with intelligent decision support tools that slash compute costs and fuel real-time adaptability, automating workflows and pruning models to unlock a new era of efficiency, reduce costs, and unleash innovation.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: Gen AI Offers Second Chance at Platform Business Model**
Generative AI levels the playing field, letting businesses do more with less on every front. The true reward will come from business model innovation. — IBM IBV 2023-2024


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Jump at Opportunity for Second Chance**
Collect all the platform puzzle pieces you couldn’t gather the last time you thought about becoming a platform business, acting like a startup and avoiding incrementalism.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Outfit a Gen AI Data Expedition**
Find the data your platform needs in data lakes, data mines, data warehouses, content management systems—even laptop hard drives.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Put Governance at Heart of Gen AI Lifecycle**
Make governance a fixture on the executive leadership team’s agenda, balancing the power of gen AI with the guardrails required for trustworthy execution.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: Gen AI Reinforces Ecosystem Innovation**
Gen AI can ignite ecosystem innovation by tapping into the collective brainpower of many organizations quickly and easily. By synthesizing their shared expertise, it can brainstorm potential solutions to big problems, predict which products will be most successful, and optimize project plans to deliver desired outcomes.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Innovate the Way You Innovate**
Use generative AI to spark creativity and enhance collaboration throughout the innovation cycle, synthesizing expertise across the ecosystem to solve complex problems, develop competitive products, and disrupt traditional business models.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Prepare for Higher Value Work with Cross-Ecosystem Skills**
Unleash the potential of generative AI-powered ecosystem innovation by addressing internal barriers, building and developing data, skills, and culture as critical ingredients to drive long-term ecosystem success.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Reevaluate Relationship Status**
Tap your ecosystem’s collective intelligence, assessing whether you have the right partners to spur your innovation forward—and be prepared to swipe left.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: Gen AI and App Modernization Fuel Agility and Revenue Growth**
Combined, generative AI and app modernization fuel a virtuous cycle of increased agility and revenue growth, enabling transformation initiatives that just weren’t feasible before.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Hyper-Personalization at Scale**
Executives expect generative AI to pave the way for personalized experiences at a scale never seen before by analyzing every click, swipe, and interaction. — IBM IBV 2023-2024


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Grab Low-Hanging Fruit**
Apply gen AI to modern applications to showcase its potential, demonstrating its ability to deliver specific business outcomes to overcome the inertia that plagues some modernization initiatives.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Go After Previously "Off Limits" Opportunities**
Reach beyond low-hanging fruit to high-value opportunities that were either too difficult or too scary to attempt modernizing before, urgently advancing modernization efforts in core business systems.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Stop Measuring Business and IT Goals Separately**
Rather than crafting alliances of convenience, form firm and unyielding partnerships between IT and the business, going beyond establishing innovation squads for generative AI by holding all leaders accountable for both technology modernization and business performance, irrespective of their roles.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: CEOs Can't Pass the Buck on AI Ethics**
CEOs must take the reins and blaze a trail for others to follow in AI ethics, as roughly three times more executives look directly to CEOs for guidance on AI ethics than the board of directors, general counsel, privacy officers, or risk and compliance officers.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Give Ethics Teams a Seat at the Table**
Roll up your sleeves to close the gap between intentions and actions, championing ethics teams, policies, and monitoring, and reporting progress to the board of directors and externally, as appropriate.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Earn Trust by Aligning with Customer Expectations**
Build a collaborative culture of trust from the bottom up, making ethics everyone’s responsibility—and governance a collective noun.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Bake in Regulatory Preparedness and Ethics**
Craft your strategy based on the broad strokes of emerging regulations, course-correcting when essential details are finalized, aligning with internal policies and procedures—and keep recalibrating as rules evolve, staying focused on trustworthy AI and good governance every step of the way.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: Gen AI Driving Unexpected Spending**
Gen AI is exposing cracks in old-fashioned funding practices. Like any nascent technology, it’s dynamic by nature. What it needs—and how it can deliver value—is changing by the day. And that throws a wrench into the traditional budgeting process.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Don't Get Sidelined by Ballooning IT Budget**
Make sure you have a clear understanding of how high-impact projects will tap resources—both human and technical—to accurately budget for associated costs.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Unclog the People Cost Bottleneck**
Bolder, high-ROI initiatives can attract top talent and help absorb spiking AI talent costs—if your organization can stomach the higher price tag.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Redesign Product Development**
Redesign product development to derive high-value product insights from every customer interaction, continuously learning and generating the experiences, products, and content customers want—at exactly the right time.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Be Intentional and Stack Investments**
Dive into the data to decide where your generative AI program can provide the most bang for your buck, worrying less about financial precision until you’ve designed initiatives worth doing.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Reboot How Your Organization Operates**
Explore hybrid generative AI deployment models, such as the “hub and spoke” approach, and update your operating model to enable a hybrid approach to decision-making.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Empower People to Drive Transformation**
Foster a collaborative culture of shared responsibility, inclusivity, and proactive engagement, evolving the operating model to facilitate the creation of interdisciplinary teams better equipped to ideate innovative products and solutions and overcome the obstacles to scaling generative AI.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Make Innovation at Scale Your North Star**
Design an operating model that fosters innovation across your ecosystem by building bridges and enabling rapid adaptation in lockstep with partner organizations.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Give Operations Teams Runway to Experiment**
Reward teams for getting creative with process automation in operations, as long as they provide clear documentation about what worked, highlighting where they delivered measurable business value and where efforts fell short.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Treat AI Assistants Like Racecars**
Provide a roadmap that shows employees where and when they should automate or augment processes with AI assistants, giving them an owner’s manual that explains how to use these powerful machines effectively and responsibly.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Trade Control for Capability**
Tap partners with generative AI expertise to automate processes that aren’t core to your competitive advantage, developing new internal roles, such as process orchestrators, digital librarians, and experience designers, to improve processes that must be managed in-house.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Get Your CPO to Build the Business Case**
Address reservations hindering generative AI outcomes, elevating the role of procurement from the transactional to the strategic.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Take First-Mover Advantage**
Commit brainpower—and bandwidth—to push gen AI projects past pilot phase to unlock your supply chain’s full potential.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Anticipate, Adapt, Accelerate**
Report on a broader set of key supplier sustainability metrics more frequently—and set a higher bar, putting partners on alert and holding them accountable.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Supporting Fact: Revenue Premium for Early Adopters**
Companies that have embraced gen AI for digital product idea generation delivered a 17% revenue premium for new products and 5% greater revenue from existing product enhancements in 2023. — IBM IBV 2023-2024


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Set a Risk Threshold that Fuels Innovation**
Understand the full spectrum of risks generative AI introduces and their impact on your existing risk profile, then explicitly define how much risk you’re willing to accept to move the needle.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Cool Simmering Reputational Risks**
Maintain credibility with stakeholders by monitoring and responding to reputational risks as they emerge with gen AI, predicting which risks are most likely to escalate and suggesting proactive mitigation strategies to keep the lid on heated situations.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Prepare for 100-Year Risks Every Week**
Use generative AI to stress-test your strategy and build resilience into your operations, giving risk managers the operational visibility they need to protect value and transform potential threats into opportunities.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Lengthen Lifespan of Physical Assets**
Get ahead of routine maintenance, fine-tune processes, and drive unprecedented reliability and profitability by embedding generative AI into physical assets.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Make Machines Self-Aware**
Overcome predictive maintenance barriers by giving your assets the power to self-monitor, self-maintain, and communicate their status across the network and partner ecosystem.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Major on Eco-Friendly Innovation**
Merge disparate data streams to uncover actionable insights that drive asset performance optimization and sustainability outcomes, visualizing the intricate web of asset relationships and simulate scenarios to future-proof sustainability strategies and reduce environmental impact.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Stop Fighting Fires**
Enable innovation with real-time, data-driven insights, pairing these findings with business know-how to deliver differentiated outcomes.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Feed Gen AI Data that Supports Productivity**
Map the full range of preemptive data initiatives needed to connect people and technology across the supply chain ecosystem, upskilling employees and train tools to speed decisions and actions.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Supercharge Supply Chain Operating Models**
Create self-learning simulations that let you identify, visualize, and proactively correct critical operating exceptions, hyper-automating transactional work to create next-level operational efficiencies.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Position Marketing as Model for Workforce Transformation**
Challenge your CMO to redefine what marketers do and what they don’t, building lessons learned into transformation of other functions across the enterprise.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Build Augmented Teams**
Build augmented teams to prepare for an influx of generative AI-infused workflows, leveraging gen AI to ideate and rapidly validate a high volume of ideas with customers.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Prioritize Creative Ideation**
Raise the bar for marketing materials by tying them to touchpoints and moments of truth along the customer journey, boosting productivity by streamlining content creation and diverting human energy toward higher-value work.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Build 360-Degree Customer Profiles**
Unify data to make hyper-personalized marketing possible, giving CMOs autonomy over the marketing tech stack across all touchpoints, including sales and service.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Treat Gen AI Like a Burning Platform**
Pressure cybersecurity leaders to act with urgency, responding to gen AI’s risks as immediate—not incremental.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Make Trusted Data the Backbone**
Evolve your cybersecurity practices to consider the requirements of multiple generative AI models and data services.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Reorient Cybersecurity Investments**
Make AI an essential tool to strengthen security defenses, encouraging cybersecurity leaders to embed generative AI and automation into their tool kits to resolve security risks and incidents at speed and at scale.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Turn Trade-Offs into Win-Wins**
Use generative AI to address key sustainability data gaps, make reporting processes more efficient, reduce risk, and comply with rapidly changing requirements.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Make 1+1=3 with Ecosystem Partners**
Scale impact across the enterprise and the ecosystem to pursue sustainability and profit as complementary business goals, co-creating generative AI capabilities with partners to limit environmental impact and advance sustainability initiatives.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Use Gen AI to Make a Net Positive Impact**
Minimize the environmental impact of gen AI by building on existing foundation models rather than starting from scratch, using gen AI to create better code with lower environmental impact and redesign data centers to consider sustainability.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Turn Human Agents into Heroes**
Free up human agents so they can pivot to more personalized customer engagement—where it matters most—to offer enhanced value to customers, differentiate your brand, and begin transforming customer service from a cost center into a revenue accelerator.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Use Gen AI to Learn More About Customers**
To conquer high risks and capture high rewards in customer service, gen AI deployment should be about listening, testing, and then capitalizing.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Upskill Product Teams on Experience and Innovation**
Upskill product teams on experience and innovation, identifying time and money drains in the build and test cycle that can be powered by generative AI and redistribute these resources in a way that supports the development of better UX/UI and more innovative products.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Exploit Successes and Learnings**
Because generative AI is as much about your people as it is about technology, the very visible realm of customer service will serve to motivate change across the enterprise.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Find the Friction and Obliterate It**
While generative AI is accessible to all, how CEOs choose to use this capability can be a differentiator. By analyzing large amounts of user data, gen AI can identify common pain points and help design experiences that are intuitive, engaging, and unique.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Create Ethical Journeys**
Lead with empathy to build trust while you speed toward innovative new experiences, prioritizing ethics and invite customer feedback to engage customers, identify pain points, and pivot as their demands evolve.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Critical Capability: Give Workers What They Want**
Use generative AI to put your employees in the operating model of tomorrow, developing effective human-machine partnerships to create more value than either can alone—and keep employee engagement top of mind.
```


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Key Finding: IT Automation as Innovation Launchpad**
IT automation, streamlined by generative AI, liberates teams from maintenance and support, freeing them to envision a future built on new transformative technologies and new digital products and revenue streams.


---

**Source:** `ceos-guide-to-generative-ai-second-edition`

**Supporting Fact: Gen AI for Code Generation**
Today, 62% of IT executives say their organizations are using gen AI for code generation—and that figure will jump to 87% by 2026. — IBM IBV 2024


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Margin Compression in Asset Management**
Pre-tax operating margins in asset management have declined by three percentage points in North America and five percentage points in Europe between 2019 and 2023. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Efficiency Impact of AI in Technology**
Gen AI is reshaping software development and maintenance, potentially leading to a 20% efficiency impact. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Key Finding: Domain-Based Transformation**
Asset managers should reimagine organizational domains through zero-based, AI-enabled redesign of workflows, anchored in strategic priorities. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Key Finding: Revamping Talent Strategies**
Firms need to upskill existing talent and raise AI literacy, focusing on building AI capabilities rather than solely hiring new talent. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Key Finding: Optimizing Operating Models with AI**
A governance model blending centralized oversight with decentralized experimentation and delivery is most effective. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Key Finding: Maintaining Control of Technology Roadmaps**
Asset managers should retain ownership of their technology roadmaps, using vendors strategically while insourcing critical capabilities. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Key Finding: Developing Data Strategies**
Asset managers need to redesign their data governance practices, establish unified data platforms, and implement robust governance strategies to manage unstructured data. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Key Finding: Enabling Effective Adoption of AI**
Successful AI adoption requires gradual adaptation, structured support, and behavior rewiring, with a dedicated change management team. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Critical Capability: Domain Redesign**
Asset managers must redesign workflows from the ground up, leveraging AI to streamline processes and improve efficiency across entire domains. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Critical Capability: Talent Upskilling**
Asset managers need to invest in training programs to upskill existing employees in AI-related skills, enabling them to effectively use AI tools in their roles. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Critical Capability: Data Governance**
Establishing unified data platforms and robust governance strategies is crucial for managing unstructured data and ensuring compliance in AI initiatives. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Technology Spending vs. Productivity Paradox**
Despite increased technology investments, cost as a share of AUM has remained relatively flat, and there's no clear correlation between higher tech spend and improved productivity. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Critical Capability: Change Management**
A dedicated change management team is essential for driving AI adoption, influencing mindsets, and ensuring that employees embrace new AI-driven processes. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**AI Roadmap: Focus on Reusable "Recipes"**
Leading asset managers are focusing on reusable AI "recipes" and capability patterns to standardize processes, reduce integration risks, and embed AI across the tech stack. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**AI Roadmap: Prioritize Data Capabilities**
Prioritizing data capabilities in change-the-bank budgets is essential to unlock the full value of AI agents. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Measuring Success: Efficiency Gains and Revenue Growth**
Productivity lift of 25-40% and revenue growth can be unlocked by asset managers that prioritize the right AI tech bets. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Measuring Success: Behavior Shifts and Uplift in Software Development**
Revenue efficiency gains from AI-powered software development life-cycle automation only emerge after teams move beyond initial tool usage spikes, with lasting behavior shifts and a 15 to 30 percent uplift typically taking six to nine months. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Run-the-Business vs. Change-the-Business Spending**
Asset managers allocate 60-80% of their technology budget to "run-the-business" initiatives, leaving only 20-40% for "change-the-business" operations, with a small fraction dedicated to firmwide digital transformation. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Legacy Systems and Tech Debt**
Fragmented systems and outdated technology stacks drive up operational complexity and costs, creating a vicious cycle of maintaining legacy systems instead of modernizing. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**AI Leapfrog Opportunity for Asset Managers**
AI presents a "once-in-a-generation opportunity" for asset managers to break out of entrenched cost structures and recover profitability levels. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**AI-Driven Value Creation Areas**
C-suite leaders identified AI-driven value in improving distribution flows, enhancing data processing in investment management, automating compliance control, and transforming software development. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Efficiency Impact of AI in Client-Facing Roles**
Gen AI in client-facing roles can enable more seamless and personalized interactions, potentially resulting in a 9% efficiency impact. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Efficiency Impact of AI in Investment Management**
Gen AI is transforming insight generation and decision-making in investment management, with a potential 8% efficiency impact. — McKinsey 2025 Report


---

**Source:** `how-ai-could-reshape-the-economics-of-the-asset-management-industry (1)`

**Efficiency Impact of AI in Risk and Compliance**
Gen AI is streamlining manual processes in risk and compliance, with an estimated 5% efficiency impact. — McKinsey 2025 Report


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Key Finding: Agents Suited for Complex, Unstructured Tasks**
Agents are well-suited for use cases involving complex decisions, unstructured data, or brittle rule-based systems.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Model Selection: Performance Baseline**
Set up evals to establish a performance baseline for model performance.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Model Selection: Accuracy Target**
Focus on meeting your accuracy target with the best models available.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Model Selection: Cost and Latency Optimization**
Optimize for cost and latency by replacing larger models with smaller ones where possible.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Tool Types: Data, Action, Orchestration**
Agents need tools for data retrieval, action execution (e.g., sending emails), and orchestration (using other agents as tools).


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Best Practice: Standardized Tool Definitions**
Each tool should have a standardized definition, enabling flexible, many-to-many relationships between tools and agents, improving discoverability and version management.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Best Practice: Use Existing Documents for Instructions**
Use existing operating procedures, support scripts, or policy documents to create LLM-friendly routines.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Best Practice: Prompt Agents to Break Down Tasks**
Providing smaller, clearer steps from dense resources helps minimize ambiguity and helps the model better follow instructions.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Best Practice: Define Clear Actions**
Make sure every step in your routine corresponds to a specific action or output.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Best Practice: Capture Edge Cases**
A robust routine anticipates common variations and includes instructions on how to handle them with conditional steps or branches.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**AI Roadmap: Incremental Approach to Agent Building**
Customers typically achieve greater success with an incremental approach, rather than immediately building a fully autonomous agent with complex architecture.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Agent Definition**
Agents are systems that independently accomplish tasks on your behalf, leveraging an LLM to manage workflow execution and make decisions.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Orchestration Patterns: Single-Agent vs. Multi-Agent**
Orchestration patterns fall into single-agent systems (one model executing workflows in a loop) and multi-agent systems (workflow execution distributed across coordinated agents).


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Single-Agent Systems: Manage Complexity with Prompt Templates**
Use a single flexible base prompt that accepts policy variables to adapt easily to various contexts, significantly simplifying maintenance and evaluation.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**When to Consider Multiple Agents: Complex Logic or Tool Overload**
Consider splitting tasks across multiple agents when prompts contain many conditional statements or when tool similarity/overlap hinders performance.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Multi-Agent Patterns: Manager vs. Decentralized**
Multi-agent systems can be Manager (central agent orchestrates specialized agents) or Decentralized (agents hand off tasks to one another).


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Manager Pattern: Centralized Control**
The manager pattern empowers a central LLM to orchestrate a network of specialized agents seamlessly through tool calls.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Decentralized Pattern: Agent Handoffs**
In a decentralized pattern, agents can ‘handoff’ workflow execution to one another, optimal when you don’t need a single agent maintaining central control or synthesis.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Critical Capability: Guardrails for Safety and Predictability**
Guardrails are critical at every stage, from input filtering and tool use to human-in-the-loop intervention, helping ensure agents operate safely and predictably in production.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Guardrails: Layered Defense Mechanism**
Using multiple, specialized guardrails together creates more resilient agents.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Guardrail Types: Relevance, Safety, PII, Moderation, Tool Safeguards, Rules-Based, Output Validation**
Examples include relevance classifiers, safety classifiers, PII filters, moderation, tool safeguards, rules-based protections, and output validation.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Guardrail Implementation: Focus on Data Privacy and Content Safety**
Set up guardrails that address the risks you’ve already identified for your use case and layer in additional ones as you uncover new vulnerabilities.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Non-Agent Examples**
Simple chatbots, single-turn LLMs, or sentiment classifiers are not agents because they don't use LLMs to control workflow execution.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Guardrail Implementation: Add New Guardrails Based on Real-World Edge Cases**
Add new guardrails based on real-world edge cases and failures you encounter.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Guardrail Implementation: Optimize for Security and User Experience**
Optimize for both security and user experience, tweaking your guardrails as your agent evolves.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Critical Capability: Human Intervention**
Human intervention is a critical safeguard enabling you to improve an agent’s real-world performance without compromising user experience.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Human Intervention Triggers: Failure Thresholds and High-Risk Actions**
Two primary triggers typically warrant human intervention: exceeding failure thresholds and high-risk actions.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**AI Roadmap: Start Small, Validate, and Grow**
The path to successful deployment isn’t all-or-nothing. Start small, validate with real users, and grow capabilities over time.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Agent Core Characteristics**
Agents leverage an LLM for decision-making, recognize workflow completion, proactively correct actions, and halt execution to transfer control to the user if needed.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Agent Components: Model, Tools, Instructions**
An agent consists of an LLM (Model), external functions/APIs (Tools), and explicit guidelines/guardrails (Instructions).


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Critical Capability: Tool Access and Selection**
Agents need access to various tools to interact with external systems, dynamically selecting appropriate tools based on the workflow's current state, within defined guardrails.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**When to Build an Agent: Prioritize Difficult-to-Automate Workflows**
Prioritize workflows that have previously resisted automation, especially where traditional deterministic and rule-based methods encounter friction.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Use Case Criteria for Agents: Complex Decisions, Rules Maintenance, Unstructured Data**
Consider agents for workflows involving nuanced judgment, difficult-to-maintain rulesets, or heavy reliance on unstructured data.


---

**Source:** `openai-a-practical-guide-to-building-agents`

**Model Selection: Start with Capable Model, Optimize Later**
Build your agent prototype with the most capable model to establish a performance baseline, then try swapping in smaller models to optimize for cost and latency.


---

**Source:** `securing-ai`

**AI Systems Support Strategic Decision Making**
AI systems are increasingly responsible for supporting strategic decision-making, making them targets for adversaries seeking to degrade, deny, deceive, or manipulate them. — [Introduction]


---

**Source:** `securing-ai`

**Anomaly Detection Limitations in AI Security**
Organizations can't rely as much on anomaly detection to discover malicious intent in AI systems because AI systems often act stochastically and produce unpredictable results. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**GenAI's Non-Deterministic Nature Adds Complexity**
The non-deterministic nature of GenAI adds complexity to security testing by multiplying error scenarios, making it difficult to assess every imaginable attack path. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**Defense-in-Depth, Secure-by-Design, and Zero Trust as Foundation**
Enterprises can leverage strategies like defense-in-depth, secure-by-design, and zero trust as a solid foundation for securing AI systems. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**AI Models: Complex Software Modules**
AI models are the most complex software modules ever created, making it more difficult to find, analyze, and remediate attacks. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**AI "Black Box" Hides Cybersecurity Information**
The "black box" nature of AI models makes it difficult to understand how inputs become outputs, hindering security professionals who need visibility into application function and data usage. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**Third-Party AI Model Risks**
Enterprises often procure AI models from third-party providers, assuming built-in security, but providers may have different security priorities than the enterprise. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**Open-Source AI Model Risks**
Organizations downloading pretrained, open-source AI models may overlook malware and other threats, requiring them to find their own security solutions. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**AI Systems Must Adhere to Established Security Requirements**
Despite their unique characteristics, AI systems remain enterprise systems and must adhere to established security requirements. — [Who is Responsible for AI Security?]


---

**Source:** `securing-ai`

**AI Security Engineering Augments Traditional Security**
Traditional risk, DevSecOps, and cybersecurity teams will be supported and augmented by AI security engineering teams with expertise in core AI operations and special risks. — [Who is Responsible for AI Security?]


---

**Source:** `securing-ai`

**Gartner: IT/Security Leaders Involved in GenAI Security**
Nearly all (93%) of IT/security leaders surveyed are at least somewhat involved in their organization’s GenAI security/risk management efforts, but just 24% said they own this responsibility. — [Gartner Report, Who is Responsible for AI Security?]


---

**Source:** `securing-ai`

**Increased AI Adoption = Increased Risk**
The more AI-driven use cases an organization implements, the more AI integrations fall into the crosshairs of adversaries, bringing increased risk of mission failure and reputational damage. — [Introduction]


---

**Source:** `securing-ai`

**IBM IBV: Secure AI is Essential, But Not Implemented**
An IBM IBV survey found that while 82% of respondents say secure and trustworthy AI is essential, just 24% of their current generative AI projects have a component to secure these initiatives. — [IBM IBV Survey, Who is Responsible for AI Security?]


---

**Source:** `securing-ai`

**Integrated Approach to Secure Systems**
Leading enterprises employ an integrated approach that assesses potential risks, implements critical guardrails, hardens systems during design and development, and actively monitors and defends against potential threats. — [How AI Security Engineers Reinforce the Security Foundation]


---

**Source:** `securing-ai`

**AI Security Engineers Enhance GRC**
AI security engineers can enhance GRC for AI-related risks by monitoring for data privacy, assisting with compliance, and integrating AI risk management with broader GRC guardrails. — [How AI Security Engineers Reinforce the Security Foundation]


---

**Source:** `securing-ai`

**AI Security Engineers Strengthen Model Training and Architectures**
AI security engineers can ensure more robust model training and architectures to strengthen their attack resilience. — [How AI Security Engineers Reinforce the Security Foundation]


---

**Source:** `securing-ai`

**AI Security Engineers Perform Deep Testing and Monitoring**
AI security engineers can perform deep testing and monitoring of AI systems to detect suspicious behavior that might be otherwise overlooked due to the technology’s non-deterministic nature. — [How AI Security Engineers Reinforce the Security Foundation]


---

**Source:** `securing-ai`

**AI Security Lapses Lead to Reputational Damage and Financial Liability**
AI security lapses and glitches take various forms, and even the world’s most well-funded AI innovators are not immune, resulting in reputational damage and financial liability. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Examples of AI Security Lapses**
Examples include: TrojanPuzzle attacks, ChatGPT data leaks, malicious dependency packages, and fooled facial authentication models. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Need for Controls for Safe AI Integration**
These malicious actions and algorithmic errors highlight the critical need for organizations to implement controls that allow safe integration of AI with core systems and processes. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Adversarial Personas Targeting AI**
Adversarial personas range from individual threat actors and hacktivists to financially motivated criminal organizations and nation-states. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Key Finding: Catastrophic AI Attack is a Matter of "When," Not "If"**
Many experts believe a catastrophic attack on AI systems is a matter of "when" not "if," given the value of the information underlying these systems and their overall risk profile. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**AI and Cybersecurity Talent Shortage**
Organizations face a shortage of AI and cybersecurity talent, particularly those who understand the security risks of LLMs and can collaborate effectively with data scientists and AI engineers. — [Introduction]


---

**Source:** `securing-ai`

**Limited AI Deployments Due to Security Concerns**
A comparatively smaller number of AI systems are deployed in full production, given challenges in certifying them as fully secure to achieve authority to operate (ATO). — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**AI Attack Surface is Inviting**
The attack surface continues to be inviting, as these types of attacks may in some cases be easier to carry out than breaking into web servers or overwhelming networks. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Data Poisoning: Manipulating Training Data**
Adversaries manipulate training data to compromise model behaviors and insert backdoors through data poisoning. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Malware in AI Models**
Adversaries package malicious code within model files and libraries, similar to malware in any other file. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Model Evasion: Fooling the Model**
Adversaries perturb model inputs to control model outputs, also known as model evasion. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Large Language Model Misuse: Jailbreaking**
Adversaries override an LLM’s instructions and safety alignment through jailbreaking. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**Data Leakage and Model Theft**
Adversaries infer and steal sensitive training data, model behavior, and/or intellectual property through data leakage and model theft. — [What do AI Security Threats Look Like?]


---

**Source:** `securing-ai`

**One-Size-Fits-All AI Security Strategy is Ineffective**
Given the diversity of threats and threat actors, enterprises cannot simply embrace a one-size-fits-all strategy. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**MITRE ATLAS for Benchmarking AI Security**
Booz Allen often uses a comprehensive security framework such as MITRE ATLAS to benchmark the current state and identify realistic objectives that meaningfully enhance the security posture. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**Key AI Security Engineering Practices**
Key practices include: Risk Modeling, Red Teaming, Security Testing, Model Scanning, Dependency Scanning, Data Tampering Detection, Robust Model Training, Operational Controls and Monitoring, Model Updates, and Governance. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**Key Quote: AI Security Expertise is Rare**
"Those who understand the security risks of LLMs and can collaborate effectively with data scientists and AI engineers '. . . is a much smaller and rarer group of people.'" — [Ben Aung, chief risk officer at Sage, via Wall Street Journal]


---

**Source:** `securing-ai`

**Tailored Analysis for AI Security Practices**
Organizations should conduct a tailored analysis to identify what AI security practices to incorporate rather than setting out to apply each practice. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**Qualify and Control Risks Through Risk Modeling and Governance**
At a minimum, organizations must qualify and control risks by performing risk modeling and establishing a governance plan. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**Open-Source Tools for Model and Dependency Scanning**
Open-source tools for model and dependency scanning can be incorporated at very low cost and quickly integrated into the MLOps pipeline. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**Risk Profiles for Different AI Use Cases**
Different risk profiles exist for: GenAI for Business, Third-Party GenAI Model Integration, Pretrained Models, Fine-Tuned Models, and Homegrown Models. — [Getting Started with an AI Security Strategy]


---

**Source:** `securing-ai`

**AI Security: A Team Effort**
AI security must be a team effort, requiring collaboration across CIOs, chief risk officers, CTOs, and CISOs, as well as AI security engineering expertise. — [Everyone Has a Role to Play in AI Security]


---

**Source:** `securing-ai`

**Updating Operating Policies for AI**
The inclusion of AI technologies within enterprise systems requires that organizations update some of their most critical operating policies. — [Everyone Has a Role to Play in AI Security]


---

**Source:** `securing-ai`

**Critical Operating Policies for AI**
Critical operating policies include: Integrated Oversight and Management, Risk Assessment, Governance and Policy, Continuous Improvement, and Upskilling. — [Everyone Has a Role to Play in AI Security]


---

**Source:** `securing-ai`

**Continuous Improvement and Upskilling are Vital for AI Security**
The dynamic nature of AI technology necessitates continuous learning and improvement in security practices. — [Everyone Has a Role to Play in AI Security]


---

**Source:** `securing-ai`

**Regulators and Standards Organizations Offer AI Security Resources**
Regulators and standards organizations like NIST, MITRE, and OWASP offer frameworks, tools, and knowledge bases for AI security. — [Appendix A: Mobilizing to Advance AI Security Resources]


---

**Source:** `securing-ai`

**Expansion of AI Security Threats Catalyzes Growth in Countermeasures**
The expansion of AI security threats has catalyzed a corresponding growth in tools for countering them. — [Appendix A: Mobilizing to Advance AI Security Resources]


---

**Source:** `securing-ai`

**AI Skills Shortage: Prompt Injection**
O’Reilly’s State of Security in 2024 study found that 33.9% of respondents identified a shortage of AI skills, particularly for vulnerabilities like prompt injection, as one of their most significant gaps. — [Introduction]


---

**Source:** `securing-ai`

**Biden Administration's Executive Order on AI**
The Biden Administration’s Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence calls for robust, reliable, repeatable, and standardized evaluations of AI systems before they are operationalized. — [Appendix A: Mobilizing to Advance AI Security Resources]


---

**Source:** `securing-ai`

**Centralized AI Security Expertise**
By creating a centralized cadre of AI security experts and empowering them to collaborate with business and IT stakeholders, organizations can maximize the reach and effectiveness of this limited pool of expertise. — [Introduction]


---

**Source:** `securing-ai`

**Cross-Functional Governance for AI Security**
With a cross-functional governance approach, an awareness of the latest threats, and the staffing and ability to implement calibrated countermeasures, organizations can confidently turn an AI-first posture into a secure mission transformation. — [Introduction]


---

**Source:** `securing-ai`

**Ubiquitous AI Magnifies Vulnerabilities**
The distributed and ubiquitous nature of AI magnifies its vulnerabilities, especially with AI agents embedded into business processes with limited oversight. — [Why is AI Security Unique?]


---

**Source:** `securing-ai`

**Shadow AI and Third-Party Risks**
Employees may be doing shadow AI (using AI tools without approval), and vendors may be embedding AI without notifying users, decreasing transparency and weakening security. — [Why is AI Security Unique?]


---

**Source:** `situationalawareness`

**Key Finding: Superintelligence Could Follow AGI Quickly**
Automated AI research, with millions of AGIs, could compress a decade of algorithmic progress into a year, leading to rapid transition from AGI to vastly superhuman AI systems. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Supporting Fact: Unhobbling Gains**
Techniques like scaffolding and tool use can result in effective compute gains of 5-30x on many benchmarks. — Epoch AI survey, highlighting the importance of algorithmic progress beyond base models.


---

**Source:** `situationalawareness`

**AI Roadmap: Three Key Ingredients for Agent-Coworkers**
The path from chatbot to agent-coworker requires: 1) solving the "onboarding problem," 2) addressing the test-time compute overhang, and 3) enabling models to use a computer. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Critical Capability: Securing Algorithmic Secrets**
AGI-level security for algorithmic secrets is necessary years before AGI-level security for weights. These algorithmic breakthroughs will matter more than a 10x or 100x larger cluster in a few years. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Critical Capability: Superalignment Research**
We will need better alignment techniques to ensure even basic side constraints for future models, like follow instructions or follow the law. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Critical Capability: Industrial Mobilization**
The race to AGI will require mobilizing American industrial might, including building massive GPU clusters, datacenters, and power plants. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**AI Roadmap: Stages of AGI Development**
The author envisions a progression: 1) Proto-automated engineers (2026/27), 2) Proto-automated researchers (2027/28), and 3) 10x+ pace of progress leading to superintelligence (2028/29). — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Decisions: Prioritize Data Centers in the US**
Given the dysfunction and cost of building fabs in the US, prioritize datacenters in the US while betting more heavily on democratic allies like Japan and South Korea for fab projects. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Decisions: Prioritize Security**
American AI labs must put the national interest first, before the allure of free-flowing Middle Eastern cash, arcane regulation, or even, yes, admirable climate commitments. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Best Practice: Superdefense**
Even with alignment, implement "superdefense" measures like airgapped datacenters, hardware encryption, and strict limitations on external dependencies to reduce fallout from potential failures. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Measuring Success: AGI Revenue Run Rate**
A key milestone for AI revenue is when a big tech company (Google, Microsoft, Meta, etc.) hits a $100B revenue run rate from AI (products and API). — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Key Finding: Trillions Will Be Invested in AI Infrastructure**
As AI revenue grows rapidly, trillions of dollars will be invested in GPU, datacenter, and power buildout before the end of the decade. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**AI Roadmap: The Project**
By 2027/28, expect a government AGI project to emerge, as no startup can handle superintelligence. The endgame will be on somewhere in a SCIF. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Key Finding: AI Labs' Security is an Afterthought**
Leading AI labs treat security as an afterthought, handing AGI secrets to the CCP on a silver platter. Securing AGI secrets and weights against state actors is crucial. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Key Finding: Superalignment is an Unsolved Problem**
Reliably controlling AI systems much smarter than we are is an unsolved technical problem. Failure to solve it could easily be catastrophic. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Key Finding: Free World Must Prevail in AGI Race**
Superintelligence will give a decisive economic and military advantage. The free world's very survival will be at stake in the race to AGI. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Key Quote: Models Just Want to Learn**
"The models, they just want to learn. You have to understand this. The models, they just want to learn." — Ilya Sutskever (circa 2015, via Dario Amodei), highlighting the consistent improvements with scaling deep learning.


---

**Source:** `situationalawareness`

**Supporting Fact: GPT-2 to GPT-4 Qualitative Jump**
GPT-2 to GPT-4 represented a qualitative jump from ~preschooler to ~smart high-schooler abilities in 4 years. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Supporting Fact: Compute Scaling Trend**
Training compute for frontier AI systems has grown at roughly ~0.5 OOMs/year for the last decade and a half. — Leopold Aschenbrenner, Situational Awareness: The Decade Ahead


---

**Source:** `situationalawareness`

**Supporting Fact: Algorithmic Efficiency Gains**
Algorithmic efficiency in language modeling has improved by roughly ~0.5 OOMs/year from 2012 to 2023. — Epoch AI estimates, suggesting significant compute multipliers.


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Key Finding: Untapped Value in Advanced Analytics**
Only a small fraction of the value that could be unlocked by advanced-analytics approaches has been realized, with some sectors unlocking as little as 10%. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #3: Lack of Analytics Strategy Beyond Use Cases**
Failing to develop a comprehensive analytics strategy beyond specific use cases can lead to missed opportunities and difficulty in energizing the workforce. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Develop a Comprehensive Analytics Strategy**
The CDO or CAO must ask business leaders about the threats and opportunities presented by AI and advanced analytics, and how data and analytics can create new opportunities. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #4: Poorly Defined Analytics Roles**
Few executives can describe in detail the analytics talent their organizations have, where it's located, how it's organized, and whether they have the right skills and titles. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Define and Inventory Analytics Roles**
The CDO and CHRO should detail job descriptions for all needed analytics roles, inventory existing talent, and fill remaining roles through external hiring. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Critical Capability: Analytics Talent as a Tapestry of Skill Sets**
Think about analytics talent as a tapestry of skill sets and roles, each with its own carefully crafted definition. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #5: Lack of Analytics Translators**
The absence of analytics translators, who bridge the gap between business needs and technical expertise, hinders the ability to unlock value from analytics initiatives. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Hire or Train Analytics Translators**
Companies should hire or train analytics translators, prioritizing internal candidates with deep company knowledge and business acumen. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Best Practice: Translator Academies**
Create translator academies to train internal candidates in the unique combination of business knowledge, technical fluency, and project-management excellence required for the role. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #6: Isolated Analytics Capabilities**
Organizations with successful analytics initiatives embed analytics capabilities into their core businesses, while those that struggle develop them in isolation. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Hybrid Organizational Model for Analytics**
The C-suite should consider a hybrid organizational model in which agile teams combine professionals from both the business and analytics sides. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Key Finding: Growing Gap Between AI Leaders and Laggards**
The gap between leaders and laggards in successful AI and analytics adoption is growing, both within and among industry sectors. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Best Practice: Centralized vs. Decentralized Analytics Over Time**
Early in a company's analytics journey, a more centralized approach may be beneficial, but over time, the center can transition to a facilitation role as the business becomes more proficient. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #7: Costly Data-Cleansing Efforts Started En Masse**
Business leaders often believe all data must be cleaned before analytics can begin, leading to wasted effort and resources. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Supporting Fact & Figure: Wasted Data Cleansing Efforts**
McKinsey estimates that companies may be squandering as much as 70 percent of their data-cleansing efforts. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Prioritize Data Cleansing Based on Use Cases**
The CDO, in conjunction with business and IT leaders, should orchestrate data cleansing on the data that fuel the most valuable use cases. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #8: Analytics Platforms Not Built to Purpose**
Companies often make mistakes like integrating legacy IT systems first or building a data lake before figuring out how to fill and structure it, leading to meager benefits. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Supporting Fact & Figure: Data Lake Failures**
More than half of all data lakes are not fit for purpose, often requiring significant design changes or abandonment. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Parallel Data Platform Development**
A new data platform can exist in parallel with legacy systems, allowing for data ingestion, cleansing, and analytics while legacy systems continue to service transactional data needs. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #9: Inability to Quantify Analytics Impact**
Many companies spend millions on analytics without being able to attribute any bottom-line impact to these investments. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Performance-Management Framework for Analytics**
Create a performance-management framework for analytics initiatives with carefully developed metrics that track directly to the initiatives. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Measuring Success: Align Metrics to Specific Use Cases**
Align metrics to specific use cases (e.g., percentage reduction in overstock) to determine the impact of analytics and enable resource reallocation. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Key Finding: Acting on Red Flags Improves Success**
Business leaders who identify and address the ten red flags outlined in the article can dramatically improve their companies’ chances of success in analytics within two to three years. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #10: Neglecting Ethical, Social, and Regulatory Implications**
Failing to anticipate the ethical, social, and regulatory implications of analytics initiatives can lead to regulatory issues and damage employee relations. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Risk-Management Program for Analytics**
The CDO should lead a risk-management program, working with the CHRO, business-ethics experts, and legal counsel, to set up resiliency testing services that can expose and interpret the secondary effects of analytics programs. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Critical Capability: Resiliency Testing Services**
Implement resiliency testing services to quickly expose and interpret the secondary effects of the company's analytics programs, addressing potential ethical and regulatory issues. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #1: Lack of Executive Vision for Advanced Analytics**
Executive teams often lack a solid understanding of the difference between traditional analytics (business intelligence and reporting) and advanced analytics (predictive and prescriptive tools like machine learning), hindering program success. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Executive Education on Advanced Analytics**
The CEO, CAO, or CDO should conduct workshops for the executive team to educate them on advanced analytics concepts and address misconceptions. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Best Practice: In-House Analytics Academies**
Establish in-house "academies" to continually teach key analytics concepts to a broader management audience. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Red Flag #2: Undefined Value of Initial Use Cases**
Applying analytics tools and methods without precisely assessing the feasibility or calculating the business value of use cases leads to waste and undermines confidence in analytics initiatives. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Decision: Prioritize High-Value, Feasible Use Cases**
Companies should focus on the top three to five feasible use cases that can create the greatest value quickly (ideally within the first year) to generate momentum and buy-in. — McKinsey Analytics


---

**Source:** `ten-red-flags-signaling-your-analytics-program-will-fail`

**Critical Capability: Value Chain Analysis for Use Case Identification**
Analyze the entire value chain of the business to pinpoint the highest-value analytics use cases, considering both impact and feasibility. — McKinsey Analytics


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Deployment is Increasing, but Outcomes are Lagging**
79% of leaders reported full-scale deployment for three or more AI applications, up from 62% last year, yet many organizations are struggling with middling results.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Key Action 2: Transform Operations**
The entire operating model may need to change to accommodate the unique capabilities of intelligent machines to ensure ethical and quality application of AI.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Key Action 3: Orchestrate Tech and Talent**
Companies must develop their AI strategies in a tight talent market, with growing off-the-shelf platforms, tools and accelerators that can jump-start a company’s transformation.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Key Action 4: Select High-Value Use Cases**
AI is fueling transformations across all industries, and many leaders have begun to unlock which use cases are driving the most value within their given context.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI-Ready Culture: Agility and Executive Leadership**
Agility and willingness to change, combined with executive leadership around a vision for AI, are the most important factors in developing an AI-ready culture.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Importance of Change Management**
High-outcome organizations are more than 55% more likely to invest in change management compared to low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Workforce Optimism Towards AI**
82% of respondents surveyed indicate employees believe that working with AI technologies will enhance their performance and job satisfaction.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Human-Machine Collaboration Strategy**
43% of all respondents reported their organization has appointed a leader responsible for helping workers collaborate better with intelligent machines.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI for Decision-Making at Senior Levels**
44% of all respondents reported using AI to assist in decision-making at senior-most levels.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Gaps in Enabling Hybrid Human-Machine Workforce**
Only 21% of respondents reported actively educating workers on when to apply AI most effectively, highlighting a gap in enabling human-machine collaboration.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Redesigning Work for AI**
One of the biggest opportunities for driving greater value with AI is redesigning work itself.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Investment to Increase**
76% of respondents plan to increase their AI investments in the next fiscal year, indicating a persistent belief in AI's importance.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Fostering Trust in Algorithms**
An important element in establishing positive working relationships with intelligent machines is to focus on fostering trust in algorithms by involving business specialists and frontline employees to help design them.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices and Outcomes**
Operational leading practices were among the behaviors most highly associated with outcomes, including MLOps, redesigning workflows and documenting AI model life cycles.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices: ROI Tracking**
86% of high-outcome organizations track the ROI of deployed models and applications, compared to 71% of low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices: Data Governance**
77% of high-outcome organizations have a documented process for governance and quality of data put into AI models, compared to 62% of low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices: MLOps**
76% of high-outcome organizations follow documented MLOps procedures, compared to 63% of low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices: AI Model Life Cycle**
84% of high-outcome organizations follow a documented AI model life cycle publication strategy, compared to 66% of low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices: Common AI Platform**
81% of high-outcome organizations leverage a common and consistent platform for AI model and application development, compared to 66% of low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Operational Leading Practices: AI Quality and Risk Management**
78% of high-outcome organizations use an AI quality and risk management process and framework to assess AI model bias and other risks before models go into production, compared to 63% of low-outcome organizations.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Importance of AI Solutions**
A clear majority (60%) of respondents viewed AI solutions as strategically “very important” for their organizations’ success.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Ethical AI Frameworks and Outcomes**
Organizations can often achieve better outcomes when they adopt an ethical AI framework that aligns with Trustworthy AI principles.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Challenges in Starting AI Projects: Proving Business Value**
The top reported challenge when starting new AI projects is proving AI’s business value (37%).
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Managing AI Risk: Top Inhibitor to Scaling**
50% of respondents cited management of AI-related risks as one of the top inhibitors to scaling AI projects.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Risk Management Alignment**
Only 33% of respondents have aligned their AI risk management with their organization’s broader risk management efforts.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Risk Mitigation: Training**
Respondents’ top two risk-mitigation strategies are training AI developers to recognize and resolve AI ethical issues (35%) and training / supporting employees to foster productive, positive relationships to AI (34%).
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Acquiring AI Talent vs. Retraining**
A majority of surveyed organizations reported they still prioritize bringing new AI talent into the business from outside, rather than retraining existing workers.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Acquiring AI Solutions**
A significant majority of survey respondents acquire AI as a product or service (65%)—rather than attempting to build their own AI solutions in-house (35%).
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Solution Acquisition by Experience**
Organizations with more years of AI implementation experience tend to be more likely to try building their own AI solutions, while organizations with fewer years under their belt have a tendency to depend on packaged solutions.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Use Case Selection: Impact on Outcomes**
The choices organizations make when selecting which business processes to start with could set the trajectory for how quickly and to what degree they will achieve successful outcomes and gain momentum through early efforts.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Industry-Specific AI Investments**
The processes, practices and regulatory contexts specific to each industry have a large influence on the way that companies in different industries pursue AI investments.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Consumer Industry: AI Assistants on the Shop Floor**
Smaller consumer product and manufacturing firms see the most success with bringing AI assistants to the shop floor in the form of virtual operator assistants.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Consumer Industry: AI-Enabled Value Chain Optimization**
Larger consumer product and manufacturing firms tend to see better results from investing in AI-enabled value chain optimization to identify hidden opportunities and overlooked savings.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Challenges in Scaling AI Projects: Managing AI-Related Risks**
Key impediments to scaling AI projects include managing AI-related risks (50%), lack of executive buy-in (50%), and lack of maintenance or ongoing support (50%).
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Life Sciences and Health Care: Focus on Automating Repetitive Tasks**
Top use cases across life sciences and health care as an industry still tend to focus primarily on automating repetitive tasks and standard cross-industry business processes.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Life Sciences: Smart Drug Discovery**
Within life sciences, AI's role within the biopharmaceutical R&D value chain manifests in the preeminent role of smart drug discovery applications.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Health Care: AI-Assisted Diagnoses**
The leading industry-specific health care AI use cases focus on outcomes and monitoring in such potentially transformational areas as AI-assisted diagnoses including predictive diagnoses, patient engagement, insurance fraud detection and smarter hospitals.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Health Care: Trustworthy AI for Equitable Outcomes**
Key in this regard is in guarding against the kind of model bias that could result in unfair and inequitable health care delivery and insurance coverage, among other areas.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Energy, Resources and Industrials: Focus on Data Management**
Survey results reflect focus in IT cloud pricing and optimization of uptime and reliability for managing data, as well as the expansion of human resources with skills in data engineering.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Energy, Resources and Industrials: Operational Models Lagging**
The operational models for harnessing AI technology have not yet made inroads into ER&I compared with respondents in other industries.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Technology, Media and Telecommunications: AI Critical for Competitiveness**
72% of respondents strongly agree that AI is very important to their ability to stay competitive over the next five years, 12 percentage points higher than any other industry.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Technology, Media and Telecommunications: Telecommunications and Media Lead in AI Adoption**
Telecommunications and media companies tend to be the furthest along at embracing AI, the sector with the largest proportion of Transformers.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Financial Services: Lagging in AI Maturity**
Compared to other industries surveyed, financial services companies tend to be lagging slightly in their AI maturity journey.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Financial Services: Next-Generation Digital Customer Experience**
Next-generation digital customer experience and broad risk management are likely to be particularly lucrative opportunities to drive positive impact and profitable growth for the financial services industry.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Importance of Clear Leadership and Focused Investment**
Successful AI transformation requires clear leadership and focused investment, as well as coordination and discipline to maintain systems and algorithms.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Government and Public Services: Focus on Back-Office Activities**
Across all types of organizations surveyed, the majority are still focusing AI efforts on back-office activities where efficiencies can be created through automation.
— Deloitte’s State of AI in the Enterprise, 5th Edition report
```


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Payback Periods are Meeting Expectations**
87% of respondents reported that the length of payback period for AI projects is within their expectations or faster.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**AI Outcomes: Focus on Cost Reduction**
The most frequently reported outcome of AI initiatives is reduced costs (78%), which may overshadow more transformational opportunities like revenue generation.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**High-Outcome Organizations See Revenue Generation**
High-outcome organizations (Transformers and Pathseekers) are significantly more likely to report revenue-generating results from AI.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `us-ai-institute-state-of-ai-fifth-edition`

**Key Action 1: Invest in Culture and Leadership**
Leaders should reinvent work to capitalize on workforce optimism and opportunity that their human workforce sees in AI.
— Deloitte’s State of AI in the Enterprise, 5th Edition report


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**ChatGPT's Rapid Adoption**
ChatGPT reached 100 million users in just two months, demonstrating the unprecedented democratization of AI. Its accessibility sets it apart from previous AI technologies. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Versatility Enables Faster Application Development**
The versatility of foundation models allows companies to use the same model for multiple business use cases, accelerating application development and benefit realization. Companies can stand up applications and realize their benefits much faster. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Prone to Hallucination**
Large language models can be prone to "hallucination," or answering questions with plausible but untrue assertions. This means companies should be careful of integrating generative AI without human oversight in applications where errors can cause harm or where explainability is needed. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Emerging Generative AI Ecosystem**
A value chain is emerging to support generative AI, including specialized hardware, cloud platforms, MLOps, model hubs, and applications. This ecosystem facilitates the training and use of generative AI technology. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Exploration of Generative AI: A Must, Not a Maybe**
CEOs should consider exploration of generative AI a must, not a maybe. The economics and technical requirements to start are not prohibitive, while the downside of inaction could be quickly falling behind competitors. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Risks**
Generative AI poses a variety of risks, including fairness, intellectual property, privacy, security, explainability, reliability, organizational impact, and social and environmental impact. CEOs will want to design their teams and processes to mitigate those risks from the start. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Intellectual Property Risks**
Training data and model outputs can generate significant IP risks, including infringing on copyrighted, trademarked, patented, or otherwise legally protected materials. Even when using a provider’s generative AI tool, organizations will need to understand what data went into training and how it’s used in tool outputs. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Privacy Concerns**
Privacy concerns could arise if users input information that later ends up in model outputs in a form that makes individuals identifiable. Generative AI could also be used to create and disseminate malicious content such as disinformation, deepfakes, and hate speech. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Security Risks**
Generative AI may be used by bad actors to accelerate the sophistication and speed of cyberattacks. It also can be manipulated to provide malicious outputs. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Explainability Challenges**
Generative AI relies on neural networks with billions of parameters, challenging our ability to explain how any given answer is produced. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Organizational Impact**
Generative AI may significantly affect the workforce, and the impact on specific groups and local communities could be disproportionately negative. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Foundation Models: The Power Behind Generative AI**
Generative AI chatbots are powered by foundation models, expansive neural networks trained on vast quantities of unstructured data. These models can perform a wide range of tasks, unlike narrow, task-specific AI models. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Social and Environmental Impact**
The development and training of foundation models may lead to detrimental social and environmental consequences, including an increase in carbon emissions. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Software Engineering: AI-Based Code Completion**
Implementing AI-based code-completion products can speed up a developer’s code generation by as much as 50 percent. It can also help in debugging, which may improve the quality of the developed product. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Relationship Managers: Generative AI for Productivity**
Generative AI can speed up an RM’s analysis process (from days to hours), improve job satisfaction, and potentially capture insights the RM might have otherwise overlooked. The bank decided to build a solution that accesses a foundation model through an API. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Customer Support: Fine-Tuning for Efficiency**
Fine-tuning a foundation model optimized for conversations on high-quality customer chats and sector-specific questions and answers can free up service representatives to focus on higher-value and complex customer inquiries, improved representatives’ efficiency and job satisfaction, and increased service standards and customer satisfaction. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Drug Discovery: Training a Foundation Model from Scratch**
Training a foundation model from scratch can add value by predicting which drug candidates might lead to favorable outcomes and by improving the ability to accurately identify relevant cell features for drug discovery. This can lead to more efficient and effective drug discovery processes. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Transformative Use Cases Already Exist**
Transformative use cases that offer practical benefits for jobs and the workplace already exist. Companies across sectors, from pharmaceuticals to banking to retail, are standing up a range of use cases to capture value creation potential. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Costs Vary Widely**
Costs of pursuing generative AI vary widely, depending on the use case and the data required for software, cloud infrastructure, technical expertise, and risk mitigation. Companies must take into account risk issues, regardless of use case, and some will require more resources than others. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Build a Business Case First**
While there is merit to getting started fast, building a basic business case first will help companies better navigate their generative AI journeys. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Organizing for Generative AI: Cross-Functional Group**
Convene a cross-functional group of the company’s leaders (for example, representing data science, engineering, legal, cybersecurity, marketing, design, and other business functions). Such a group can not only help identify and prioritize the highest-value use cases but also enable coordinated and safe implementation across the organization. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Reimagining End-to-End Domains**
It is important to have a perspective on the family of use cases by domain that will have the most transformative potential across business functions. Organizations are reimagining the target state enabled by generative AI working in sync with other traditional AI applications, along with new ways of working that may not have been possible before. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI's Versatility and Limitations**
While versatile, generative AI can sometimes provide less accurate results, highlighting the importance of AI risk management. It is also currently unsuited for directly analyzing large amounts of tabular data or solving advanced numerical-optimization problems. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Enabling a Fully Loaded Technology Stack**
A modern data and tech stack is key to nearly any successful approach to generative AI. CEOs should look to their chief technology officers to determine whether the company has the required technical capabilities in terms of computing resources, data systems, tools, and access to models (open source via model hubs or commercial via APIs). — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Building a ‘Lighthouse’**
It’s important to showcase internally how it can affect a company’s operating model, perhaps through a “lighthouse approach.” For example, one way forward is building a “virtual expert” that enables frontline workers to tap proprietary sources of knowledge and offer the most relevant content to customers. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Balancing Risk and Value Creation**
Business leaders must balance value creation opportunities with the risks involved in generative AI. The cross-functional leadership team will want to not only establish overarching ethical principles and guidelines for generative AI use but also develop a thorough understanding of the risks presented by each potential use case. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Applying an Ecosystem Approach to Partnerships**
Business leaders should focus on building and maintaining a balanced set of alliances. A company’s acquisitions and alliances strategy should continue to concentrate on building an ecosystem of partners tuned to different contexts and addressing what generative AI requires at all levels of the tech stack, while being careful to prevent vendor lock-in. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Focusing on Required Talent and Skills**
To effectively apply generative AI for business value, companies need to build their technical capabilities and upskill their current workforce. This requires a concerted effort by leadership to identify the required capabilities based on the company’s prioritized use cases, which will likely extend beyond technical roles to include a talent mix across engineering, data, design, risk, product, and other business functions. — QuantumBlack, AI by McKinsey
```


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI Augments Knowledge Workers**
Generative AI can augment nearly every knowledge worker, increasing productivity through integration into everyday tools like email and word-processing software. Much of its value could derive from how software vendors embed the technology into everyday tools. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**CEO's Role: Act Now or Exercise Caution?**
CEOs must decide whether to aggressively adopt generative AI to leapfrog the competition or to experiment cautiously before making large investments. Companies will also have to assess whether they have the necessary technical expertise, technology and data architecture, operating model, and risk management processes. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Article Goal: Value Creation and Starting the Journey**
This article aims to help CEOs understand the value creation potential of generative AI and how to begin their adoption journey. It offers a primer, example cases, and guidance on positioning the organization for success. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI: Automate, Augment, Accelerate**
Generative AI can be used to automate, augment, and accelerate work across a broad range of content, including images, video, audio, and computer code. It can perform several functions in organizations, including classifying, editing, summarizing, answering questions, and drafting new content. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Generative AI vs. Traditional AI: Content Generation**
The primary difference between generative AI and previous forms of AI is its ability to efficiently generate new content, often in unstructured formats like text or images. The underlying model that enables generative AI to work is called a foundation model. — QuantumBlack, AI by McKinsey


---

**Source:** `what-every-ceo-should-know-about-generative-ai`

**Foundation Models: Trained on Vast Unstructured Data**
Foundation models are trained on extremely large and varied sets of unstructured data, enabling them to learn patterns and relationships. This allows them to perform multiple functions, unlike traditional deep learning models that are often task-specific. — QuantumBlack, AI by McKinsey
