**Source:** `Emerging Architectures for LLM Applications _ Andreessen Horowitz`

**Context Window Limitations and Costs**
While increasing the context window is possible, it comes with tradeoffs, as cost and time of inference can scale quadratically with prompt length, making it cost-prohibitive for many applications. â€” [Matt Bornstein and Rajko Radovanovic, Andreessen Horowitz]
