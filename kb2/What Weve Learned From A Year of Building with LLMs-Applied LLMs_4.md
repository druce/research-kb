**Source:** `What We’ve Learned From A Year of Building with LLMs – Applied LLMs`

**Prompting Technique: Chain-of-Thought (CoT)**
Encourage the LLM to explain its reasoning process before providing the final answer, adding specificity to reduce hallucination rates. — Applied LLMs
