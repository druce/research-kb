**Source:** `Best Practices for RAG pipelines`

**Summarization Reduces Redundancy and Prevents Long Prompts**
Summarization reduces redundancy and prevents long prompts from slowing down inference in LLMs. Recomp is the preferred summarization method, with LongLLMLingua as an alternative.
