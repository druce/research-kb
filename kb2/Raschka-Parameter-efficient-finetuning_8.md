**Source:** `Raschka-Parameter-efficient-finetuning`

**Prefix Tuning Efficiency**
Prefix tuning can achieve comparable performance to finetuning all layers while only training a small percentage (e.g., 0.1%) of the parameters. â€” Raschka-Parameter-efficient-finetuning
