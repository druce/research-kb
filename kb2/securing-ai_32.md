**Source:** `securing-ai`

**Data Poisoning: Manipulating Training Data**
Adversaries manipulate training data to compromise model behaviors and insert backdoors through data poisoning. â€” [What do AI Security Threats Look Like?]
