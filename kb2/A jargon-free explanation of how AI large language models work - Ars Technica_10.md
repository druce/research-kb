**Source:** `A jargon-free explanation of how AI large language models work - Ars Technica`

**Attention Mechanism: Matchmaking for Words**
The attention mechanism in transformers allows words to "look around" for other words with relevant context and share information. Each word creates query and key vectors to find the best matches. â€” [Timothy B. Lee and Sean Trott, Ars Technica]
