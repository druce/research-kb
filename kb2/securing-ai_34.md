**Source:** `securing-ai`

**Model Evasion: Fooling the Model**
Adversaries perturb model inputs to control model outputs, also known as model evasion. â€” [What do AI Security Threats Look Like?]
